{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cf9748",
   "metadata": {},
   "source": [
    "# Task A: NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3dca4e",
   "metadata": {},
   "source": [
    "## 0. Load the preprocessed data\n",
    "**We will use preprocessed image dataset and testset after image processing and PCA. They characterize 2 different classes (tumor or not) based on 200 features.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4dffb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed198e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 200) (3000,)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed image data with help of pickle.\n",
    "with open('DataAfterProcess/images_AfterProcess.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "    \n",
    "with open('DataAfterProcess/label_AfterProcess.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)\n",
    "    \n",
    "# Check result.\n",
    "print(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0cbf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200) (200,)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed test dataset with help of pickle.\n",
    "with open('DataAfterProcess/test_images_AfterProcess.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "    \n",
    "with open('DataAfterProcess/test_label_AfterProcess.pickle', 'rb') as handle:\n",
    "    y_test = pickle.load(handle)\n",
    "    \n",
    "# Check result.\n",
    "print(X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9480dad",
   "metadata": {},
   "source": [
    "### Training-Validation-Test \n",
    "**Split the preprocessed image dataset into training set (90%) and validation set (10%). The test set is chosen as dataset from AMLS-2021_test.zip.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7474e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad638729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 200) (2700, 2) (300, 200) (300, 2) (200, 200) (200, 2)\n",
      "train set: 0.9 | val set: 0.1 | test set: 0.067\n"
     ]
    }
   ],
   "source": [
    "# Implement one-hot encoding to labels.\n",
    "y = to_categorical(y)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Split dataset into a training set and a validation set (90% training and 10% validation data).\n",
    "# Notice that all random state is chosen as fixed in this assignment to ensure reproducibility.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, \n",
    "                                                  test_size=0.1, random_state=2)\n",
    "\n",
    "# Check result.\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape) \n",
    "print('train set: {} | val set: {} | test set: {}'.format(round(len(y_train)/len(X),3), \n",
    "                                                          round(len(y_val)/len(X),3),\n",
    "                                                          round(len(y_test)/len(X),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca63f4",
   "metadata": {},
   "source": [
    "## 1. Hyperparameter tuning: Trial and error\n",
    "**In this part, we try to train a neural network and tune the hyperparameter by trial and error, which means we change the hyperparameter of model by checking curve of training and validation loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8ae5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98bbd3",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8586f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input, output dimension of the NN, since they are fixed!\n",
    "input_units = X_train.shape[1]\n",
    "output_units = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9164868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to plot traing loss and validation loss.\n",
    "def plot_loss(training_history):    \n",
    "    # Set new figure.\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.grid()    \n",
    "    \n",
    "    # Read loss information wrt.loss from input.      \n",
    "    history_dict = training_history.history\n",
    "\n",
    "    tra_loss, val_loss = history_dict['loss'], history_dict['val_loss']\n",
    "    epochs = range(1,len(tra_loss)+1)\n",
    "\n",
    "    # Plot trainging loss and validation loss.\n",
    "    plt.plot(epochs,tra_loss, 'bo', label='Training loss') \n",
    "    plt.plot(epochs,val_loss, 'b', label='Validation loss')\n",
    "\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c1c29",
   "metadata": {},
   "source": [
    "### Formulate initial neural network\n",
    "**Build the initial neural network with 3 layers: input layer, hidden layer and output layer.**\n",
    "- Dense hidden layer with 4 units and relu as activation function;\n",
    "- Epochs and batch size are chosen as 100 and 128;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d68f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 4)                 804       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 854\n",
      "Trainable params: 854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defeine layer variable.\n",
    "hidden_units_ini = 4\n",
    "\n",
    "# Define training variable.\n",
    "epochs_ini = 100\n",
    "batch_size_ini = 128\n",
    "\n",
    "# Create the model.\n",
    "model_ini = models.Sequential()\n",
    "model_ini.add(layers.Dense(units=hidden_units_ini, activation='relu', input_shape=[input_units]))\n",
    "model_ini.add(layers.Dense(units=hidden_units_ini, activation='relu'))\n",
    "model_ini.add(layers.Dense(units=hidden_units_ini, activation='relu'))\n",
    "model_ini.add(layers.Dense(units=output_units, activation='softmax'))\n",
    "\n",
    "# Configure the model with optimizer, loss function and metrics.\n",
    "model_ini.compile(optimizer=optimizers.Adam(),\n",
    "                  loss=losses.CategoricalCrossentropy(),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "# Check result.\n",
    "print(model_ini.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d6baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "2700/2700 [==============================] - 0s 161us/sample - loss: 0.7116 - categorical_accuracy: 0.5911 - val_loss: 0.6672 - val_categorical_accuracy: 0.6433\n",
      "Epoch 2/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.6311 - categorical_accuracy: 0.7048 - val_loss: 0.6155 - val_categorical_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.5787 - categorical_accuracy: 0.7870 - val_loss: 0.5752 - val_categorical_accuracy: 0.8067\n",
      "Epoch 4/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.5327 - categorical_accuracy: 0.8419 - val_loss: 0.5364 - val_categorical_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.4883 - categorical_accuracy: 0.8663 - val_loss: 0.4978 - val_categorical_accuracy: 0.8467\n",
      "Epoch 6/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.4463 - categorical_accuracy: 0.8744 - val_loss: 0.4629 - val_categorical_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.4080 - categorical_accuracy: 0.8800 - val_loss: 0.4362 - val_categorical_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.3748 - categorical_accuracy: 0.8893 - val_loss: 0.4111 - val_categorical_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.3470 - categorical_accuracy: 0.8963 - val_loss: 0.3863 - val_categorical_accuracy: 0.8733\n",
      "Epoch 10/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.3233 - categorical_accuracy: 0.8967 - val_loss: 0.3653 - val_categorical_accuracy: 0.8767\n",
      "Epoch 11/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.3020 - categorical_accuracy: 0.9048 - val_loss: 0.3495 - val_categorical_accuracy: 0.8867\n",
      "Epoch 12/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.2844 - categorical_accuracy: 0.9133 - val_loss: 0.3381 - val_categorical_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.2669 - categorical_accuracy: 0.9159 - val_loss: 0.3282 - val_categorical_accuracy: 0.8933\n",
      "Epoch 14/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.2511 - categorical_accuracy: 0.9219 - val_loss: 0.3184 - val_categorical_accuracy: 0.8967\n",
      "Epoch 15/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.2369 - categorical_accuracy: 0.9270 - val_loss: 0.3097 - val_categorical_accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.2230 - categorical_accuracy: 0.9356 - val_loss: 0.2996 - val_categorical_accuracy: 0.8967\n",
      "Epoch 17/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.2103 - categorical_accuracy: 0.9400 - val_loss: 0.2935 - val_categorical_accuracy: 0.9033\n",
      "Epoch 18/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1990 - categorical_accuracy: 0.9437 - val_loss: 0.2860 - val_categorical_accuracy: 0.9067\n",
      "Epoch 19/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1891 - categorical_accuracy: 0.9456 - val_loss: 0.2794 - val_categorical_accuracy: 0.9133\n",
      "Epoch 20/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.1786 - categorical_accuracy: 0.9485 - val_loss: 0.2743 - val_categorical_accuracy: 0.9100\n",
      "Epoch 21/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1694 - categorical_accuracy: 0.9500 - val_loss: 0.2726 - val_categorical_accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1598 - categorical_accuracy: 0.9537 - val_loss: 0.2722 - val_categorical_accuracy: 0.9133\n",
      "Epoch 23/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1521 - categorical_accuracy: 0.9559 - val_loss: 0.2737 - val_categorical_accuracy: 0.9100\n",
      "Epoch 24/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1452 - categorical_accuracy: 0.9574 - val_loss: 0.2746 - val_categorical_accuracy: 0.9100\n",
      "Epoch 25/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1380 - categorical_accuracy: 0.9604 - val_loss: 0.2723 - val_categorical_accuracy: 0.9100\n",
      "Epoch 26/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1317 - categorical_accuracy: 0.9604 - val_loss: 0.2713 - val_categorical_accuracy: 0.9133\n",
      "Epoch 27/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1258 - categorical_accuracy: 0.9630 - val_loss: 0.2724 - val_categorical_accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1212 - categorical_accuracy: 0.9637 - val_loss: 0.2754 - val_categorical_accuracy: 0.9133\n",
      "Epoch 29/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1164 - categorical_accuracy: 0.9663 - val_loss: 0.2716 - val_categorical_accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.1123 - categorical_accuracy: 0.9681 - val_loss: 0.2637 - val_categorical_accuracy: 0.9200\n",
      "Epoch 31/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.1075 - categorical_accuracy: 0.9685 - val_loss: 0.2703 - val_categorical_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1021 - categorical_accuracy: 0.9704 - val_loss: 0.2753 - val_categorical_accuracy: 0.9167\n",
      "Epoch 33/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0983 - categorical_accuracy: 0.9719 - val_loss: 0.2790 - val_categorical_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0949 - categorical_accuracy: 0.9711 - val_loss: 0.2801 - val_categorical_accuracy: 0.9167\n",
      "Epoch 35/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0913 - categorical_accuracy: 0.9726 - val_loss: 0.2837 - val_categorical_accuracy: 0.9200\n",
      "Epoch 36/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0900 - categorical_accuracy: 0.9726 - val_loss: 0.2892 - val_categorical_accuracy: 0.9200\n",
      "Epoch 37/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0893 - categorical_accuracy: 0.9737 - val_loss: 0.3048 - val_categorical_accuracy: 0.9200\n",
      "Epoch 38/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0854 - categorical_accuracy: 0.9744 - val_loss: 0.3058 - val_categorical_accuracy: 0.9233\n",
      "Epoch 39/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0817 - categorical_accuracy: 0.9770 - val_loss: 0.3080 - val_categorical_accuracy: 0.9267\n",
      "Epoch 40/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0783 - categorical_accuracy: 0.9778 - val_loss: 0.3163 - val_categorical_accuracy: 0.9233\n",
      "Epoch 41/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0759 - categorical_accuracy: 0.9781 - val_loss: 0.3185 - val_categorical_accuracy: 0.9267\n",
      "Epoch 42/100\n",
      "2700/2700 [==============================] - ETA: 0s - loss: 0.0432 - categorical_accuracy: 0.99 - 0s 15us/sample - loss: 0.0738 - categorical_accuracy: 0.9789 - val_loss: 0.3234 - val_categorical_accuracy: 0.9267\n",
      "Epoch 43/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0716 - categorical_accuracy: 0.9796 - val_loss: 0.3306 - val_categorical_accuracy: 0.9267\n",
      "Epoch 44/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0689 - categorical_accuracy: 0.9796 - val_loss: 0.3347 - val_categorical_accuracy: 0.9200\n",
      "Epoch 45/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0671 - categorical_accuracy: 0.9807 - val_loss: 0.3362 - val_categorical_accuracy: 0.9233\n",
      "Epoch 46/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0652 - categorical_accuracy: 0.9807 - val_loss: 0.3481 - val_categorical_accuracy: 0.9200\n",
      "Epoch 47/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0637 - categorical_accuracy: 0.9807 - val_loss: 0.3497 - val_categorical_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "2700/2700 [==============================] - 0s 13us/sample - loss: 0.0620 - categorical_accuracy: 0.9811 - val_loss: 0.3588 - val_categorical_accuracy: 0.9200\n",
      "Epoch 49/100\n",
      "2700/2700 [==============================] - 0s 13us/sample - loss: 0.0599 - categorical_accuracy: 0.9815 - val_loss: 0.3689 - val_categorical_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0594 - categorical_accuracy: 0.9826 - val_loss: 0.3925 - val_categorical_accuracy: 0.9200\n",
      "Epoch 51/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0578 - categorical_accuracy: 0.9826 - val_loss: 0.3877 - val_categorical_accuracy: 0.9200\n",
      "Epoch 52/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0557 - categorical_accuracy: 0.9830 - val_loss: 0.3995 - val_categorical_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0529 - categorical_accuracy: 0.9833 - val_loss: 0.4084 - val_categorical_accuracy: 0.9200\n",
      "Epoch 54/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0516 - categorical_accuracy: 0.9833 - val_loss: 0.4067 - val_categorical_accuracy: 0.9233\n",
      "Epoch 55/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0502 - categorical_accuracy: 0.9837 - val_loss: 0.4135 - val_categorical_accuracy: 0.9200\n",
      "Epoch 56/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.0492 - categorical_accuracy: 0.9837 - val_loss: 0.4179 - val_categorical_accuracy: 0.9200\n",
      "Epoch 57/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0482 - categorical_accuracy: 0.9841 - val_loss: 0.4241 - val_categorical_accuracy: 0.9200\n",
      "Epoch 58/100\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.0474 - categorical_accuracy: 0.9844 - val_loss: 0.4300 - val_categorical_accuracy: 0.9200\n",
      "Epoch 59/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0466 - categorical_accuracy: 0.9844 - val_loss: 0.4353 - val_categorical_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0458 - categorical_accuracy: 0.9844 - val_loss: 0.4393 - val_categorical_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0451 - categorical_accuracy: 0.9844 - val_loss: 0.4455 - val_categorical_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0444 - categorical_accuracy: 0.9844 - val_loss: 0.4507 - val_categorical_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0438 - categorical_accuracy: 0.9844 - val_loss: 0.4539 - val_categorical_accuracy: 0.9133\n",
      "Epoch 64/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0432 - categorical_accuracy: 0.9844 - val_loss: 0.4619 - val_categorical_accuracy: 0.9133\n",
      "Epoch 65/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0426 - categorical_accuracy: 0.9844 - val_loss: 0.4702 - val_categorical_accuracy: 0.9133\n",
      "Epoch 66/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0420 - categorical_accuracy: 0.9844 - val_loss: 0.4745 - val_categorical_accuracy: 0.9133\n",
      "Epoch 67/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0423 - categorical_accuracy: 0.9841 - val_loss: 0.4800 - val_categorical_accuracy: 0.9133\n",
      "Epoch 68/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0414 - categorical_accuracy: 0.9844 - val_loss: 0.4843 - val_categorical_accuracy: 0.9133\n",
      "Epoch 69/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0407 - categorical_accuracy: 0.9844 - val_loss: 0.4888 - val_categorical_accuracy: 0.9133\n",
      "Epoch 70/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0399 - categorical_accuracy: 0.9844 - val_loss: 0.4903 - val_categorical_accuracy: 0.9133\n",
      "Epoch 71/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0394 - categorical_accuracy: 0.9844 - val_loss: 0.5007 - val_categorical_accuracy: 0.9133\n",
      "Epoch 72/100\n",
      "2700/2700 [==============================] - 0s 14us/sample - loss: 0.0386 - categorical_accuracy: 0.9848 - val_loss: 0.5046 - val_categorical_accuracy: 0.9133\n",
      "Epoch 73/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0378 - categorical_accuracy: 0.9852 - val_loss: 0.5138 - val_categorical_accuracy: 0.9133\n",
      "Epoch 74/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0373 - categorical_accuracy: 0.9852 - val_loss: 0.5206 - val_categorical_accuracy: 0.9133\n",
      "Epoch 75/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.0366 - categorical_accuracy: 0.9852 - val_loss: 0.5258 - val_categorical_accuracy: 0.9133\n",
      "Epoch 76/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0358 - categorical_accuracy: 0.9856 - val_loss: 0.5284 - val_categorical_accuracy: 0.9133\n",
      "Epoch 77/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0354 - categorical_accuracy: 0.9856 - val_loss: 0.5320 - val_categorical_accuracy: 0.9133\n",
      "Epoch 78/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0350 - categorical_accuracy: 0.9856 - val_loss: 0.5380 - val_categorical_accuracy: 0.9133\n",
      "Epoch 79/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0347 - categorical_accuracy: 0.9856 - val_loss: 0.5445 - val_categorical_accuracy: 0.9133\n",
      "Epoch 80/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0345 - categorical_accuracy: 0.9856 - val_loss: 0.5432 - val_categorical_accuracy: 0.9133\n",
      "Epoch 81/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0342 - categorical_accuracy: 0.9856 - val_loss: 0.5486 - val_categorical_accuracy: 0.9133\n",
      "Epoch 82/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0340 - categorical_accuracy: 0.9856 - val_loss: 0.5528 - val_categorical_accuracy: 0.9133\n",
      "Epoch 83/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0336 - categorical_accuracy: 0.9856 - val_loss: 0.5541 - val_categorical_accuracy: 0.9133\n",
      "Epoch 84/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0352 - categorical_accuracy: 0.9848 - val_loss: 0.5545 - val_categorical_accuracy: 0.9133\n",
      "Epoch 85/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0354 - categorical_accuracy: 0.9856 - val_loss: 0.5485 - val_categorical_accuracy: 0.9067\n",
      "Epoch 86/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0350 - categorical_accuracy: 0.9848 - val_loss: 0.5543 - val_categorical_accuracy: 0.9033\n",
      "Epoch 87/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0351 - categorical_accuracy: 0.9852 - val_loss: 0.5692 - val_categorical_accuracy: 0.9067\n",
      "Epoch 88/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0326 - categorical_accuracy: 0.9859 - val_loss: 0.5785 - val_categorical_accuracy: 0.9067\n",
      "Epoch 89/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0319 - categorical_accuracy: 0.9859 - val_loss: 0.5801 - val_categorical_accuracy: 0.9067\n",
      "Epoch 90/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0315 - categorical_accuracy: 0.9859 - val_loss: 0.5822 - val_categorical_accuracy: 0.9067\n",
      "Epoch 91/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0311 - categorical_accuracy: 0.9859 - val_loss: 0.5850 - val_categorical_accuracy: 0.9067\n",
      "Epoch 92/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0310 - categorical_accuracy: 0.9859 - val_loss: 0.5847 - val_categorical_accuracy: 0.9067\n",
      "Epoch 93/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0307 - categorical_accuracy: 0.9859 - val_loss: 0.5835 - val_categorical_accuracy: 0.9067\n",
      "Epoch 94/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0304 - categorical_accuracy: 0.9859 - val_loss: 0.5872 - val_categorical_accuracy: 0.9067\n",
      "Epoch 95/100\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.0301 - categorical_accuracy: 0.9859 - val_loss: 0.5943 - val_categorical_accuracy: 0.9067\n",
      "Epoch 96/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0299 - categorical_accuracy: 0.9859 - val_loss: 0.5984 - val_categorical_accuracy: 0.9067\n",
      "Epoch 97/100\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.0296 - categorical_accuracy: 0.9859 - val_loss: 0.6051 - val_categorical_accuracy: 0.9067\n",
      "Epoch 98/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0295 - categorical_accuracy: 0.9859 - val_loss: 0.6059 - val_categorical_accuracy: 0.9067\n",
      "Epoch 99/100\n",
      "2700/2700 [==============================] - 0s 16us/sample - loss: 0.0292 - categorical_accuracy: 0.9859 - val_loss: 0.6116 - val_categorical_accuracy: 0.9100\n",
      "Epoch 100/100\n",
      "2700/2700 [==============================] - 0s 15us/sample - loss: 0.0290 - categorical_accuracy: 0.9859 - val_loss: 0.6172 - val_categorical_accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "#  Train the model and evaluate with the validation set in every epoch.\n",
    "history_ini = model_ini.fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs=epochs_ini,\n",
    "                            batch_size=batch_size_ini,\n",
    "                            validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4d6f8",
   "metadata": {},
   "source": [
    "### Model validation\n",
    "**Evaluate the model per validation set by checking accuracy score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "779ff596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 43us/sample - loss: 0.6172 - categorical_accuracy: 0.9067\n",
      "[0.617218524813652, 0.9066667]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot traing loss and validation loss.\n",
    "plot_loss(history_ini)\n",
    "\n",
    "# Evaluate model by using validation set.\n",
    "print(model_ini.evaluate(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52aa2bc",
   "metadata": {},
   "source": [
    "### Formulate modified neural network\n",
    "**According to the previous result, we modify the network deeper (more hidden layers) and bigger (more hidden units). To avoid the overfitting, the l2 regularization and dropout layer are also considered.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7058173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 16)                3216      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 4,066\n",
      "Trainable params: 4,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defeine new layer variable. \n",
    "hidden_units_complex = 16\n",
    "C_complex = 0.02\n",
    "dropout_ratio_complex = 0.2\n",
    "\n",
    "# Define training variable\n",
    "epochs_complex = 200\n",
    "batch_size_complex = 128\n",
    "\n",
    "# Create the new model with l2 regularization and drop out layer.\n",
    "model_complex = models.Sequential()\n",
    "model_complex.add(layers.Dense(units=hidden_units_complex, activation='relu', \n",
    "                               kernel_regularizer=regularizers.l2(C_complex), input_shape=[input_units]))\n",
    "model_complex.add(layers.Dropout(dropout_ratio_complex))\n",
    "model_complex.add(layers.Dense(units=hidden_units_complex, activation='relu', \n",
    "                               kernel_regularizer=regularizers.l2(C_complex)))\n",
    "model_complex.add(layers.Dropout(dropout_ratio_complex))\n",
    "model_complex.add(layers.Dense(units=hidden_units_complex, activation='relu', \n",
    "                               kernel_regularizer=regularizers.l2(C_complex)))\n",
    "model_complex.add(layers.Dropout(dropout_ratio_complex))\n",
    "model_complex.add(layers.Dense(units=hidden_units_complex, activation='relu', \n",
    "                               kernel_regularizer=regularizers.l2(C_complex)))\n",
    "model_complex.add(layers.Dropout(dropout_ratio_complex))\n",
    "model_complex.add(layers.Dense(units=output_units, activation='softmax'))\n",
    "\n",
    "# Configure the model with optimizer, loss function and metrics.\n",
    "model_complex.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "# Check result.\n",
    "print(model_complex.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1db434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2700/2700 [==============================] - 1s 360us/sample - loss: 2.1051 - categorical_accuracy: 0.6996 - val_loss: 1.9007 - val_categorical_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 1.7894 - categorical_accuracy: 0.8315 - val_loss: 1.6477 - val_categorical_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 1.5657 - categorical_accuracy: 0.8441 - val_loss: 1.4574 - val_categorical_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 1.3873 - categorical_accuracy: 0.8507 - val_loss: 1.2953 - val_categorical_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 1.2343 - categorical_accuracy: 0.8485 - val_loss: 1.1579 - val_categorical_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 1.1067 - categorical_accuracy: 0.8511 - val_loss: 1.0411 - val_categorical_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.9967 - categorical_accuracy: 0.8504 - val_loss: 0.9434 - val_categorical_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.9030 - categorical_accuracy: 0.8507 - val_loss: 0.8570 - val_categorical_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.8294 - categorical_accuracy: 0.8533 - val_loss: 0.7812 - val_categorical_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.7479 - categorical_accuracy: 0.8556 - val_loss: 0.7154 - val_categorical_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.6953 - categorical_accuracy: 0.8585 - val_loss: 0.6512 - val_categorical_accuracy: 0.8433\n",
      "Epoch 12/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.6353 - categorical_accuracy: 0.8670 - val_loss: 0.5977 - val_categorical_accuracy: 0.8433\n",
      "Epoch 13/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.5824 - categorical_accuracy: 0.8689 - val_loss: 0.5534 - val_categorical_accuracy: 0.8567\n",
      "Epoch 14/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.5472 - categorical_accuracy: 0.8763 - val_loss: 0.5194 - val_categorical_accuracy: 0.8833\n",
      "Epoch 15/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.5066 - categorical_accuracy: 0.9011 - val_loss: 0.4888 - val_categorical_accuracy: 0.8833\n",
      "Epoch 16/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.4694 - categorical_accuracy: 0.9063 - val_loss: 0.4557 - val_categorical_accuracy: 0.8967\n",
      "Epoch 17/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.4368 - categorical_accuracy: 0.9226 - val_loss: 0.4278 - val_categorical_accuracy: 0.9233\n",
      "Epoch 18/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.4086 - categorical_accuracy: 0.9322 - val_loss: 0.4066 - val_categorical_accuracy: 0.9300\n",
      "Epoch 19/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3915 - categorical_accuracy: 0.9296 - val_loss: 0.3905 - val_categorical_accuracy: 0.9300\n",
      "Epoch 20/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3724 - categorical_accuracy: 0.9407 - val_loss: 0.3824 - val_categorical_accuracy: 0.9300\n",
      "Epoch 21/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.3555 - categorical_accuracy: 0.9452 - val_loss: 0.3669 - val_categorical_accuracy: 0.9367\n",
      "Epoch 22/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.3465 - categorical_accuracy: 0.9456 - val_loss: 0.3815 - val_categorical_accuracy: 0.9333\n",
      "Epoch 23/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3367 - categorical_accuracy: 0.9467 - val_loss: 0.3687 - val_categorical_accuracy: 0.9333\n",
      "Epoch 24/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3278 - categorical_accuracy: 0.9433 - val_loss: 0.3724 - val_categorical_accuracy: 0.9333\n",
      "Epoch 25/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.3120 - categorical_accuracy: 0.9511 - val_loss: 0.3676 - val_categorical_accuracy: 0.9300\n",
      "Epoch 26/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.3019 - categorical_accuracy: 0.9559 - val_loss: 0.3641 - val_categorical_accuracy: 0.9333\n",
      "Epoch 27/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2940 - categorical_accuracy: 0.9574 - val_loss: 0.3589 - val_categorical_accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2916 - categorical_accuracy: 0.9581 - val_loss: 0.3670 - val_categorical_accuracy: 0.9333\n",
      "Epoch 29/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2795 - categorical_accuracy: 0.9578 - val_loss: 0.3529 - val_categorical_accuracy: 0.9400\n",
      "Epoch 30/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2689 - categorical_accuracy: 0.9633 - val_loss: 0.3590 - val_categorical_accuracy: 0.9333\n",
      "Epoch 31/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2610 - categorical_accuracy: 0.9630 - val_loss: 0.3540 - val_categorical_accuracy: 0.9367\n",
      "Epoch 32/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2528 - categorical_accuracy: 0.9674 - val_loss: 0.3496 - val_categorical_accuracy: 0.9333\n",
      "Epoch 33/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2460 - categorical_accuracy: 0.9722 - val_loss: 0.3524 - val_categorical_accuracy: 0.9333\n",
      "Epoch 34/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2439 - categorical_accuracy: 0.9700 - val_loss: 0.3365 - val_categorical_accuracy: 0.9367\n",
      "Epoch 35/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2376 - categorical_accuracy: 0.9704 - val_loss: 0.3445 - val_categorical_accuracy: 0.9300\n",
      "Epoch 36/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2300 - categorical_accuracy: 0.9752 - val_loss: 0.3366 - val_categorical_accuracy: 0.9400\n",
      "Epoch 37/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2319 - categorical_accuracy: 0.9667 - val_loss: 0.3279 - val_categorical_accuracy: 0.9367\n",
      "Epoch 38/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2339 - categorical_accuracy: 0.9689 - val_loss: 0.3545 - val_categorical_accuracy: 0.9267\n",
      "Epoch 39/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2402 - categorical_accuracy: 0.9674 - val_loss: 0.3236 - val_categorical_accuracy: 0.9333\n",
      "Epoch 40/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2301 - categorical_accuracy: 0.9722 - val_loss: 0.3237 - val_categorical_accuracy: 0.9300\n",
      "Epoch 41/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2240 - categorical_accuracy: 0.9737 - val_loss: 0.3293 - val_categorical_accuracy: 0.9367\n",
      "Epoch 42/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2230 - categorical_accuracy: 0.9726 - val_loss: 0.3288 - val_categorical_accuracy: 0.9300\n",
      "Epoch 43/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2222 - categorical_accuracy: 0.9759 - val_loss: 0.3535 - val_categorical_accuracy: 0.9200\n",
      "Epoch 44/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2182 - categorical_accuracy: 0.9715 - val_loss: 0.3263 - val_categorical_accuracy: 0.9300\n",
      "Epoch 45/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2138 - categorical_accuracy: 0.9785 - val_loss: 0.3366 - val_categorical_accuracy: 0.9300\n",
      "Epoch 46/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2205 - categorical_accuracy: 0.9715 - val_loss: 0.3367 - val_categorical_accuracy: 0.9300\n",
      "Epoch 47/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2168 - categorical_accuracy: 0.9707 - val_loss: 0.3315 - val_categorical_accuracy: 0.9367\n",
      "Epoch 48/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2151 - categorical_accuracy: 0.9711 - val_loss: 0.3318 - val_categorical_accuracy: 0.9333\n",
      "Epoch 49/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2076 - categorical_accuracy: 0.9756 - val_loss: 0.3215 - val_categorical_accuracy: 0.9400\n",
      "Epoch 50/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2035 - categorical_accuracy: 0.9796 - val_loss: 0.3492 - val_categorical_accuracy: 0.9300\n",
      "Epoch 51/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1959 - categorical_accuracy: 0.9785 - val_loss: 0.3164 - val_categorical_accuracy: 0.9433\n",
      "Epoch 52/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2039 - categorical_accuracy: 0.9744 - val_loss: 0.3425 - val_categorical_accuracy: 0.9367\n",
      "Epoch 53/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.2016 - categorical_accuracy: 0.9774 - val_loss: 0.3500 - val_categorical_accuracy: 0.9333\n",
      "Epoch 54/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1994 - categorical_accuracy: 0.9767 - val_loss: 0.3382 - val_categorical_accuracy: 0.9333\n",
      "Epoch 55/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2004 - categorical_accuracy: 0.9774 - val_loss: 0.3558 - val_categorical_accuracy: 0.9267\n",
      "Epoch 56/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.2028 - categorical_accuracy: 0.9719 - val_loss: 0.3301 - val_categorical_accuracy: 0.9333\n",
      "Epoch 57/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1988 - categorical_accuracy: 0.9774 - val_loss: 0.3417 - val_categorical_accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.2019 - categorical_accuracy: 0.9770 - val_loss: 0.3450 - val_categorical_accuracy: 0.9300\n",
      "Epoch 59/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1949 - categorical_accuracy: 0.9800 - val_loss: 0.3477 - val_categorical_accuracy: 0.9300\n",
      "Epoch 60/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1959 - categorical_accuracy: 0.9781 - val_loss: 0.3632 - val_categorical_accuracy: 0.9333\n",
      "Epoch 61/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2015 - categorical_accuracy: 0.9778 - val_loss: 0.3571 - val_categorical_accuracy: 0.9333\n",
      "Epoch 62/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2059 - categorical_accuracy: 0.9719 - val_loss: 0.3589 - val_categorical_accuracy: 0.9300\n",
      "Epoch 63/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2052 - categorical_accuracy: 0.9748 - val_loss: 0.3316 - val_categorical_accuracy: 0.9300\n",
      "Epoch 64/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1950 - categorical_accuracy: 0.9781 - val_loss: 0.3421 - val_categorical_accuracy: 0.9267\n",
      "Epoch 65/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.2004 - categorical_accuracy: 0.9763 - val_loss: 0.3440 - val_categorical_accuracy: 0.9367\n",
      "Epoch 66/200\n",
      "2700/2700 [==============================] - ETA: 0s - loss: 0.2344 - categorical_accuracy: 0.97 - 0s 18us/sample - loss: 0.1931 - categorical_accuracy: 0.9793 - val_loss: 0.3435 - val_categorical_accuracy: 0.9333\n",
      "Epoch 67/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1871 - categorical_accuracy: 0.9800 - val_loss: 0.3407 - val_categorical_accuracy: 0.9300\n",
      "Epoch 68/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1839 - categorical_accuracy: 0.9822 - val_loss: 0.3326 - val_categorical_accuracy: 0.9300\n",
      "Epoch 69/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1861 - categorical_accuracy: 0.9819 - val_loss: 0.3417 - val_categorical_accuracy: 0.9367\n",
      "Epoch 70/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1879 - categorical_accuracy: 0.9796 - val_loss: 0.3291 - val_categorical_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1870 - categorical_accuracy: 0.9796 - val_loss: 0.3393 - val_categorical_accuracy: 0.9400\n",
      "Epoch 72/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1790 - categorical_accuracy: 0.9822 - val_loss: 0.3233 - val_categorical_accuracy: 0.9400\n",
      "Epoch 73/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1872 - categorical_accuracy: 0.9807 - val_loss: 0.3364 - val_categorical_accuracy: 0.9333\n",
      "Epoch 74/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1817 - categorical_accuracy: 0.9819 - val_loss: 0.3460 - val_categorical_accuracy: 0.9333\n",
      "Epoch 75/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1807 - categorical_accuracy: 0.9826 - val_loss: 0.3371 - val_categorical_accuracy: 0.9333\n",
      "Epoch 76/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1837 - categorical_accuracy: 0.9833 - val_loss: 0.3524 - val_categorical_accuracy: 0.9400\n",
      "Epoch 77/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1829 - categorical_accuracy: 0.9804 - val_loss: 0.3524 - val_categorical_accuracy: 0.9367\n",
      "Epoch 78/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1950 - categorical_accuracy: 0.9759 - val_loss: 0.3226 - val_categorical_accuracy: 0.9433\n",
      "Epoch 79/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1861 - categorical_accuracy: 0.9815 - val_loss: 0.3526 - val_categorical_accuracy: 0.9333\n",
      "Epoch 80/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1814 - categorical_accuracy: 0.9822 - val_loss: 0.3335 - val_categorical_accuracy: 0.9367\n",
      "Epoch 81/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1763 - categorical_accuracy: 0.9837 - val_loss: 0.3447 - val_categorical_accuracy: 0.9400\n",
      "Epoch 82/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1761 - categorical_accuracy: 0.9844 - val_loss: 0.3461 - val_categorical_accuracy: 0.9367\n",
      "Epoch 83/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1784 - categorical_accuracy: 0.9826 - val_loss: 0.3532 - val_categorical_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1797 - categorical_accuracy: 0.9819 - val_loss: 0.3353 - val_categorical_accuracy: 0.9400\n",
      "Epoch 85/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1799 - categorical_accuracy: 0.9830 - val_loss: 0.3379 - val_categorical_accuracy: 0.9367\n",
      "Epoch 86/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1725 - categorical_accuracy: 0.9848 - val_loss: 0.3341 - val_categorical_accuracy: 0.9400\n",
      "Epoch 87/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1769 - categorical_accuracy: 0.9807 - val_loss: 0.3556 - val_categorical_accuracy: 0.9333\n",
      "Epoch 88/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1770 - categorical_accuracy: 0.9826 - val_loss: 0.3175 - val_categorical_accuracy: 0.9433\n",
      "Epoch 89/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1789 - categorical_accuracy: 0.9863 - val_loss: 0.3354 - val_categorical_accuracy: 0.9367\n",
      "Epoch 90/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1769 - categorical_accuracy: 0.9830 - val_loss: 0.3425 - val_categorical_accuracy: 0.9367\n",
      "Epoch 91/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1758 - categorical_accuracy: 0.9848 - val_loss: 0.3571 - val_categorical_accuracy: 0.9333\n",
      "Epoch 92/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1757 - categorical_accuracy: 0.9811 - val_loss: 0.3618 - val_categorical_accuracy: 0.9300\n",
      "Epoch 93/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1832 - categorical_accuracy: 0.9804 - val_loss: 0.3556 - val_categorical_accuracy: 0.9267\n",
      "Epoch 94/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1669 - categorical_accuracy: 0.9878 - val_loss: 0.3560 - val_categorical_accuracy: 0.9300\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1742 - categorical_accuracy: 0.9833 - val_loss: 0.3345 - val_categorical_accuracy: 0.9333\n",
      "Epoch 96/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1733 - categorical_accuracy: 0.9841 - val_loss: 0.3683 - val_categorical_accuracy: 0.9267\n",
      "Epoch 97/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1755 - categorical_accuracy: 0.9822 - val_loss: 0.3206 - val_categorical_accuracy: 0.9367\n",
      "Epoch 98/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1782 - categorical_accuracy: 0.9796 - val_loss: 0.3338 - val_categorical_accuracy: 0.9400\n",
      "Epoch 99/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1736 - categorical_accuracy: 0.9833 - val_loss: 0.3382 - val_categorical_accuracy: 0.9333\n",
      "Epoch 100/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1699 - categorical_accuracy: 0.9819 - val_loss: 0.3319 - val_categorical_accuracy: 0.9400\n",
      "Epoch 101/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1722 - categorical_accuracy: 0.9804 - val_loss: 0.3161 - val_categorical_accuracy: 0.9400\n",
      "Epoch 102/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1653 - categorical_accuracy: 0.9841 - val_loss: 0.3377 - val_categorical_accuracy: 0.9333\n",
      "Epoch 103/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1640 - categorical_accuracy: 0.9867 - val_loss: 0.3372 - val_categorical_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1652 - categorical_accuracy: 0.9844 - val_loss: 0.3323 - val_categorical_accuracy: 0.9367\n",
      "Epoch 105/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1576 - categorical_accuracy: 0.9881 - val_loss: 0.3396 - val_categorical_accuracy: 0.9367\n",
      "Epoch 106/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1637 - categorical_accuracy: 0.9852 - val_loss: 0.3357 - val_categorical_accuracy: 0.9400\n",
      "Epoch 107/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1647 - categorical_accuracy: 0.9830 - val_loss: 0.3361 - val_categorical_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1769 - categorical_accuracy: 0.9819 - val_loss: 0.3282 - val_categorical_accuracy: 0.9333\n",
      "Epoch 109/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1924 - categorical_accuracy: 0.9685 - val_loss: 0.3609 - val_categorical_accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1824 - categorical_accuracy: 0.9756 - val_loss: 0.3295 - val_categorical_accuracy: 0.9367\n",
      "Epoch 111/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1747 - categorical_accuracy: 0.9807 - val_loss: 0.3217 - val_categorical_accuracy: 0.9467\n",
      "Epoch 112/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1857 - categorical_accuracy: 0.9796 - val_loss: 0.3545 - val_categorical_accuracy: 0.9467\n",
      "Epoch 113/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1877 - categorical_accuracy: 0.9770 - val_loss: 0.3538 - val_categorical_accuracy: 0.9500\n",
      "Epoch 114/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1811 - categorical_accuracy: 0.9830 - val_loss: 0.3352 - val_categorical_accuracy: 0.9500\n",
      "Epoch 115/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1757 - categorical_accuracy: 0.9815 - val_loss: 0.3556 - val_categorical_accuracy: 0.9367\n",
      "Epoch 116/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1745 - categorical_accuracy: 0.9848 - val_loss: 0.3327 - val_categorical_accuracy: 0.9400\n",
      "Epoch 117/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1747 - categorical_accuracy: 0.9800 - val_loss: 0.3427 - val_categorical_accuracy: 0.9400\n",
      "Epoch 118/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1692 - categorical_accuracy: 0.9852 - val_loss: 0.3345 - val_categorical_accuracy: 0.9367\n",
      "Epoch 119/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1649 - categorical_accuracy: 0.9885 - val_loss: 0.3465 - val_categorical_accuracy: 0.9300\n",
      "Epoch 120/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1672 - categorical_accuracy: 0.9852 - val_loss: 0.3596 - val_categorical_accuracy: 0.9333\n",
      "Epoch 121/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1668 - categorical_accuracy: 0.9844 - val_loss: 0.3424 - val_categorical_accuracy: 0.9333\n",
      "Epoch 122/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1656 - categorical_accuracy: 0.9859 - val_loss: 0.3326 - val_categorical_accuracy: 0.9300\n",
      "Epoch 123/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1665 - categorical_accuracy: 0.9844 - val_loss: 0.3601 - val_categorical_accuracy: 0.9367\n",
      "Epoch 124/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1685 - categorical_accuracy: 0.9852 - val_loss: 0.3488 - val_categorical_accuracy: 0.9333\n",
      "Epoch 125/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1675 - categorical_accuracy: 0.9826 - val_loss: 0.3601 - val_categorical_accuracy: 0.9367\n",
      "Epoch 126/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1644 - categorical_accuracy: 0.9841 - val_loss: 0.3460 - val_categorical_accuracy: 0.9433\n",
      "Epoch 127/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1634 - categorical_accuracy: 0.9841 - val_loss: 0.3296 - val_categorical_accuracy: 0.9433\n",
      "Epoch 128/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1582 - categorical_accuracy: 0.9859 - val_loss: 0.3423 - val_categorical_accuracy: 0.9400\n",
      "Epoch 129/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1540 - categorical_accuracy: 0.9885 - val_loss: 0.3533 - val_categorical_accuracy: 0.9367\n",
      "Epoch 130/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1561 - categorical_accuracy: 0.9856 - val_loss: 0.3390 - val_categorical_accuracy: 0.9433\n",
      "Epoch 131/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1641 - categorical_accuracy: 0.9815 - val_loss: 0.3538 - val_categorical_accuracy: 0.9400\n",
      "Epoch 132/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1682 - categorical_accuracy: 0.9841 - val_loss: 0.3347 - val_categorical_accuracy: 0.9367\n",
      "Epoch 133/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1586 - categorical_accuracy: 0.9874 - val_loss: 0.3445 - val_categorical_accuracy: 0.9300\n",
      "Epoch 134/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1568 - categorical_accuracy: 0.9874 - val_loss: 0.3349 - val_categorical_accuracy: 0.9400\n",
      "Epoch 135/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1521 - categorical_accuracy: 0.9911 - val_loss: 0.3284 - val_categorical_accuracy: 0.9333\n",
      "Epoch 136/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1528 - categorical_accuracy: 0.9874 - val_loss: 0.3295 - val_categorical_accuracy: 0.9333\n",
      "Epoch 137/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1547 - categorical_accuracy: 0.9844 - val_loss: 0.3565 - val_categorical_accuracy: 0.9233\n",
      "Epoch 138/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1549 - categorical_accuracy: 0.9863 - val_loss: 0.3219 - val_categorical_accuracy: 0.9433\n",
      "Epoch 139/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1500 - categorical_accuracy: 0.9889 - val_loss: 0.3288 - val_categorical_accuracy: 0.9433\n",
      "Epoch 140/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1501 - categorical_accuracy: 0.9878 - val_loss: 0.3410 - val_categorical_accuracy: 0.9300\n",
      "Epoch 141/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1581 - categorical_accuracy: 0.9833 - val_loss: 0.3461 - val_categorical_accuracy: 0.9300\n",
      "Epoch 142/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1476 - categorical_accuracy: 0.9911 - val_loss: 0.3525 - val_categorical_accuracy: 0.9233\n",
      "Epoch 143/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1461 - categorical_accuracy: 0.9878 - val_loss: 0.3218 - val_categorical_accuracy: 0.9367\n",
      "Epoch 144/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1518 - categorical_accuracy: 0.9878 - val_loss: 0.3252 - val_categorical_accuracy: 0.9400\n",
      "Epoch 145/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1528 - categorical_accuracy: 0.9870 - val_loss: 0.3408 - val_categorical_accuracy: 0.9267\n",
      "Epoch 146/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1524 - categorical_accuracy: 0.9852 - val_loss: 0.3488 - val_categorical_accuracy: 0.9267\n",
      "Epoch 147/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1525 - categorical_accuracy: 0.9856 - val_loss: 0.3122 - val_categorical_accuracy: 0.9333\n",
      "Epoch 148/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1553 - categorical_accuracy: 0.9844 - val_loss: 0.3434 - val_categorical_accuracy: 0.9367\n",
      "Epoch 149/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1494 - categorical_accuracy: 0.9885 - val_loss: 0.3265 - val_categorical_accuracy: 0.9333\n",
      "Epoch 150/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1620 - categorical_accuracy: 0.9811 - val_loss: 0.3141 - val_categorical_accuracy: 0.9400\n",
      "Epoch 151/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1587 - categorical_accuracy: 0.9807 - val_loss: 0.3299 - val_categorical_accuracy: 0.9400\n",
      "Epoch 152/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1956 - categorical_accuracy: 0.9681 - val_loss: 0.3440 - val_categorical_accuracy: 0.9233\n",
      "Epoch 153/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1832 - categorical_accuracy: 0.9756 - val_loss: 0.3410 - val_categorical_accuracy: 0.9333\n",
      "Epoch 154/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1770 - categorical_accuracy: 0.9793 - val_loss: 0.3133 - val_categorical_accuracy: 0.9400\n",
      "Epoch 155/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1707 - categorical_accuracy: 0.9830 - val_loss: 0.3589 - val_categorical_accuracy: 0.9267\n",
      "Epoch 156/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1616 - categorical_accuracy: 0.9852 - val_loss: 0.3235 - val_categorical_accuracy: 0.9400\n",
      "Epoch 157/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1552 - categorical_accuracy: 0.9881 - val_loss: 0.3692 - val_categorical_accuracy: 0.9200\n",
      "Epoch 158/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1571 - categorical_accuracy: 0.9856 - val_loss: 0.3403 - val_categorical_accuracy: 0.9333\n",
      "Epoch 159/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1568 - categorical_accuracy: 0.9852 - val_loss: 0.3417 - val_categorical_accuracy: 0.9333\n",
      "Epoch 160/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1637 - categorical_accuracy: 0.9837 - val_loss: 0.3709 - val_categorical_accuracy: 0.9333\n",
      "Epoch 161/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1583 - categorical_accuracy: 0.9852 - val_loss: 0.3533 - val_categorical_accuracy: 0.9367\n",
      "Epoch 162/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1527 - categorical_accuracy: 0.9881 - val_loss: 0.3314 - val_categorical_accuracy: 0.9367\n",
      "Epoch 163/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1485 - categorical_accuracy: 0.9859 - val_loss: 0.3365 - val_categorical_accuracy: 0.9333\n",
      "Epoch 164/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1527 - categorical_accuracy: 0.9833 - val_loss: 0.3481 - val_categorical_accuracy: 0.9267\n",
      "Epoch 165/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1454 - categorical_accuracy: 0.9930 - val_loss: 0.3290 - val_categorical_accuracy: 0.9300\n",
      "Epoch 166/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1512 - categorical_accuracy: 0.9874 - val_loss: 0.3459 - val_categorical_accuracy: 0.9333\n",
      "Epoch 167/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1451 - categorical_accuracy: 0.9896 - val_loss: 0.3488 - val_categorical_accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1453 - categorical_accuracy: 0.9896 - val_loss: 0.3289 - val_categorical_accuracy: 0.9333\n",
      "Epoch 169/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1520 - categorical_accuracy: 0.9859 - val_loss: 0.3427 - val_categorical_accuracy: 0.9300\n",
      "Epoch 170/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1542 - categorical_accuracy: 0.9863 - val_loss: 0.3409 - val_categorical_accuracy: 0.9333\n",
      "Epoch 171/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1489 - categorical_accuracy: 0.9874 - val_loss: 0.3645 - val_categorical_accuracy: 0.9333\n",
      "Epoch 172/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1534 - categorical_accuracy: 0.9848 - val_loss: 0.3432 - val_categorical_accuracy: 0.9300\n",
      "Epoch 173/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1543 - categorical_accuracy: 0.9841 - val_loss: 0.3303 - val_categorical_accuracy: 0.9400\n",
      "Epoch 174/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1481 - categorical_accuracy: 0.9870 - val_loss: 0.3160 - val_categorical_accuracy: 0.9400\n",
      "Epoch 175/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1506 - categorical_accuracy: 0.9863 - val_loss: 0.3127 - val_categorical_accuracy: 0.9300\n",
      "Epoch 176/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1422 - categorical_accuracy: 0.9941 - val_loss: 0.3192 - val_categorical_accuracy: 0.9333\n",
      "Epoch 177/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1469 - categorical_accuracy: 0.9874 - val_loss: 0.3182 - val_categorical_accuracy: 0.9333\n",
      "Epoch 178/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1523 - categorical_accuracy: 0.9859 - val_loss: 0.3468 - val_categorical_accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1528 - categorical_accuracy: 0.9833 - val_loss: 0.3501 - val_categorical_accuracy: 0.9433\n",
      "Epoch 180/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1528 - categorical_accuracy: 0.9867 - val_loss: 0.3844 - val_categorical_accuracy: 0.9267\n",
      "Epoch 181/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1447 - categorical_accuracy: 0.9911 - val_loss: 0.3561 - val_categorical_accuracy: 0.9300\n",
      "Epoch 182/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1492 - categorical_accuracy: 0.9844 - val_loss: 0.3399 - val_categorical_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1461 - categorical_accuracy: 0.9896 - val_loss: 0.3434 - val_categorical_accuracy: 0.9333\n",
      "Epoch 184/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1478 - categorical_accuracy: 0.9870 - val_loss: 0.3546 - val_categorical_accuracy: 0.9300\n",
      "Epoch 185/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1528 - categorical_accuracy: 0.9863 - val_loss: 0.3691 - val_categorical_accuracy: 0.9300\n",
      "Epoch 186/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1502 - categorical_accuracy: 0.9848 - val_loss: 0.3386 - val_categorical_accuracy: 0.9300\n",
      "Epoch 187/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1438 - categorical_accuracy: 0.9893 - val_loss: 0.3251 - val_categorical_accuracy: 0.9367\n",
      "Epoch 188/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1502 - categorical_accuracy: 0.9859 - val_loss: 0.3320 - val_categorical_accuracy: 0.9367\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1454 - categorical_accuracy: 0.9856 - val_loss: 0.3265 - val_categorical_accuracy: 0.9400\n",
      "Epoch 190/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1471 - categorical_accuracy: 0.9878 - val_loss: 0.3285 - val_categorical_accuracy: 0.9367\n",
      "Epoch 191/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1477 - categorical_accuracy: 0.9841 - val_loss: 0.3225 - val_categorical_accuracy: 0.9333\n",
      "Epoch 192/200\n",
      "2700/2700 [==============================] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 1.00 - 0s 18us/sample - loss: 0.1424 - categorical_accuracy: 0.9907 - val_loss: 0.3175 - val_categorical_accuracy: 0.9400\n",
      "Epoch 193/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1567 - categorical_accuracy: 0.9852 - val_loss: 0.3042 - val_categorical_accuracy: 0.9367\n",
      "Epoch 194/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1672 - categorical_accuracy: 0.9781 - val_loss: 0.2986 - val_categorical_accuracy: 0.9400\n",
      "Epoch 195/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1673 - categorical_accuracy: 0.9811 - val_loss: 0.2880 - val_categorical_accuracy: 0.9467\n",
      "Epoch 196/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1684 - categorical_accuracy: 0.9811 - val_loss: 0.2916 - val_categorical_accuracy: 0.9567\n",
      "Epoch 197/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1544 - categorical_accuracy: 0.9848 - val_loss: 0.3159 - val_categorical_accuracy: 0.9433\n",
      "Epoch 198/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1553 - categorical_accuracy: 0.9870 - val_loss: 0.3064 - val_categorical_accuracy: 0.9433\n",
      "Epoch 199/200\n",
      "2700/2700 [==============================] - 0s 18us/sample - loss: 0.1465 - categorical_accuracy: 0.9904 - val_loss: 0.3121 - val_categorical_accuracy: 0.9433\n",
      "Epoch 200/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1490 - categorical_accuracy: 0.9867 - val_loss: 0.2980 - val_categorical_accuracy: 0.9467\n"
     ]
    }
   ],
   "source": [
    "#  Train the model and evaluate with the validation set in every epoch.\n",
    "history_complex = model_complex.fit(X_train,\n",
    "                                    y_train,\n",
    "                                    epochs=epochs_complex,\n",
    "                                    batch_size=batch_size_complex,\n",
    "                                    validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ded88e",
   "metadata": {},
   "source": [
    "### Model validation\n",
    "**Evaluate the model per validation set by checking accuracy score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f6e15a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 41us/sample - loss: 0.2980 - categorical_accuracy: 0.9467\n",
      "[0.297995086312294, 0.94666666]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot traing loss and validation loss\n",
    "plot_loss(history_complex)\n",
    "\n",
    "# Evaluate model by using validation set.\n",
    "print(model_complex.evaluate(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffabbb77",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter tuning: GridsearchCV \n",
    "**Let's also try to tune the hyperparameters of neural network with help of GridsearchCV(). We tune number of hidden units, dropout ratio and regularization parameter here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad982f",
   "metadata": {},
   "source": [
    "### Implement GrisearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36143246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1dfa9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to build and compile model with genreal number of hidden units, drop out ratio and regularzation parameter  \n",
    "def create_model(hidden_units=16, dropout_ratio=0.2, C=0.02):\n",
    "    # Create the model.\n",
    "    model = models.Sequential()    \n",
    "    model.add(layers.Dense(units=hidden_units, activation='relu', \n",
    "                           kernel_regularizer=regularizers.l2(C), input_shape=[input_units]))\n",
    "    model.add(layers.Dropout(dropout_ratio))\n",
    "    model.add(layers.Dense(units=hidden_units, activation='relu', \n",
    "                           kernel_regularizer=regularizers.l2(C)))\n",
    "    model.add(layers.Dropout(dropout_ratio))\n",
    "    model.add(layers.Dense(units=hidden_units, activation='relu', \n",
    "                           kernel_regularizer=regularizers.l2(C)))\n",
    "    model.add(layers.Dropout(dropout_ratio))\n",
    "    model.add(layers.Dense(units=hidden_units, activation='relu', \n",
    "                           kernel_regularizer=regularizers.l2(C)))\n",
    "    model.add(layers.Dropout(dropout_ratio))\n",
    "    model.add(layers.Dense(units=output_units, activation='softmax'))\n",
    "\n",
    "    # Configure the model with optimizer, loss function and metrics.\n",
    "    model.compile(optimizer=optimizers.Adam(),\n",
    "                  loss=losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a model wrapper with help of KerasClassifier().\n",
    "model_grid = KerasClassifier(build_fn=create_model, epochs=200,batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4adfae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary called param_grid and fill out some parameters for hidden units, C and dropout ratio.\n",
    "hidden_units_grid = [16,32]\n",
    "C_grid = [0.02,0.2]\n",
    "dropout_ratio_grid = [0.2,0.5]\n",
    "\n",
    "param_grid = dict(hidden_units=hidden_units_grid,\n",
    "                  C=C_grid,\n",
    "                  dropout_ratio=dropout_ratio_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fefdf88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 316us/sample - loss: 2.2218 - accuracy: 0.5745 - val_loss: 1.9398 - val_accuracy: 0.7967\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8964 - accuracy: 0.7676 - val_loss: 1.7503 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.7202 - accuracy: 0.8236 - val_loss: 1.5926 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.5531 - accuracy: 0.8366 - val_loss: 1.4545 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4247 - accuracy: 0.8486 - val_loss: 1.3323 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3005 - accuracy: 0.8481 - val_loss: 1.2258 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1967 - accuracy: 0.8481 - val_loss: 1.1305 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0945 - accuracy: 0.8532 - val_loss: 1.0448 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.0182 - accuracy: 0.8509 - val_loss: 0.9678 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9344 - accuracy: 0.8509 - val_loss: 0.9013 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8750 - accuracy: 0.8537 - val_loss: 0.8378 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8137 - accuracy: 0.8532 - val_loss: 0.7816 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7625 - accuracy: 0.8569 - val_loss: 0.7316 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7206 - accuracy: 0.8556 - val_loss: 0.6849 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6674 - accuracy: 0.8606 - val_loss: 0.6438 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.84 - 0s 21us/sample - loss: 0.6202 - accuracy: 0.8606 - val_loss: 0.6072 - val_accuracy: 0.8500\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5925 - accuracy: 0.8722 - val_loss: 0.5746 - val_accuracy: 0.8500\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.5632 - accuracy: 0.8787 - val_loss: 0.5454 - val_accuracy: 0.8600\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.5266 - accuracy: 0.8810 - val_loss: 0.5169 - val_accuracy: 0.8667\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5078 - accuracy: 0.8884 - val_loss: 0.4982 - val_accuracy: 0.8700\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4780 - accuracy: 0.8954 - val_loss: 0.4827 - val_accuracy: 0.8900\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4510 - accuracy: 0.9093 - val_loss: 0.4707 - val_accuracy: 0.9000\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4310 - accuracy: 0.9148 - val_loss: 0.4461 - val_accuracy: 0.9000\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4156 - accuracy: 0.9176 - val_loss: 0.4386 - val_accuracy: 0.9133\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3840 - accuracy: 0.9315 - val_loss: 0.4282 - val_accuracy: 0.9167\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3765 - accuracy: 0.9356 - val_loss: 0.4137 - val_accuracy: 0.9333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3561 - accuracy: 0.9426 - val_loss: 0.4037 - val_accuracy: 0.9200\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3424 - accuracy: 0.9463 - val_loss: 0.3995 - val_accuracy: 0.9267\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3254 - accuracy: 0.9546 - val_loss: 0.3870 - val_accuracy: 0.9233\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3171 - accuracy: 0.9532 - val_loss: 0.3860 - val_accuracy: 0.9333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3101 - accuracy: 0.9574 - val_loss: 0.3828 - val_accuracy: 0.9367\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2951 - accuracy: 0.9630 - val_loss: 0.3836 - val_accuracy: 0.9367\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2829 - accuracy: 0.9671 - val_loss: 0.3807 - val_accuracy: 0.9333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2825 - accuracy: 0.9648 - val_loss: 0.3786 - val_accuracy: 0.9367\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2712 - accuracy: 0.9694 - val_loss: 0.3773 - val_accuracy: 0.9300\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2743 - accuracy: 0.9644 - val_loss: 0.3765 - val_accuracy: 0.9267\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2633 - accuracy: 0.9681 - val_loss: 0.3726 - val_accuracy: 0.9267\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2558 - accuracy: 0.9727 - val_loss: 0.3654 - val_accuracy: 0.9333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2540 - accuracy: 0.9713 - val_loss: 0.3906 - val_accuracy: 0.9333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2446 - accuracy: 0.9736 - val_loss: 0.3718 - val_accuracy: 0.9333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2461 - accuracy: 0.9722 - val_loss: 0.3690 - val_accuracy: 0.9300\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2411 - accuracy: 0.9694 - val_loss: 0.3589 - val_accuracy: 0.9267\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2358 - accuracy: 0.9769 - val_loss: 0.3550 - val_accuracy: 0.9233\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2414 - accuracy: 0.9704 - val_loss: 0.3597 - val_accuracy: 0.9200\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2397 - accuracy: 0.9713 - val_loss: 0.3756 - val_accuracy: 0.9267\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2311 - accuracy: 0.9731 - val_loss: 0.3684 - val_accuracy: 0.9233\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2254 - accuracy: 0.9764 - val_loss: 0.3559 - val_accuracy: 0.9233\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2249 - accuracy: 0.9708 - val_loss: 0.3496 - val_accuracy: 0.9267\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2228 - accuracy: 0.9792 - val_loss: 0.3506 - val_accuracy: 0.9367\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2149 - accuracy: 0.9806 - val_loss: 0.3600 - val_accuracy: 0.9267\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2176 - accuracy: 0.9778 - val_loss: 0.3747 - val_accuracy: 0.9300\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2153 - accuracy: 0.9764 - val_loss: 0.3492 - val_accuracy: 0.9200\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2100 - accuracy: 0.9787 - val_loss: 0.3610 - val_accuracy: 0.9200\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2092 - accuracy: 0.9796 - val_loss: 0.3637 - val_accuracy: 0.9233\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2049 - accuracy: 0.9810 - val_loss: 0.3756 - val_accuracy: 0.9200\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1979 - accuracy: 0.9819 - val_loss: 0.3659 - val_accuracy: 0.9200\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2021 - accuracy: 0.9801 - val_loss: 0.3691 - val_accuracy: 0.9233\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2021 - accuracy: 0.9787 - val_loss: 0.3634 - val_accuracy: 0.9233\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1998 - accuracy: 0.9750 - val_loss: 0.3752 - val_accuracy: 0.9167\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1960 - accuracy: 0.9796 - val_loss: 0.3746 - val_accuracy: 0.9300\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1978 - accuracy: 0.9801 - val_loss: 0.3526 - val_accuracy: 0.9167\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1978 - accuracy: 0.9773 - val_loss: 0.3695 - val_accuracy: 0.9267\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1909 - accuracy: 0.9819 - val_loss: 0.3623 - val_accuracy: 0.9267\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1998 - accuracy: 0.9755 - val_loss: 0.3785 - val_accuracy: 0.9233\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1960 - accuracy: 0.9787 - val_loss: 0.3564 - val_accuracy: 0.9300\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1964 - accuracy: 0.9769 - val_loss: 0.3686 - val_accuracy: 0.9267\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1899 - accuracy: 0.9838 - val_loss: 0.3661 - val_accuracy: 0.9267\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1915 - accuracy: 0.9796 - val_loss: 0.3704 - val_accuracy: 0.9267\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1905 - accuracy: 0.9773 - val_loss: 0.3349 - val_accuracy: 0.9367\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1862 - accuracy: 0.9829 - val_loss: 0.3366 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1864 - accuracy: 0.9829 - val_loss: 0.3398 - val_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1884 - accuracy: 0.9782 - val_loss: 0.3457 - val_accuracy: 0.9300\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1783 - accuracy: 0.9866 - val_loss: 0.3615 - val_accuracy: 0.9333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1892 - accuracy: 0.9787 - val_loss: 0.3442 - val_accuracy: 0.9300\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1878 - accuracy: 0.9792 - val_loss: 0.3573 - val_accuracy: 0.9333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1869 - accuracy: 0.9833 - val_loss: 0.3505 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1802 - accuracy: 0.9847 - val_loss: 0.3542 - val_accuracy: 0.9333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1909 - accuracy: 0.9815 - val_loss: 0.3309 - val_accuracy: 0.9333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1850 - accuracy: 0.9824 - val_loss: 0.3648 - val_accuracy: 0.9333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1777 - accuracy: 0.9810 - val_loss: 0.3508 - val_accuracy: 0.9300\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1758 - accuracy: 0.9852 - val_loss: 0.3580 - val_accuracy: 0.9333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1784 - accuracy: 0.9843 - val_loss: 0.3536 - val_accuracy: 0.9300\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1791 - accuracy: 0.9824 - val_loss: 0.3697 - val_accuracy: 0.9267\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1779 - accuracy: 0.9819 - val_loss: 0.3404 - val_accuracy: 0.9300\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1800 - accuracy: 0.9773 - val_loss: 0.3343 - val_accuracy: 0.9333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1737 - accuracy: 0.9838 - val_loss: 0.3375 - val_accuracy: 0.9367\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1698 - accuracy: 0.9847 - val_loss: 0.3422 - val_accuracy: 0.9300\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1767 - accuracy: 0.9815 - val_loss: 0.3484 - val_accuracy: 0.9333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1714 - accuracy: 0.9852 - val_loss: 0.3603 - val_accuracy: 0.9333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1697 - accuracy: 0.9847 - val_loss: 0.3570 - val_accuracy: 0.9367\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1713 - accuracy: 0.9861 - val_loss: 0.3425 - val_accuracy: 0.9333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1711 - accuracy: 0.9843 - val_loss: 0.3504 - val_accuracy: 0.9300\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1685 - accuracy: 0.9856 - val_loss: 0.3649 - val_accuracy: 0.9300\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1697 - accuracy: 0.9852 - val_loss: 0.3567 - val_accuracy: 0.9367\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1653 - accuracy: 0.9875 - val_loss: 0.3853 - val_accuracy: 0.9300\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1735 - accuracy: 0.9819 - val_loss: 0.3768 - val_accuracy: 0.9300\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1748 - accuracy: 0.9856 - val_loss: 0.3763 - val_accuracy: 0.9333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1697 - accuracy: 0.9819 - val_loss: 0.3305 - val_accuracy: 0.9367\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1688 - accuracy: 0.9833 - val_loss: 0.3545 - val_accuracy: 0.9300\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1649 - accuracy: 0.9866 - val_loss: 0.3365 - val_accuracy: 0.9267\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1685 - accuracy: 0.9819 - val_loss: 0.3582 - val_accuracy: 0.9300\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1663 - accuracy: 0.9806 - val_loss: 0.3555 - val_accuracy: 0.9300\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1707 - accuracy: 0.9801 - val_loss: 0.3364 - val_accuracy: 0.9400\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1654 - accuracy: 0.9856 - val_loss: 0.3444 - val_accuracy: 0.9333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1643 - accuracy: 0.9838 - val_loss: 0.3566 - val_accuracy: 0.9333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1697 - accuracy: 0.9819 - val_loss: 0.3477 - val_accuracy: 0.9367\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.99 - 0s 21us/sample - loss: 0.1662 - accuracy: 0.9838 - val_loss: 0.3691 - val_accuracy: 0.9233\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1623 - accuracy: 0.9870 - val_loss: 0.3521 - val_accuracy: 0.9300\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1642 - accuracy: 0.9833 - val_loss: 0.3507 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1620 - accuracy: 0.9829 - val_loss: 0.3693 - val_accuracy: 0.9300\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1631 - accuracy: 0.9861 - val_loss: 0.3657 - val_accuracy: 0.9267\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1684 - accuracy: 0.9819 - val_loss: 0.3724 - val_accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1680 - accuracy: 0.9838 - val_loss: 0.3786 - val_accuracy: 0.9333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1626 - accuracy: 0.9852 - val_loss: 0.3714 - val_accuracy: 0.9267\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1607 - accuracy: 0.9838 - val_loss: 0.3554 - val_accuracy: 0.9300\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1605 - accuracy: 0.9875 - val_loss: 0.3679 - val_accuracy: 0.9300\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1571 - accuracy: 0.9880 - val_loss: 0.3811 - val_accuracy: 0.9267\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1522 - accuracy: 0.9903 - val_loss: 0.3827 - val_accuracy: 0.9300\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1586 - accuracy: 0.9870 - val_loss: 0.3814 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1601 - accuracy: 0.9866 - val_loss: 0.3734 - val_accuracy: 0.9300\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1557 - accuracy: 0.9870 - val_loss: 0.3691 - val_accuracy: 0.9300\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1586 - accuracy: 0.9861 - val_loss: 0.3543 - val_accuracy: 0.9367\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1588 - accuracy: 0.9856 - val_loss: 0.3573 - val_accuracy: 0.9367\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1579 - accuracy: 0.9875 - val_loss: 0.3550 - val_accuracy: 0.9333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1578 - accuracy: 0.9861 - val_loss: 0.3758 - val_accuracy: 0.9333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1654 - accuracy: 0.9852 - val_loss: 0.3561 - val_accuracy: 0.9333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1573 - accuracy: 0.9894 - val_loss: 0.3549 - val_accuracy: 0.9333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1577 - accuracy: 0.9852 - val_loss: 0.3644 - val_accuracy: 0.9333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1554 - accuracy: 0.9884 - val_loss: 0.3683 - val_accuracy: 0.9300\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1593 - accuracy: 0.9852 - val_loss: 0.3535 - val_accuracy: 0.9333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1568 - accuracy: 0.9852 - val_loss: 0.3729 - val_accuracy: 0.9300\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1630 - accuracy: 0.9838 - val_loss: 0.3372 - val_accuracy: 0.9300\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1631 - accuracy: 0.9838 - val_loss: 0.3206 - val_accuracy: 0.9333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1670 - accuracy: 0.9806 - val_loss: 0.3595 - val_accuracy: 0.9233\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1661 - accuracy: 0.9824 - val_loss: 0.3278 - val_accuracy: 0.9267\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1593 - accuracy: 0.9847 - val_loss: 0.3745 - val_accuracy: 0.9300\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1651 - accuracy: 0.9838 - val_loss: 0.3654 - val_accuracy: 0.9300\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1580 - accuracy: 0.9847 - val_loss: 0.3626 - val_accuracy: 0.9300\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1575 - accuracy: 0.9852 - val_loss: 0.3595 - val_accuracy: 0.9267\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1510 - accuracy: 0.9875 - val_loss: 0.3770 - val_accuracy: 0.9300\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1566 - accuracy: 0.9870 - val_loss: 0.3704 - val_accuracy: 0.9300\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1568 - accuracy: 0.9852 - val_loss: 0.3497 - val_accuracy: 0.9300\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1550 - accuracy: 0.9833 - val_loss: 0.3461 - val_accuracy: 0.9267\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1512 - accuracy: 0.9875 - val_loss: 0.3548 - val_accuracy: 0.9367\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1499 - accuracy: 0.9875 - val_loss: 0.3578 - val_accuracy: 0.9333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1539 - accuracy: 0.9861 - val_loss: 0.3512 - val_accuracy: 0.9333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1521 - accuracy: 0.9880 - val_loss: 0.3711 - val_accuracy: 0.9300\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1512 - accuracy: 0.9866 - val_loss: 0.3540 - val_accuracy: 0.9333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1573 - accuracy: 0.9843 - val_loss: 0.3549 - val_accuracy: 0.9333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1572 - accuracy: 0.9847 - val_loss: 0.3481 - val_accuracy: 0.9333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1551 - accuracy: 0.9833 - val_loss: 0.3361 - val_accuracy: 0.9433\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1486 - accuracy: 0.9856 - val_loss: 0.3648 - val_accuracy: 0.9333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1550 - accuracy: 0.9801 - val_loss: 0.3440 - val_accuracy: 0.9367\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1576 - accuracy: 0.9801 - val_loss: 0.3976 - val_accuracy: 0.9267\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1451 - accuracy: 0.9907 - val_loss: 0.3498 - val_accuracy: 0.9367\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1574 - accuracy: 0.9856 - val_loss: 0.3699 - val_accuracy: 0.9333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1491 - accuracy: 0.9880 - val_loss: 0.3744 - val_accuracy: 0.9300\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1519 - accuracy: 0.9829 - val_loss: 0.3636 - val_accuracy: 0.9333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1526 - accuracy: 0.9838 - val_loss: 0.3505 - val_accuracy: 0.9300\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1494 - accuracy: 0.9870 - val_loss: 0.3681 - val_accuracy: 0.9300\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1503 - accuracy: 0.9894 - val_loss: 0.3870 - val_accuracy: 0.9267\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1482 - accuracy: 0.9866 - val_loss: 0.3834 - val_accuracy: 0.9300\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1478 - accuracy: 0.9884 - val_loss: 0.3811 - val_accuracy: 0.9267\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1489 - accuracy: 0.9843 - val_loss: 0.3764 - val_accuracy: 0.9233\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1565 - accuracy: 0.9815 - val_loss: 0.3766 - val_accuracy: 0.9333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1579 - accuracy: 0.9829 - val_loss: 0.3554 - val_accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1478 - accuracy: 0.9884 - val_loss: 0.3825 - val_accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1516 - accuracy: 0.9856 - val_loss: 0.3651 - val_accuracy: 0.9200\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1456 - accuracy: 0.9880 - val_loss: 0.3807 - val_accuracy: 0.9200\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1430 - accuracy: 0.9903 - val_loss: 0.3754 - val_accuracy: 0.9300\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1458 - accuracy: 0.9856 - val_loss: 0.3570 - val_accuracy: 0.9333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1446 - accuracy: 0.9861 - val_loss: 0.3705 - val_accuracy: 0.9367\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1452 - accuracy: 0.9884 - val_loss: 0.3648 - val_accuracy: 0.9367\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1514 - accuracy: 0.9824 - val_loss: 0.3338 - val_accuracy: 0.9333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1505 - accuracy: 0.9829 - val_loss: 0.3886 - val_accuracy: 0.9367\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1505 - accuracy: 0.9861 - val_loss: 0.3737 - val_accuracy: 0.9367\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1506 - accuracy: 0.9847 - val_loss: 0.3515 - val_accuracy: 0.9367\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1445 - accuracy: 0.9866 - val_loss: 0.3704 - val_accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1511 - accuracy: 0.9833 - val_loss: 0.3555 - val_accuracy: 0.9400\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1520 - accuracy: 0.9861 - val_loss: 0.3748 - val_accuracy: 0.9367\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1507 - accuracy: 0.9870 - val_loss: 0.3785 - val_accuracy: 0.9367\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1486 - accuracy: 0.9866 - val_loss: 0.3600 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1491 - accuracy: 0.9889 - val_loss: 0.3824 - val_accuracy: 0.9367\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1477 - accuracy: 0.9875 - val_loss: 0.3321 - val_accuracy: 0.9267\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1455 - accuracy: 0.9875 - val_loss: 0.3573 - val_accuracy: 0.9333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1478 - accuracy: 0.9843 - val_loss: 0.3691 - val_accuracy: 0.9333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1468 - accuracy: 0.9856 - val_loss: 0.3847 - val_accuracy: 0.9300\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1466 - accuracy: 0.9870 - val_loss: 0.3580 - val_accuracy: 0.9333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1444 - accuracy: 0.9884 - val_loss: 0.3787 - val_accuracy: 0.9267\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1545 - accuracy: 0.9833 - val_loss: 0.3528 - val_accuracy: 0.9333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1449 - accuracy: 0.9875 - val_loss: 0.3851 - val_accuracy: 0.9267\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1438 - accuracy: 0.9894 - val_loss: 0.3695 - val_accuracy: 0.9300\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1491 - accuracy: 0.9861 - val_loss: 0.3436 - val_accuracy: 0.9333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1402 - accuracy: 0.9894 - val_loss: 0.3696 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1437 - accuracy: 0.9870 - val_loss: 0.3540 - val_accuracy: 0.9333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1410 - accuracy: 0.9875 - val_loss: 0.3492 - val_accuracy: 0.9300\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1496 - accuracy: 0.9856 - val_loss: 0.3670 - val_accuracy: 0.9300\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1398 - accuracy: 0.9894 - val_loss: 0.3283 - val_accuracy: 0.9333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1428 - accuracy: 0.9870 - val_loss: 0.3282 - val_accuracy: 0.9400\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1468 - accuracy: 0.9847 - val_loss: 0.3255 - val_accuracy: 0.9400\n",
      "540/540 [==============================] - 0s 229us/sample - loss: 0.2784 - accuracy: 0.9481\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 324us/sample - loss: 2.1330 - accuracy: 0.7106 - val_loss: 1.9200 - val_accuracy: 0.8367\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8798 - accuracy: 0.8194 - val_loss: 1.7324 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6952 - accuracy: 0.8292 - val_loss: 1.5698 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.5354 - accuracy: 0.8500 - val_loss: 1.4277 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.3948 - accuracy: 0.8412 - val_loss: 1.3020 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2868 - accuracy: 0.8505 - val_loss: 1.1889 - val_accuracy: 0.8300\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.1705 - accuracy: 0.8528 - val_loss: 1.0870 - val_accuracy: 0.8300\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.0801 - accuracy: 0.8532 - val_loss: 0.9996 - val_accuracy: 0.8300\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.9957 - accuracy: 0.8532 - val_loss: 0.9233 - val_accuracy: 0.8300\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9244 - accuracy: 0.8532 - val_loss: 0.8570 - val_accuracy: 0.8300\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8570 - accuracy: 0.8565 - val_loss: 0.7992 - val_accuracy: 0.8467\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7958 - accuracy: 0.8616 - val_loss: 0.7464 - val_accuracy: 0.8467\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7431 - accuracy: 0.8644 - val_loss: 0.6971 - val_accuracy: 0.8500\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6971 - accuracy: 0.8602 - val_loss: 0.6523 - val_accuracy: 0.8667\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6466 - accuracy: 0.8704 - val_loss: 0.6124 - val_accuracy: 0.8667\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6102 - accuracy: 0.8713 - val_loss: 0.5754 - val_accuracy: 0.8700\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5748 - accuracy: 0.8736 - val_loss: 0.5419 - val_accuracy: 0.8833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5447 - accuracy: 0.8833 - val_loss: 0.5142 - val_accuracy: 0.8933\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5156 - accuracy: 0.8912 - val_loss: 0.4930 - val_accuracy: 0.9033\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4923 - accuracy: 0.8949 - val_loss: 0.4751 - val_accuracy: 0.9033\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4673 - accuracy: 0.9037 - val_loss: 0.4554 - val_accuracy: 0.9133\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4488 - accuracy: 0.9083 - val_loss: 0.4362 - val_accuracy: 0.9233\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4212 - accuracy: 0.9144 - val_loss: 0.4246 - val_accuracy: 0.9100\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4057 - accuracy: 0.9264 - val_loss: 0.4047 - val_accuracy: 0.9200\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3826 - accuracy: 0.9287 - val_loss: 0.3939 - val_accuracy: 0.9300\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3673 - accuracy: 0.9343 - val_loss: 0.3838 - val_accuracy: 0.9267\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3640 - accuracy: 0.9352 - val_loss: 0.3723 - val_accuracy: 0.9267\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3397 - accuracy: 0.9463 - val_loss: 0.3662 - val_accuracy: 0.9367\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3232 - accuracy: 0.9574 - val_loss: 0.3597 - val_accuracy: 0.9333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3209 - accuracy: 0.9505 - val_loss: 0.3660 - val_accuracy: 0.9400\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3145 - accuracy: 0.9519 - val_loss: 0.3397 - val_accuracy: 0.9400\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3070 - accuracy: 0.9551 - val_loss: 0.3314 - val_accuracy: 0.9333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2935 - accuracy: 0.9616 - val_loss: 0.3437 - val_accuracy: 0.9400\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2834 - accuracy: 0.9593 - val_loss: 0.3432 - val_accuracy: 0.9367\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2838 - accuracy: 0.9611 - val_loss: 0.3384 - val_accuracy: 0.9367\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2717 - accuracy: 0.9634 - val_loss: 0.3297 - val_accuracy: 0.9367\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2622 - accuracy: 0.9676 - val_loss: 0.3124 - val_accuracy: 0.9400\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2599 - accuracy: 0.9657 - val_loss: 0.3120 - val_accuracy: 0.9400\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2521 - accuracy: 0.9708 - val_loss: 0.3104 - val_accuracy: 0.9400\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2527 - accuracy: 0.9704 - val_loss: 0.3278 - val_accuracy: 0.9367\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2521 - accuracy: 0.9653 - val_loss: 0.3000 - val_accuracy: 0.9400\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2544 - accuracy: 0.9699 - val_loss: 0.3233 - val_accuracy: 0.9400\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2386 - accuracy: 0.9750 - val_loss: 0.3228 - val_accuracy: 0.9400\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2383 - accuracy: 0.9755 - val_loss: 0.3168 - val_accuracy: 0.9433\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2313 - accuracy: 0.9769 - val_loss: 0.3049 - val_accuracy: 0.9433\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2292 - accuracy: 0.9769 - val_loss: 0.3125 - val_accuracy: 0.9400\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2302 - accuracy: 0.9722 - val_loss: 0.3084 - val_accuracy: 0.9400\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2236 - accuracy: 0.9759 - val_loss: 0.3082 - val_accuracy: 0.9333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2264 - accuracy: 0.9750 - val_loss: 0.2874 - val_accuracy: 0.9467\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2156 - accuracy: 0.9801 - val_loss: 0.2904 - val_accuracy: 0.9500\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2218 - accuracy: 0.9736 - val_loss: 0.3102 - val_accuracy: 0.9467\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2182 - accuracy: 0.9778 - val_loss: 0.3025 - val_accuracy: 0.9467\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2116 - accuracy: 0.9787 - val_loss: 0.2986 - val_accuracy: 0.9467\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2137 - accuracy: 0.9815 - val_loss: 0.3106 - val_accuracy: 0.9467\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2129 - accuracy: 0.9824 - val_loss: 0.3041 - val_accuracy: 0.9467\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2088 - accuracy: 0.9778 - val_loss: 0.3036 - val_accuracy: 0.9433\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2129 - accuracy: 0.9736 - val_loss: 0.3120 - val_accuracy: 0.9400\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2049 - accuracy: 0.9833 - val_loss: 0.3189 - val_accuracy: 0.9400\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2089 - accuracy: 0.9778 - val_loss: 0.3130 - val_accuracy: 0.9433\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2010 - accuracy: 0.9824 - val_loss: 0.3080 - val_accuracy: 0.9400\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1992 - accuracy: 0.9819 - val_loss: 0.3083 - val_accuracy: 0.9500\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1947 - accuracy: 0.9819 - val_loss: 0.3073 - val_accuracy: 0.9467\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1961 - accuracy: 0.9829 - val_loss: 0.3164 - val_accuracy: 0.9467\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1938 - accuracy: 0.9843 - val_loss: 0.3108 - val_accuracy: 0.9433\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1896 - accuracy: 0.9819 - val_loss: 0.3159 - val_accuracy: 0.9467\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1994 - accuracy: 0.9782 - val_loss: 0.3198 - val_accuracy: 0.9433\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1979 - accuracy: 0.9819 - val_loss: 0.2996 - val_accuracy: 0.9467\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1964 - accuracy: 0.9782 - val_loss: 0.3037 - val_accuracy: 0.9367\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1898 - accuracy: 0.9819 - val_loss: 0.3158 - val_accuracy: 0.9433\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1898 - accuracy: 0.9833 - val_loss: 0.3104 - val_accuracy: 0.9433\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1925 - accuracy: 0.9778 - val_loss: 0.3195 - val_accuracy: 0.9367\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1864 - accuracy: 0.9843 - val_loss: 0.3153 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1852 - accuracy: 0.9843 - val_loss: 0.3022 - val_accuracy: 0.9433\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1927 - accuracy: 0.9796 - val_loss: 0.3197 - val_accuracy: 0.9433\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1871 - accuracy: 0.9801 - val_loss: 0.3158 - val_accuracy: 0.9400\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1856 - accuracy: 0.9843 - val_loss: 0.3149 - val_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1905 - accuracy: 0.9833 - val_loss: 0.3093 - val_accuracy: 0.9367\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1888 - accuracy: 0.9810 - val_loss: 0.2994 - val_accuracy: 0.9400\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1854 - accuracy: 0.9866 - val_loss: 0.3059 - val_accuracy: 0.9433\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1835 - accuracy: 0.9815 - val_loss: 0.3067 - val_accuracy: 0.9433\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1867 - accuracy: 0.9819 - val_loss: 0.3121 - val_accuracy: 0.9467\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1919 - accuracy: 0.9769 - val_loss: 0.2907 - val_accuracy: 0.9433\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1806 - accuracy: 0.9852 - val_loss: 0.3014 - val_accuracy: 0.9467\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1787 - accuracy: 0.9884 - val_loss: 0.3145 - val_accuracy: 0.9433\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1785 - accuracy: 0.9870 - val_loss: 0.3157 - val_accuracy: 0.9367\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1779 - accuracy: 0.9819 - val_loss: 0.3048 - val_accuracy: 0.9433\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1813 - accuracy: 0.9833 - val_loss: 0.3151 - val_accuracy: 0.9367\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1765 - accuracy: 0.9838 - val_loss: 0.3112 - val_accuracy: 0.9400\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1821 - accuracy: 0.9856 - val_loss: 0.3033 - val_accuracy: 0.9367\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1794 - accuracy: 0.9815 - val_loss: 0.2985 - val_accuracy: 0.9467\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1780 - accuracy: 0.9824 - val_loss: 0.3116 - val_accuracy: 0.9433\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1841 - accuracy: 0.9819 - val_loss: 0.3004 - val_accuracy: 0.9467\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1733 - accuracy: 0.9884 - val_loss: 0.2909 - val_accuracy: 0.9433\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.98 - 0s 20us/sample - loss: 0.1751 - accuracy: 0.9819 - val_loss: 0.2879 - val_accuracy: 0.9433\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1845 - accuracy: 0.9815 - val_loss: 0.2896 - val_accuracy: 0.9367\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1702 - accuracy: 0.9870 - val_loss: 0.3030 - val_accuracy: 0.9400\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1710 - accuracy: 0.9861 - val_loss: 0.3110 - val_accuracy: 0.9400\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1770 - accuracy: 0.9819 - val_loss: 0.2910 - val_accuracy: 0.9433\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1700 - accuracy: 0.9833 - val_loss: 0.2683 - val_accuracy: 0.9533\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1748 - accuracy: 0.9847 - val_loss: 0.2852 - val_accuracy: 0.9433\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1652 - accuracy: 0.9861 - val_loss: 0.2742 - val_accuracy: 0.9433\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1758 - accuracy: 0.9829 - val_loss: 0.3028 - val_accuracy: 0.9433\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1740 - accuracy: 0.9838 - val_loss: 0.2861 - val_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1752 - accuracy: 0.9838 - val_loss: 0.3049 - val_accuracy: 0.9333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1705 - accuracy: 0.9838 - val_loss: 0.2895 - val_accuracy: 0.9400\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1701 - accuracy: 0.9843 - val_loss: 0.2864 - val_accuracy: 0.9433\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1694 - accuracy: 0.9833 - val_loss: 0.2917 - val_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1666 - accuracy: 0.9866 - val_loss: 0.3019 - val_accuracy: 0.9400\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1638 - accuracy: 0.9875 - val_loss: 0.2997 - val_accuracy: 0.9400\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1722 - accuracy: 0.9824 - val_loss: 0.2822 - val_accuracy: 0.9433\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1678 - accuracy: 0.9856 - val_loss: 0.2971 - val_accuracy: 0.9400\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1668 - accuracy: 0.9856 - val_loss: 0.3030 - val_accuracy: 0.9367\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1765 - accuracy: 0.9796 - val_loss: 0.3033 - val_accuracy: 0.9367\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1697 - accuracy: 0.9847 - val_loss: 0.3154 - val_accuracy: 0.9467\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1598 - accuracy: 0.9884 - val_loss: 0.2669 - val_accuracy: 0.9500\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1676 - accuracy: 0.9824 - val_loss: 0.2848 - val_accuracy: 0.9367\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1645 - accuracy: 0.9843 - val_loss: 0.2928 - val_accuracy: 0.9400\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1676 - accuracy: 0.9843 - val_loss: 0.2981 - val_accuracy: 0.9433\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1675 - accuracy: 0.9861 - val_loss: 0.3182 - val_accuracy: 0.9400\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1556 - accuracy: 0.9912 - val_loss: 0.2955 - val_accuracy: 0.9467\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1607 - accuracy: 0.9880 - val_loss: 0.2923 - val_accuracy: 0.9500\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1667 - accuracy: 0.9852 - val_loss: 0.2796 - val_accuracy: 0.9467\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1609 - accuracy: 0.9847 - val_loss: 0.3017 - val_accuracy: 0.9400\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1641 - accuracy: 0.9856 - val_loss: 0.2934 - val_accuracy: 0.9400\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1561 - accuracy: 0.9889 - val_loss: 0.2954 - val_accuracy: 0.9367\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1631 - accuracy: 0.9847 - val_loss: 0.2891 - val_accuracy: 0.9400\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1671 - accuracy: 0.9806 - val_loss: 0.3008 - val_accuracy: 0.9400\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1623 - accuracy: 0.9847 - val_loss: 0.2783 - val_accuracy: 0.9400\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1597 - accuracy: 0.9870 - val_loss: 0.2940 - val_accuracy: 0.9367\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1601 - accuracy: 0.9861 - val_loss: 0.2856 - val_accuracy: 0.9400\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1614 - accuracy: 0.9852 - val_loss: 0.3230 - val_accuracy: 0.9367\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1624 - accuracy: 0.9861 - val_loss: 0.2909 - val_accuracy: 0.9400\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1643 - accuracy: 0.9843 - val_loss: 0.3102 - val_accuracy: 0.9333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1643 - accuracy: 0.9843 - val_loss: 0.2670 - val_accuracy: 0.9367\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1672 - accuracy: 0.9829 - val_loss: 0.2805 - val_accuracy: 0.9400\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1626 - accuracy: 0.9856 - val_loss: 0.2885 - val_accuracy: 0.9367\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1669 - accuracy: 0.9833 - val_loss: 0.3017 - val_accuracy: 0.9333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 1.00 - 0s 20us/sample - loss: 0.1643 - accuracy: 0.9819 - val_loss: 0.2908 - val_accuracy: 0.9400\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1613 - accuracy: 0.9852 - val_loss: 0.3005 - val_accuracy: 0.9400\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1650 - accuracy: 0.9833 - val_loss: 0.2948 - val_accuracy: 0.9367\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1565 - accuracy: 0.9894 - val_loss: 0.2979 - val_accuracy: 0.9467\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1580 - accuracy: 0.9838 - val_loss: 0.2692 - val_accuracy: 0.9433\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1596 - accuracy: 0.9856 - val_loss: 0.2927 - val_accuracy: 0.9433\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1559 - accuracy: 0.9875 - val_loss: 0.2918 - val_accuracy: 0.9433\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1615 - accuracy: 0.9833 - val_loss: 0.2991 - val_accuracy: 0.9433\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1626 - accuracy: 0.9824 - val_loss: 0.2892 - val_accuracy: 0.9367\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1613 - accuracy: 0.9847 - val_loss: 0.2708 - val_accuracy: 0.9367\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1624 - accuracy: 0.9815 - val_loss: 0.2758 - val_accuracy: 0.9333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1592 - accuracy: 0.9870 - val_loss: 0.2594 - val_accuracy: 0.9433\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1594 - accuracy: 0.9847 - val_loss: 0.2794 - val_accuracy: 0.9400\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1659 - accuracy: 0.9861 - val_loss: 0.2836 - val_accuracy: 0.9367\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1633 - accuracy: 0.9833 - val_loss: 0.2927 - val_accuracy: 0.9433\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1542 - accuracy: 0.9861 - val_loss: 0.3035 - val_accuracy: 0.9433\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1569 - accuracy: 0.9866 - val_loss: 0.2935 - val_accuracy: 0.9333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1535 - accuracy: 0.9898 - val_loss: 0.3189 - val_accuracy: 0.9333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1614 - accuracy: 0.9847 - val_loss: 0.2942 - val_accuracy: 0.9333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1570 - accuracy: 0.9870 - val_loss: 0.2985 - val_accuracy: 0.9433\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1608 - accuracy: 0.9843 - val_loss: 0.2939 - val_accuracy: 0.9433\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1570 - accuracy: 0.9884 - val_loss: 0.3102 - val_accuracy: 0.9333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1557 - accuracy: 0.9875 - val_loss: 0.2950 - val_accuracy: 0.9300\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1556 - accuracy: 0.9861 - val_loss: 0.3100 - val_accuracy: 0.9367\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1566 - accuracy: 0.9880 - val_loss: 0.3256 - val_accuracy: 0.9367\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1568 - accuracy: 0.9824 - val_loss: 0.3132 - val_accuracy: 0.9367\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1538 - accuracy: 0.9880 - val_loss: 0.3215 - val_accuracy: 0.9367\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1531 - accuracy: 0.9875 - val_loss: 0.3094 - val_accuracy: 0.9300\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1541 - accuracy: 0.9847 - val_loss: 0.3074 - val_accuracy: 0.9367\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1573 - accuracy: 0.9861 - val_loss: 0.2869 - val_accuracy: 0.9367\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1516 - accuracy: 0.9866 - val_loss: 0.2907 - val_accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1575 - accuracy: 0.9856 - val_loss: 0.2788 - val_accuracy: 0.9333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1596 - accuracy: 0.9829 - val_loss: 0.2966 - val_accuracy: 0.9333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1522 - accuracy: 0.9861 - val_loss: 0.2757 - val_accuracy: 0.9433\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1594 - accuracy: 0.9847 - val_loss: 0.3017 - val_accuracy: 0.9367\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1576 - accuracy: 0.9856 - val_loss: 0.2660 - val_accuracy: 0.9400\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1597 - accuracy: 0.9856 - val_loss: 0.2734 - val_accuracy: 0.9467\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1509 - accuracy: 0.9861 - val_loss: 0.3254 - val_accuracy: 0.9400\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1539 - accuracy: 0.9866 - val_loss: 0.2940 - val_accuracy: 0.9433\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1520 - accuracy: 0.9847 - val_loss: 0.2751 - val_accuracy: 0.9333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1510 - accuracy: 0.9866 - val_loss: 0.2975 - val_accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1550 - accuracy: 0.9884 - val_loss: 0.2968 - val_accuracy: 0.9367\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1521 - accuracy: 0.9861 - val_loss: 0.2770 - val_accuracy: 0.9333\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1492 - accuracy: 0.9875 - val_loss: 0.2895 - val_accuracy: 0.9333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1573 - accuracy: 0.9829 - val_loss: 0.3154 - val_accuracy: 0.9333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1501 - accuracy: 0.9870 - val_loss: 0.2803 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1553 - accuracy: 0.9861 - val_loss: 0.3261 - val_accuracy: 0.9300\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1482 - accuracy: 0.9861 - val_loss: 0.2890 - val_accuracy: 0.9433\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1479 - accuracy: 0.9870 - val_loss: 0.2877 - val_accuracy: 0.9400\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1526 - accuracy: 0.9847 - val_loss: 0.3018 - val_accuracy: 0.9367\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1529 - accuracy: 0.9870 - val_loss: 0.2864 - val_accuracy: 0.9367\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1430 - accuracy: 0.9875 - val_loss: 0.2903 - val_accuracy: 0.9367\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1522 - accuracy: 0.9866 - val_loss: 0.2798 - val_accuracy: 0.9400\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1450 - accuracy: 0.9870 - val_loss: 0.2920 - val_accuracy: 0.9433\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1523 - accuracy: 0.9833 - val_loss: 0.2816 - val_accuracy: 0.9433\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1508 - accuracy: 0.9856 - val_loss: 0.2754 - val_accuracy: 0.9333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1459 - accuracy: 0.9866 - val_loss: 0.2836 - val_accuracy: 0.9333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1526 - accuracy: 0.9856 - val_loss: 0.2782 - val_accuracy: 0.9433\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1432 - accuracy: 0.9870 - val_loss: 0.2898 - val_accuracy: 0.9333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1491 - accuracy: 0.9861 - val_loss: 0.2828 - val_accuracy: 0.9400\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1465 - accuracy: 0.9870 - val_loss: 0.2844 - val_accuracy: 0.9400\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1502 - accuracy: 0.9847 - val_loss: 0.2953 - val_accuracy: 0.9400\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1405 - accuracy: 0.9894 - val_loss: 0.2904 - val_accuracy: 0.9367\n",
      "540/540 [==============================] - 0s 234us/sample - loss: 0.2504 - accuracy: 0.9519\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 345us/sample - loss: 2.3212 - accuracy: 0.5343 - val_loss: 2.0160 - val_accuracy: 0.7933\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.9753 - accuracy: 0.7292 - val_loss: 1.8162 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.7742 - accuracy: 0.8181 - val_loss: 1.6619 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6110 - accuracy: 0.8329 - val_loss: 1.5249 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4876 - accuracy: 0.8491 - val_loss: 1.4038 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3673 - accuracy: 0.8523 - val_loss: 1.2958 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2584 - accuracy: 0.8565 - val_loss: 1.2001 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1721 - accuracy: 0.8565 - val_loss: 1.1138 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0774 - accuracy: 0.8602 - val_loss: 1.0349 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.0034 - accuracy: 0.8569 - val_loss: 0.9640 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9282 - accuracy: 0.8611 - val_loss: 0.9009 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8828 - accuracy: 0.8593 - val_loss: 0.8439 - val_accuracy: 0.8300\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8223 - accuracy: 0.8620 - val_loss: 0.7937 - val_accuracy: 0.8300\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7737 - accuracy: 0.8611 - val_loss: 0.7496 - val_accuracy: 0.8300\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7204 - accuracy: 0.8676 - val_loss: 0.7080 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6885 - accuracy: 0.8653 - val_loss: 0.6724 - val_accuracy: 0.8400\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6464 - accuracy: 0.8731 - val_loss: 0.6380 - val_accuracy: 0.8400\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6164 - accuracy: 0.8713 - val_loss: 0.6048 - val_accuracy: 0.8567\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5822 - accuracy: 0.8736 - val_loss: 0.5797 - val_accuracy: 0.8633\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5434 - accuracy: 0.8792 - val_loss: 0.5518 - val_accuracy: 0.8700\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5310 - accuracy: 0.8806 - val_loss: 0.5246 - val_accuracy: 0.8667\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4994 - accuracy: 0.8884 - val_loss: 0.5096 - val_accuracy: 0.8733\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4801 - accuracy: 0.8986 - val_loss: 0.4916 - val_accuracy: 0.8800\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4507 - accuracy: 0.9069 - val_loss: 0.4790 - val_accuracy: 0.8967\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4372 - accuracy: 0.9102 - val_loss: 0.4616 - val_accuracy: 0.9200\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4182 - accuracy: 0.9199 - val_loss: 0.4505 - val_accuracy: 0.9233\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3971 - accuracy: 0.9287 - val_loss: 0.4440 - val_accuracy: 0.9167\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3810 - accuracy: 0.9366 - val_loss: 0.4395 - val_accuracy: 0.9267\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3641 - accuracy: 0.9384 - val_loss: 0.4285 - val_accuracy: 0.9300\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3567 - accuracy: 0.9407 - val_loss: 0.4231 - val_accuracy: 0.9267\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3472 - accuracy: 0.9380 - val_loss: 0.4279 - val_accuracy: 0.9233\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3315 - accuracy: 0.9458 - val_loss: 0.4101 - val_accuracy: 0.9267\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3173 - accuracy: 0.9551 - val_loss: 0.4064 - val_accuracy: 0.9233\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3127 - accuracy: 0.9565 - val_loss: 0.3942 - val_accuracy: 0.9233\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3017 - accuracy: 0.9579 - val_loss: 0.4056 - val_accuracy: 0.9200\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2934 - accuracy: 0.9620 - val_loss: 0.3938 - val_accuracy: 0.9300\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2773 - accuracy: 0.9620 - val_loss: 0.4070 - val_accuracy: 0.9233\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2780 - accuracy: 0.9616 - val_loss: 0.3938 - val_accuracy: 0.9233\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2664 - accuracy: 0.9671 - val_loss: 0.3995 - val_accuracy: 0.9267\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2592 - accuracy: 0.9713 - val_loss: 0.3886 - val_accuracy: 0.9333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2566 - accuracy: 0.9704 - val_loss: 0.3994 - val_accuracy: 0.9233\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2563 - accuracy: 0.9708 - val_loss: 0.4038 - val_accuracy: 0.9233\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2426 - accuracy: 0.9759 - val_loss: 0.3994 - val_accuracy: 0.9300\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2398 - accuracy: 0.9750 - val_loss: 0.3993 - val_accuracy: 0.9233\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2445 - accuracy: 0.9699 - val_loss: 0.3893 - val_accuracy: 0.9200\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2391 - accuracy: 0.9713 - val_loss: 0.3903 - val_accuracy: 0.9200\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.2331 - accuracy: 0.9773 - val_loss: 0.3941 - val_accuracy: 0.9233\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2331 - accuracy: 0.9769 - val_loss: 0.3704 - val_accuracy: 0.9300\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2225 - accuracy: 0.9801 - val_loss: 0.3845 - val_accuracy: 0.9267\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2283 - accuracy: 0.9731 - val_loss: 0.3932 - val_accuracy: 0.9267\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2301 - accuracy: 0.9713 - val_loss: 0.3744 - val_accuracy: 0.9267\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2173 - accuracy: 0.9773 - val_loss: 0.3846 - val_accuracy: 0.9233\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2178 - accuracy: 0.9755 - val_loss: 0.3707 - val_accuracy: 0.9233\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2144 - accuracy: 0.9796 - val_loss: 0.3918 - val_accuracy: 0.9233\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2048 - accuracy: 0.9833 - val_loss: 0.3908 - val_accuracy: 0.9233\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2097 - accuracy: 0.9806 - val_loss: 0.3833 - val_accuracy: 0.9233\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2047 - accuracy: 0.9815 - val_loss: 0.3770 - val_accuracy: 0.9200\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2035 - accuracy: 0.9806 - val_loss: 0.3795 - val_accuracy: 0.9233\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2040 - accuracy: 0.9787 - val_loss: 0.3729 - val_accuracy: 0.9300\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2065 - accuracy: 0.9750 - val_loss: 0.3831 - val_accuracy: 0.9267\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2002 - accuracy: 0.9801 - val_loss: 0.3867 - val_accuracy: 0.9200\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1986 - accuracy: 0.9810 - val_loss: 0.3912 - val_accuracy: 0.9300\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2022 - accuracy: 0.9782 - val_loss: 0.3852 - val_accuracy: 0.9267\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1931 - accuracy: 0.9796 - val_loss: 0.3581 - val_accuracy: 0.9300\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1931 - accuracy: 0.9843 - val_loss: 0.3655 - val_accuracy: 0.9333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2002 - accuracy: 0.9769 - val_loss: 0.3524 - val_accuracy: 0.9267\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1882 - accuracy: 0.9847 - val_loss: 0.3816 - val_accuracy: 0.9300\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1957 - accuracy: 0.9792 - val_loss: 0.3649 - val_accuracy: 0.9267\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1860 - accuracy: 0.9833 - val_loss: 0.3833 - val_accuracy: 0.9267\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1878 - accuracy: 0.9852 - val_loss: 0.3703 - val_accuracy: 0.9300\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1885 - accuracy: 0.9815 - val_loss: 0.3588 - val_accuracy: 0.9267\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1835 - accuracy: 0.9838 - val_loss: 0.3481 - val_accuracy: 0.9300\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1905 - accuracy: 0.9778 - val_loss: 0.3369 - val_accuracy: 0.9300\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1852 - accuracy: 0.9806 - val_loss: 0.3833 - val_accuracy: 0.9267\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1875 - accuracy: 0.9792 - val_loss: 0.3734 - val_accuracy: 0.9333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1753 - accuracy: 0.9866 - val_loss: 0.3661 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1833 - accuracy: 0.9843 - val_loss: 0.3668 - val_accuracy: 0.9300\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1804 - accuracy: 0.9856 - val_loss: 0.3826 - val_accuracy: 0.9300\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1705 - accuracy: 0.9866 - val_loss: 0.3696 - val_accuracy: 0.9367\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1756 - accuracy: 0.9889 - val_loss: 0.3709 - val_accuracy: 0.9300\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1771 - accuracy: 0.9824 - val_loss: 0.3752 - val_accuracy: 0.9300\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1751 - accuracy: 0.9852 - val_loss: 0.3635 - val_accuracy: 0.9367\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1738 - accuracy: 0.9852 - val_loss: 0.3518 - val_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1806 - accuracy: 0.9829 - val_loss: 0.3540 - val_accuracy: 0.9300\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1753 - accuracy: 0.9866 - val_loss: 0.3475 - val_accuracy: 0.9333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1701 - accuracy: 0.9870 - val_loss: 0.3590 - val_accuracy: 0.9300\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1721 - accuracy: 0.9838 - val_loss: 0.3624 - val_accuracy: 0.9267\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1786 - accuracy: 0.9819 - val_loss: 0.3631 - val_accuracy: 0.9300\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1711 - accuracy: 0.9843 - val_loss: 0.3634 - val_accuracy: 0.9300\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1717 - accuracy: 0.9833 - val_loss: 0.3612 - val_accuracy: 0.9333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1748 - accuracy: 0.9843 - val_loss: 0.3581 - val_accuracy: 0.9333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1717 - accuracy: 0.9847 - val_loss: 0.3665 - val_accuracy: 0.9333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1626 - accuracy: 0.9870 - val_loss: 0.3792 - val_accuracy: 0.9300\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1662 - accuracy: 0.9852 - val_loss: 0.3517 - val_accuracy: 0.9300\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1630 - accuracy: 0.9880 - val_loss: 0.3872 - val_accuracy: 0.9333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1632 - accuracy: 0.9880 - val_loss: 0.3663 - val_accuracy: 0.9300\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1681 - accuracy: 0.9829 - val_loss: 0.3560 - val_accuracy: 0.9367\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1642 - accuracy: 0.9861 - val_loss: 0.3579 - val_accuracy: 0.9333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1687 - accuracy: 0.9847 - val_loss: 0.3533 - val_accuracy: 0.9367\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1621 - accuracy: 0.9880 - val_loss: 0.3695 - val_accuracy: 0.9333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1663 - accuracy: 0.9856 - val_loss: 0.3325 - val_accuracy: 0.9367\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1697 - accuracy: 0.9829 - val_loss: 0.3413 - val_accuracy: 0.9333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1716 - accuracy: 0.9843 - val_loss: 0.3528 - val_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1723 - accuracy: 0.9833 - val_loss: 0.3292 - val_accuracy: 0.9333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1651 - accuracy: 0.9847 - val_loss: 0.3510 - val_accuracy: 0.9333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1615 - accuracy: 0.9880 - val_loss: 0.3453 - val_accuracy: 0.9367\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1599 - accuracy: 0.9847 - val_loss: 0.3632 - val_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1545 - accuracy: 0.9917 - val_loss: 0.3645 - val_accuracy: 0.9300\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1581 - accuracy: 0.9852 - val_loss: 0.3681 - val_accuracy: 0.9300\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1619 - accuracy: 0.9833 - val_loss: 0.3285 - val_accuracy: 0.9300\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1605 - accuracy: 0.9833 - val_loss: 0.3415 - val_accuracy: 0.9233\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1644 - accuracy: 0.9815 - val_loss: 0.3679 - val_accuracy: 0.9300\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1629 - accuracy: 0.9843 - val_loss: 0.3382 - val_accuracy: 0.9333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1619 - accuracy: 0.9852 - val_loss: 0.3512 - val_accuracy: 0.9267\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1730 - accuracy: 0.9755 - val_loss: 0.3453 - val_accuracy: 0.9267\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1637 - accuracy: 0.9833 - val_loss: 0.3541 - val_accuracy: 0.9367\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1576 - accuracy: 0.9861 - val_loss: 0.3497 - val_accuracy: 0.9267\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1559 - accuracy: 0.9847 - val_loss: 0.3653 - val_accuracy: 0.9267\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1610 - accuracy: 0.9847 - val_loss: 0.3508 - val_accuracy: 0.9300\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1600 - accuracy: 0.9870 - val_loss: 0.3565 - val_accuracy: 0.9300\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1584 - accuracy: 0.9833 - val_loss: 0.3480 - val_accuracy: 0.9267\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1541 - accuracy: 0.9870 - val_loss: 0.3678 - val_accuracy: 0.9300\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1531 - accuracy: 0.9907 - val_loss: 0.3650 - val_accuracy: 0.9333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1574 - accuracy: 0.9852 - val_loss: 0.3604 - val_accuracy: 0.9333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1580 - accuracy: 0.9843 - val_loss: 0.3684 - val_accuracy: 0.9300\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1504 - accuracy: 0.9898 - val_loss: 0.3586 - val_accuracy: 0.9300\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1560 - accuracy: 0.9847 - val_loss: 0.3917 - val_accuracy: 0.9333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1552 - accuracy: 0.9875 - val_loss: 0.3555 - val_accuracy: 0.9333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1552 - accuracy: 0.9852 - val_loss: 0.3816 - val_accuracy: 0.9300\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1522 - accuracy: 0.9884 - val_loss: 0.3541 - val_accuracy: 0.9300\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1513 - accuracy: 0.9875 - val_loss: 0.3834 - val_accuracy: 0.9333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1542 - accuracy: 0.9861 - val_loss: 0.3549 - val_accuracy: 0.9333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1500 - accuracy: 0.9889 - val_loss: 0.3578 - val_accuracy: 0.9267\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1508 - accuracy: 0.9880 - val_loss: 0.3440 - val_accuracy: 0.9300\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1474 - accuracy: 0.9889 - val_loss: 0.3568 - val_accuracy: 0.9333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1575 - accuracy: 0.9852 - val_loss: 0.3365 - val_accuracy: 0.9233\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1509 - accuracy: 0.9884 - val_loss: 0.3726 - val_accuracy: 0.9233\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1482 - accuracy: 0.9894 - val_loss: 0.3642 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1528 - accuracy: 0.9856 - val_loss: 0.3480 - val_accuracy: 0.9367\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1457 - accuracy: 0.9907 - val_loss: 0.3697 - val_accuracy: 0.9333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1547 - accuracy: 0.9880 - val_loss: 0.3546 - val_accuracy: 0.9300\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1493 - accuracy: 0.9894 - val_loss: 0.3495 - val_accuracy: 0.9300\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1440 - accuracy: 0.9907 - val_loss: 0.3517 - val_accuracy: 0.9300\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1531 - accuracy: 0.9856 - val_loss: 0.3722 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1509 - accuracy: 0.9870 - val_loss: 0.3468 - val_accuracy: 0.9367\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1469 - accuracy: 0.9894 - val_loss: 0.3652 - val_accuracy: 0.9367\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1531 - accuracy: 0.9884 - val_loss: 0.3511 - val_accuracy: 0.9333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1450 - accuracy: 0.9921 - val_loss: 0.3560 - val_accuracy: 0.9333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1512 - accuracy: 0.9875 - val_loss: 0.3303 - val_accuracy: 0.9367\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1503 - accuracy: 0.9852 - val_loss: 0.3435 - val_accuracy: 0.9300\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1513 - accuracy: 0.9870 - val_loss: 0.3300 - val_accuracy: 0.9367\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1490 - accuracy: 0.9898 - val_loss: 0.3436 - val_accuracy: 0.9333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1425 - accuracy: 0.9889 - val_loss: 0.3546 - val_accuracy: 0.9400\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1480 - accuracy: 0.9856 - val_loss: 0.3357 - val_accuracy: 0.9367\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1527 - accuracy: 0.9870 - val_loss: 0.3506 - val_accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1481 - accuracy: 0.9880 - val_loss: 0.3738 - val_accuracy: 0.9367\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1467 - accuracy: 0.9833 - val_loss: 0.3483 - val_accuracy: 0.9300\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1477 - accuracy: 0.9898 - val_loss: 0.3587 - val_accuracy: 0.9367\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1486 - accuracy: 0.9894 - val_loss: 0.3319 - val_accuracy: 0.9333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1422 - accuracy: 0.9889 - val_loss: 0.3541 - val_accuracy: 0.9400\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1489 - accuracy: 0.9833 - val_loss: 0.3228 - val_accuracy: 0.9400\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1439 - accuracy: 0.9856 - val_loss: 0.3555 - val_accuracy: 0.9300\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1426 - accuracy: 0.9898 - val_loss: 0.3783 - val_accuracy: 0.9300\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1443 - accuracy: 0.9884 - val_loss: 0.3493 - val_accuracy: 0.9400\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1425 - accuracy: 0.9907 - val_loss: 0.3886 - val_accuracy: 0.9333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1396 - accuracy: 0.9880 - val_loss: 0.3699 - val_accuracy: 0.9367\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1369 - accuracy: 0.9926 - val_loss: 0.3549 - val_accuracy: 0.9400\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1428 - accuracy: 0.9880 - val_loss: 0.3646 - val_accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1408 - accuracy: 0.9903 - val_loss: 0.3323 - val_accuracy: 0.9367\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1461 - accuracy: 0.9861 - val_loss: 0.3645 - val_accuracy: 0.9400\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1408 - accuracy: 0.9894 - val_loss: 0.3396 - val_accuracy: 0.9400\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1450 - accuracy: 0.9880 - val_loss: 0.3494 - val_accuracy: 0.9367\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1456 - accuracy: 0.9884 - val_loss: 0.3609 - val_accuracy: 0.9333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1430 - accuracy: 0.9898 - val_loss: 0.3392 - val_accuracy: 0.9367\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1437 - accuracy: 0.9852 - val_loss: 0.3354 - val_accuracy: 0.9267\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1432 - accuracy: 0.9880 - val_loss: 0.3495 - val_accuracy: 0.9367\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1436 - accuracy: 0.9870 - val_loss: 0.3435 - val_accuracy: 0.9300\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1403 - accuracy: 0.9894 - val_loss: 0.3386 - val_accuracy: 0.9400\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1427 - accuracy: 0.9866 - val_loss: 0.3422 - val_accuracy: 0.9367\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1359 - accuracy: 0.9907 - val_loss: 0.3634 - val_accuracy: 0.9400\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1471 - accuracy: 0.9852 - val_loss: 0.3548 - val_accuracy: 0.9300\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1405 - accuracy: 0.9856 - val_loss: 0.3269 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1426 - accuracy: 0.9903 - val_loss: 0.3446 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1482 - accuracy: 0.9852 - val_loss: 0.3628 - val_accuracy: 0.9333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1445 - accuracy: 0.9843 - val_loss: 0.3388 - val_accuracy: 0.9300\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1357 - accuracy: 0.9917 - val_loss: 0.3302 - val_accuracy: 0.9367\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1434 - accuracy: 0.9852 - val_loss: 0.3330 - val_accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1403 - accuracy: 0.9884 - val_loss: 0.3401 - val_accuracy: 0.9333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1426 - accuracy: 0.9856 - val_loss: 0.3491 - val_accuracy: 0.9333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1433 - accuracy: 0.9880 - val_loss: 0.3398 - val_accuracy: 0.9367\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1403 - accuracy: 0.9870 - val_loss: 0.3548 - val_accuracy: 0.9400\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1399 - accuracy: 0.9870 - val_loss: 0.3503 - val_accuracy: 0.9300\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1386 - accuracy: 0.9907 - val_loss: 0.3491 - val_accuracy: 0.9300\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1372 - accuracy: 0.9898 - val_loss: 0.3496 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1345 - accuracy: 0.9894 - val_loss: 0.3484 - val_accuracy: 0.9333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1364 - accuracy: 0.9875 - val_loss: 0.3406 - val_accuracy: 0.9333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1353 - accuracy: 0.9875 - val_loss: 0.3499 - val_accuracy: 0.9333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1398 - accuracy: 0.9875 - val_loss: 0.3310 - val_accuracy: 0.9367\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1427 - accuracy: 0.9852 - val_loss: 0.3662 - val_accuracy: 0.9300\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.99 - 0s 21us/sample - loss: 0.1390 - accuracy: 0.9917 - val_loss: 0.3647 - val_accuracy: 0.9333\n",
      "540/540 [==============================] - 0s 247us/sample - loss: 0.3539 - accuracy: 0.9315\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 359us/sample - loss: 2.1737 - accuracy: 0.6616 - val_loss: 1.9750 - val_accuracy: 0.8233\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.9408 - accuracy: 0.7907 - val_loss: 1.7894 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.7508 - accuracy: 0.8176 - val_loss: 1.6425 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6168 - accuracy: 0.8333 - val_loss: 1.5126 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4666 - accuracy: 0.8394 - val_loss: 1.3960 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3437 - accuracy: 0.8472 - val_loss: 1.2906 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2464 - accuracy: 0.8477 - val_loss: 1.1947 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.1486 - accuracy: 0.8481 - val_loss: 1.1102 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.0592 - accuracy: 0.8500 - val_loss: 1.0324 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9908 - accuracy: 0.8505 - val_loss: 0.9621 - val_accuracy: 0.8400\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9241 - accuracy: 0.8528 - val_loss: 0.8965 - val_accuracy: 0.8400\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8543 - accuracy: 0.8574 - val_loss: 0.8346 - val_accuracy: 0.8433\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7914 - accuracy: 0.8579 - val_loss: 0.7803 - val_accuracy: 0.8467\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7467 - accuracy: 0.8639 - val_loss: 0.7304 - val_accuracy: 0.8467\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7024 - accuracy: 0.8694 - val_loss: 0.6825 - val_accuracy: 0.8467\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6618 - accuracy: 0.8681 - val_loss: 0.6439 - val_accuracy: 0.8600\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6092 - accuracy: 0.8847 - val_loss: 0.6100 - val_accuracy: 0.8733\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5729 - accuracy: 0.8856 - val_loss: 0.5817 - val_accuracy: 0.8767\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5460 - accuracy: 0.8907 - val_loss: 0.5527 - val_accuracy: 0.8867\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5133 - accuracy: 0.9009 - val_loss: 0.5295 - val_accuracy: 0.8933\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4869 - accuracy: 0.9074 - val_loss: 0.5082 - val_accuracy: 0.9033\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4631 - accuracy: 0.9116 - val_loss: 0.4889 - val_accuracy: 0.9033\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4357 - accuracy: 0.9218 - val_loss: 0.4651 - val_accuracy: 0.9067\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4188 - accuracy: 0.9273 - val_loss: 0.4532 - val_accuracy: 0.9133\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4085 - accuracy: 0.9222 - val_loss: 0.4398 - val_accuracy: 0.9133\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3868 - accuracy: 0.9273 - val_loss: 0.4364 - val_accuracy: 0.9067\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3704 - accuracy: 0.9361 - val_loss: 0.4246 - val_accuracy: 0.9067\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3639 - accuracy: 0.9315 - val_loss: 0.4085 - val_accuracy: 0.9067\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3409 - accuracy: 0.9417 - val_loss: 0.3945 - val_accuracy: 0.9167\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3364 - accuracy: 0.9421 - val_loss: 0.3922 - val_accuracy: 0.9133\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3197 - accuracy: 0.9463 - val_loss: 0.3959 - val_accuracy: 0.9033\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3065 - accuracy: 0.9500 - val_loss: 0.3729 - val_accuracy: 0.9200\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3033 - accuracy: 0.9574 - val_loss: 0.3764 - val_accuracy: 0.9133\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2917 - accuracy: 0.9588 - val_loss: 0.3821 - val_accuracy: 0.9267\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2905 - accuracy: 0.9505 - val_loss: 0.3881 - val_accuracy: 0.9233\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2837 - accuracy: 0.9574 - val_loss: 0.3680 - val_accuracy: 0.9233\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2698 - accuracy: 0.9644 - val_loss: 0.3781 - val_accuracy: 0.9200\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2640 - accuracy: 0.9657 - val_loss: 0.3666 - val_accuracy: 0.9233\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2558 - accuracy: 0.9704 - val_loss: 0.3528 - val_accuracy: 0.9300\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2508 - accuracy: 0.9685 - val_loss: 0.3545 - val_accuracy: 0.9233\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2410 - accuracy: 0.9750 - val_loss: 0.3581 - val_accuracy: 0.9233\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2466 - accuracy: 0.9722 - val_loss: 0.3780 - val_accuracy: 0.9200\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2418 - accuracy: 0.9704 - val_loss: 0.3574 - val_accuracy: 0.9233\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2275 - accuracy: 0.9782 - val_loss: 0.3796 - val_accuracy: 0.9133\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2236 - accuracy: 0.9764 - val_loss: 0.3518 - val_accuracy: 0.9267\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2253 - accuracy: 0.9736 - val_loss: 0.3525 - val_accuracy: 0.9267\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2262 - accuracy: 0.9778 - val_loss: 0.3732 - val_accuracy: 0.9267\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2147 - accuracy: 0.9824 - val_loss: 0.3570 - val_accuracy: 0.9267\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2225 - accuracy: 0.9745 - val_loss: 0.3662 - val_accuracy: 0.9233\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2146 - accuracy: 0.9769 - val_loss: 0.3855 - val_accuracy: 0.9200\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2137 - accuracy: 0.9796 - val_loss: 0.3733 - val_accuracy: 0.9233\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2065 - accuracy: 0.9806 - val_loss: 0.3715 - val_accuracy: 0.9233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2072 - accuracy: 0.9819 - val_loss: 0.3540 - val_accuracy: 0.9267\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2082 - accuracy: 0.9755 - val_loss: 0.3775 - val_accuracy: 0.9233\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2067 - accuracy: 0.9778 - val_loss: 0.3626 - val_accuracy: 0.9300\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2013 - accuracy: 0.9806 - val_loss: 0.3763 - val_accuracy: 0.9267\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2003 - accuracy: 0.9801 - val_loss: 0.3630 - val_accuracy: 0.9267\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1952 - accuracy: 0.9838 - val_loss: 0.3744 - val_accuracy: 0.9267\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1918 - accuracy: 0.9847 - val_loss: 0.3578 - val_accuracy: 0.9233\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1964 - accuracy: 0.9819 - val_loss: 0.3775 - val_accuracy: 0.9200\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2034 - accuracy: 0.9773 - val_loss: 0.3668 - val_accuracy: 0.9300\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1894 - accuracy: 0.9843 - val_loss: 0.3672 - val_accuracy: 0.9300\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1927 - accuracy: 0.9833 - val_loss: 0.3739 - val_accuracy: 0.9300\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1942 - accuracy: 0.9815 - val_loss: 0.3791 - val_accuracy: 0.9300\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1902 - accuracy: 0.9829 - val_loss: 0.3814 - val_accuracy: 0.9333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1878 - accuracy: 0.9819 - val_loss: 0.3711 - val_accuracy: 0.9300\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1897 - accuracy: 0.9806 - val_loss: 0.3428 - val_accuracy: 0.9333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1916 - accuracy: 0.9792 - val_loss: 0.3574 - val_accuracy: 0.9333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1878 - accuracy: 0.9852 - val_loss: 0.3692 - val_accuracy: 0.9333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1842 - accuracy: 0.9847 - val_loss: 0.3672 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1827 - accuracy: 0.9847 - val_loss: 0.3955 - val_accuracy: 0.9233\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1755 - accuracy: 0.9856 - val_loss: 0.3715 - val_accuracy: 0.9300\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1787 - accuracy: 0.9856 - val_loss: 0.3658 - val_accuracy: 0.9300\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1774 - accuracy: 0.9884 - val_loss: 0.3635 - val_accuracy: 0.9300\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1717 - accuracy: 0.9898 - val_loss: 0.3695 - val_accuracy: 0.9333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1803 - accuracy: 0.9852 - val_loss: 0.3612 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1773 - accuracy: 0.9824 - val_loss: 0.3555 - val_accuracy: 0.9333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1728 - accuracy: 0.9861 - val_loss: 0.3667 - val_accuracy: 0.9300\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1699 - accuracy: 0.9880 - val_loss: 0.3685 - val_accuracy: 0.9300\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1755 - accuracy: 0.9819 - val_loss: 0.3674 - val_accuracy: 0.9333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1758 - accuracy: 0.9819 - val_loss: 0.3757 - val_accuracy: 0.9267\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1730 - accuracy: 0.9847 - val_loss: 0.3653 - val_accuracy: 0.9267\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1705 - accuracy: 0.9903 - val_loss: 0.3639 - val_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1700 - accuracy: 0.9866 - val_loss: 0.3711 - val_accuracy: 0.9300\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1693 - accuracy: 0.9875 - val_loss: 0.3499 - val_accuracy: 0.9333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1725 - accuracy: 0.9833 - val_loss: 0.3701 - val_accuracy: 0.9300\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1722 - accuracy: 0.9833 - val_loss: 0.3519 - val_accuracy: 0.9267\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1762 - accuracy: 0.9843 - val_loss: 0.3654 - val_accuracy: 0.9200\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1614 - accuracy: 0.9907 - val_loss: 0.3782 - val_accuracy: 0.9200\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1673 - accuracy: 0.9866 - val_loss: 0.3686 - val_accuracy: 0.9267\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1697 - accuracy: 0.9824 - val_loss: 0.3396 - val_accuracy: 0.9267\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1666 - accuracy: 0.9843 - val_loss: 0.3733 - val_accuracy: 0.9300\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1701 - accuracy: 0.9838 - val_loss: 0.3910 - val_accuracy: 0.9300\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1680 - accuracy: 0.9829 - val_loss: 0.3650 - val_accuracy: 0.9300\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1727 - accuracy: 0.9787 - val_loss: 0.3705 - val_accuracy: 0.9300\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1611 - accuracy: 0.9884 - val_loss: 0.3776 - val_accuracy: 0.9300\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1615 - accuracy: 0.9889 - val_loss: 0.3688 - val_accuracy: 0.9333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1629 - accuracy: 0.9852 - val_loss: 0.3830 - val_accuracy: 0.9267\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1595 - accuracy: 0.9884 - val_loss: 0.3695 - val_accuracy: 0.9233\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1640 - accuracy: 0.9884 - val_loss: 0.3752 - val_accuracy: 0.9267\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1650 - accuracy: 0.9852 - val_loss: 0.3880 - val_accuracy: 0.9233\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1629 - accuracy: 0.9866 - val_loss: 0.3753 - val_accuracy: 0.9267\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1661 - accuracy: 0.9889 - val_loss: 0.3417 - val_accuracy: 0.9400\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1652 - accuracy: 0.9852 - val_loss: 0.3724 - val_accuracy: 0.9300\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1612 - accuracy: 0.9875 - val_loss: 0.3519 - val_accuracy: 0.9300\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1645 - accuracy: 0.9856 - val_loss: 0.3760 - val_accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1595 - accuracy: 0.9861 - val_loss: 0.3726 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1583 - accuracy: 0.9866 - val_loss: 0.3931 - val_accuracy: 0.9267\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1620 - accuracy: 0.9852 - val_loss: 0.3527 - val_accuracy: 0.9300\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1623 - accuracy: 0.9870 - val_loss: 0.3713 - val_accuracy: 0.9233\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1593 - accuracy: 0.9852 - val_loss: 0.3777 - val_accuracy: 0.9267\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1527 - accuracy: 0.9903 - val_loss: 0.3854 - val_accuracy: 0.9233\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1546 - accuracy: 0.9884 - val_loss: 0.3697 - val_accuracy: 0.9300\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1615 - accuracy: 0.9838 - val_loss: 0.3661 - val_accuracy: 0.9333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1612 - accuracy: 0.9847 - val_loss: 0.3832 - val_accuracy: 0.9233\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1604 - accuracy: 0.9852 - val_loss: 0.3757 - val_accuracy: 0.9267\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1591 - accuracy: 0.9861 - val_loss: 0.3702 - val_accuracy: 0.9300\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1609 - accuracy: 0.9861 - val_loss: 0.3702 - val_accuracy: 0.9267\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1521 - accuracy: 0.9898 - val_loss: 0.3763 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1527 - accuracy: 0.9912 - val_loss: 0.3538 - val_accuracy: 0.9300\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1596 - accuracy: 0.9852 - val_loss: 0.3849 - val_accuracy: 0.9300\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1585 - accuracy: 0.9884 - val_loss: 0.4028 - val_accuracy: 0.9233\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1533 - accuracy: 0.9889 - val_loss: 0.3694 - val_accuracy: 0.9267\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1582 - accuracy: 0.9861 - val_loss: 0.3870 - val_accuracy: 0.9267\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1546 - accuracy: 0.9889 - val_loss: 0.3875 - val_accuracy: 0.9267\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1532 - accuracy: 0.9894 - val_loss: 0.3547 - val_accuracy: 0.9267\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1556 - accuracy: 0.9866 - val_loss: 0.3780 - val_accuracy: 0.9300\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1598 - accuracy: 0.9847 - val_loss: 0.3788 - val_accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1534 - accuracy: 0.9875 - val_loss: 0.3692 - val_accuracy: 0.9267\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1586 - accuracy: 0.9847 - val_loss: 0.4073 - val_accuracy: 0.9233\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1491 - accuracy: 0.9903 - val_loss: 0.3913 - val_accuracy: 0.9233\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1526 - accuracy: 0.9894 - val_loss: 0.3845 - val_accuracy: 0.9233\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1565 - accuracy: 0.9824 - val_loss: 0.3505 - val_accuracy: 0.9233\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 1.00 - 0s 20us/sample - loss: 0.1533 - accuracy: 0.9903 - val_loss: 0.3834 - val_accuracy: 0.9233\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1498 - accuracy: 0.9894 - val_loss: 0.3613 - val_accuracy: 0.9267\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1445 - accuracy: 0.9917 - val_loss: 0.3921 - val_accuracy: 0.9267\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1516 - accuracy: 0.9889 - val_loss: 0.3738 - val_accuracy: 0.9267\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1532 - accuracy: 0.9884 - val_loss: 0.3865 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1569 - accuracy: 0.9843 - val_loss: 0.3679 - val_accuracy: 0.9233\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1479 - accuracy: 0.9907 - val_loss: 0.3829 - val_accuracy: 0.9267\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1537 - accuracy: 0.9838 - val_loss: 0.3439 - val_accuracy: 0.9233\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.99 - 0s 21us/sample - loss: 0.1450 - accuracy: 0.9903 - val_loss: 0.4007 - val_accuracy: 0.9200\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1502 - accuracy: 0.9880 - val_loss: 0.3860 - val_accuracy: 0.9167\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1514 - accuracy: 0.9875 - val_loss: 0.3989 - val_accuracy: 0.9200\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1495 - accuracy: 0.9866 - val_loss: 0.4026 - val_accuracy: 0.9200\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1500 - accuracy: 0.9847 - val_loss: 0.4139 - val_accuracy: 0.9267\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1502 - accuracy: 0.9852 - val_loss: 0.3847 - val_accuracy: 0.9267\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1525 - accuracy: 0.9861 - val_loss: 0.3922 - val_accuracy: 0.9267\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1512 - accuracy: 0.9870 - val_loss: 0.3905 - val_accuracy: 0.9233\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1467 - accuracy: 0.9898 - val_loss: 0.3806 - val_accuracy: 0.9167\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1444 - accuracy: 0.9898 - val_loss: 0.3640 - val_accuracy: 0.9267\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1487 - accuracy: 0.9875 - val_loss: 0.3794 - val_accuracy: 0.9200\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1483 - accuracy: 0.9875 - val_loss: 0.3839 - val_accuracy: 0.9200\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1587 - accuracy: 0.9796 - val_loss: 0.3652 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1501 - accuracy: 0.9889 - val_loss: 0.3776 - val_accuracy: 0.9267\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1418 - accuracy: 0.9921 - val_loss: 0.3803 - val_accuracy: 0.9200\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1441 - accuracy: 0.9898 - val_loss: 0.3484 - val_accuracy: 0.9200\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1463 - accuracy: 0.9880 - val_loss: 0.3794 - val_accuracy: 0.9200\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1404 - accuracy: 0.9917 - val_loss: 0.3685 - val_accuracy: 0.9167\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1515 - accuracy: 0.9880 - val_loss: 0.4173 - val_accuracy: 0.9200\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1479 - accuracy: 0.9870 - val_loss: 0.3727 - val_accuracy: 0.9200\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1440 - accuracy: 0.9898 - val_loss: 0.3899 - val_accuracy: 0.9233\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1415 - accuracy: 0.9903 - val_loss: 0.4172 - val_accuracy: 0.9200\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1433 - accuracy: 0.9898 - val_loss: 0.3841 - val_accuracy: 0.9167\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1452 - accuracy: 0.9880 - val_loss: 0.3972 - val_accuracy: 0.9200\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1418 - accuracy: 0.9875 - val_loss: 0.3976 - val_accuracy: 0.9200\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1443 - accuracy: 0.9847 - val_loss: 0.3719 - val_accuracy: 0.9200\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1430 - accuracy: 0.9889 - val_loss: 0.4304 - val_accuracy: 0.9167\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1416 - accuracy: 0.9903 - val_loss: 0.3609 - val_accuracy: 0.9333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1435 - accuracy: 0.9880 - val_loss: 0.4024 - val_accuracy: 0.9233\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1425 - accuracy: 0.9889 - val_loss: 0.3930 - val_accuracy: 0.9233\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1406 - accuracy: 0.9894 - val_loss: 0.3733 - val_accuracy: 0.9267\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1459 - accuracy: 0.9870 - val_loss: 0.3810 - val_accuracy: 0.9233\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1489 - accuracy: 0.9866 - val_loss: 0.3840 - val_accuracy: 0.9167\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1439 - accuracy: 0.9866 - val_loss: 0.3885 - val_accuracy: 0.9267\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1402 - accuracy: 0.9921 - val_loss: 0.3811 - val_accuracy: 0.9267\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1388 - accuracy: 0.9907 - val_loss: 0.3726 - val_accuracy: 0.9233\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1408 - accuracy: 0.9894 - val_loss: 0.3901 - val_accuracy: 0.9200\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1442 - accuracy: 0.9875 - val_loss: 0.3780 - val_accuracy: 0.9233\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1391 - accuracy: 0.9898 - val_loss: 0.3894 - val_accuracy: 0.9200\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1433 - accuracy: 0.9884 - val_loss: 0.4129 - val_accuracy: 0.9200\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1439 - accuracy: 0.9884 - val_loss: 0.4100 - val_accuracy: 0.9200\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1418 - accuracy: 0.9866 - val_loss: 0.3653 - val_accuracy: 0.9200\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1430 - accuracy: 0.9884 - val_loss: 0.3533 - val_accuracy: 0.9233\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1368 - accuracy: 0.9926 - val_loss: 0.3681 - val_accuracy: 0.9233\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1366 - accuracy: 0.9921 - val_loss: 0.3444 - val_accuracy: 0.9267\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1450 - accuracy: 0.9880 - val_loss: 0.3789 - val_accuracy: 0.9233\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1411 - accuracy: 0.9894 - val_loss: 0.3667 - val_accuracy: 0.9233\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1383 - accuracy: 0.9894 - val_loss: 0.3744 - val_accuracy: 0.9267\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1374 - accuracy: 0.9907 - val_loss: 0.3820 - val_accuracy: 0.9300\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1391 - accuracy: 0.9894 - val_loss: 0.3827 - val_accuracy: 0.9267\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1388 - accuracy: 0.9889 - val_loss: 0.3763 - val_accuracy: 0.9300\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1359 - accuracy: 0.9926 - val_loss: 0.3643 - val_accuracy: 0.9300\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1348 - accuracy: 0.9903 - val_loss: 0.3738 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1367 - accuracy: 0.9907 - val_loss: 0.3813 - val_accuracy: 0.9233\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1346 - accuracy: 0.9903 - val_loss: 0.4013 - val_accuracy: 0.9233\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1439 - accuracy: 0.9884 - val_loss: 0.4098 - val_accuracy: 0.9200\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1372 - accuracy: 0.9894 - val_loss: 0.3874 - val_accuracy: 0.9233\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1341 - accuracy: 0.9898 - val_loss: 0.4108 - val_accuracy: 0.9233\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1356 - accuracy: 0.9875 - val_loss: 0.4149 - val_accuracy: 0.9167\n",
      "540/540 [==============================] - 0s 265us/sample - loss: 0.2773 - accuracy: 0.9519\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 481us/sample - loss: 2.3762 - accuracy: 0.4856 - val_loss: 2.0892 - val_accuracy: 0.5300\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 2.0095 - accuracy: 0.6750 - val_loss: 1.8563 - val_accuracy: 0.7700\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.7962 - accuracy: 0.7778 - val_loss: 1.6779 - val_accuracy: 0.8300\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.6425 - accuracy: 0.8250 - val_loss: 1.5346 - val_accuracy: 0.8367\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.5014 - accuracy: 0.8333 - val_loss: 1.4082 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3719 - accuracy: 0.8398 - val_loss: 1.2966 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2715 - accuracy: 0.8444 - val_loss: 1.1984 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1771 - accuracy: 0.8435 - val_loss: 1.1106 - val_accuracy: 0.8367\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0966 - accuracy: 0.8491 - val_loss: 1.0303 - val_accuracy: 0.8367\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0171 - accuracy: 0.8481 - val_loss: 0.9572 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9581 - accuracy: 0.8440 - val_loss: 0.8926 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8777 - accuracy: 0.8495 - val_loss: 0.8352 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8372 - accuracy: 0.8458 - val_loss: 0.7831 - val_accuracy: 0.8400\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7729 - accuracy: 0.8542 - val_loss: 0.7351 - val_accuracy: 0.8433\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7522 - accuracy: 0.8472 - val_loss: 0.6920 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6895 - accuracy: 0.8588 - val_loss: 0.6535 - val_accuracy: 0.8467\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6545 - accuracy: 0.8560 - val_loss: 0.6233 - val_accuracy: 0.8500\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6138 - accuracy: 0.8588 - val_loss: 0.5919 - val_accuracy: 0.8500\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5893 - accuracy: 0.8653 - val_loss: 0.5634 - val_accuracy: 0.8500\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5505 - accuracy: 0.8755 - val_loss: 0.5376 - val_accuracy: 0.8500\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5248 - accuracy: 0.8787 - val_loss: 0.5172 - val_accuracy: 0.8500\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5007 - accuracy: 0.8810 - val_loss: 0.5024 - val_accuracy: 0.8533\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4822 - accuracy: 0.8935 - val_loss: 0.4848 - val_accuracy: 0.8700\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4633 - accuracy: 0.8968 - val_loss: 0.4752 - val_accuracy: 0.8733\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4321 - accuracy: 0.9005 - val_loss: 0.4580 - val_accuracy: 0.9000\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4308 - accuracy: 0.9023 - val_loss: 0.4585 - val_accuracy: 0.8933\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4090 - accuracy: 0.9102 - val_loss: 0.4457 - val_accuracy: 0.9033\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3868 - accuracy: 0.9259 - val_loss: 0.4341 - val_accuracy: 0.9133\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3781 - accuracy: 0.9167 - val_loss: 0.4144 - val_accuracy: 0.9267\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3727 - accuracy: 0.9241 - val_loss: 0.4064 - val_accuracy: 0.9400\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3559 - accuracy: 0.9375 - val_loss: 0.3994 - val_accuracy: 0.9267\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3435 - accuracy: 0.9338 - val_loss: 0.3957 - val_accuracy: 0.9167\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3293 - accuracy: 0.9412 - val_loss: 0.3888 - val_accuracy: 0.9267\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3327 - accuracy: 0.9398 - val_loss: 0.3891 - val_accuracy: 0.9200\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3216 - accuracy: 0.9477 - val_loss: 0.3825 - val_accuracy: 0.9267\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3094 - accuracy: 0.9500 - val_loss: 0.3691 - val_accuracy: 0.9367\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3038 - accuracy: 0.9523 - val_loss: 0.3764 - val_accuracy: 0.9300\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3041 - accuracy: 0.9472 - val_loss: 0.3712 - val_accuracy: 0.9300\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2909 - accuracy: 0.9579 - val_loss: 0.3681 - val_accuracy: 0.9267\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2808 - accuracy: 0.9537 - val_loss: 0.3588 - val_accuracy: 0.9333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2818 - accuracy: 0.9523 - val_loss: 0.3531 - val_accuracy: 0.9267\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2701 - accuracy: 0.9662 - val_loss: 0.3437 - val_accuracy: 0.9300\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2689 - accuracy: 0.9574 - val_loss: 0.3420 - val_accuracy: 0.9333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2592 - accuracy: 0.9653 - val_loss: 0.3330 - val_accuracy: 0.9400\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2575 - accuracy: 0.9657 - val_loss: 0.3443 - val_accuracy: 0.9433\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2535 - accuracy: 0.9639 - val_loss: 0.3332 - val_accuracy: 0.9400\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2580 - accuracy: 0.9657 - val_loss: 0.3325 - val_accuracy: 0.9467\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2433 - accuracy: 0.9708 - val_loss: 0.3281 - val_accuracy: 0.9433\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2437 - accuracy: 0.9667 - val_loss: 0.3174 - val_accuracy: 0.9467\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2405 - accuracy: 0.9713 - val_loss: 0.3216 - val_accuracy: 0.9367\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2317 - accuracy: 0.9741 - val_loss: 0.3283 - val_accuracy: 0.9400\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2395 - accuracy: 0.9694 - val_loss: 0.3258 - val_accuracy: 0.9400\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2385 - accuracy: 0.9690 - val_loss: 0.3240 - val_accuracy: 0.9433\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2249 - accuracy: 0.9718 - val_loss: 0.3091 - val_accuracy: 0.9467\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2231 - accuracy: 0.9745 - val_loss: 0.3290 - val_accuracy: 0.9367\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2219 - accuracy: 0.9741 - val_loss: 0.3292 - val_accuracy: 0.9400\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2255 - accuracy: 0.9690 - val_loss: 0.3239 - val_accuracy: 0.9367\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2227 - accuracy: 0.9782 - val_loss: 0.3156 - val_accuracy: 0.9400\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2176 - accuracy: 0.9727 - val_loss: 0.3290 - val_accuracy: 0.9333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2217 - accuracy: 0.9741 - val_loss: 0.3145 - val_accuracy: 0.9367\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2108 - accuracy: 0.9773 - val_loss: 0.3297 - val_accuracy: 0.9400\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2168 - accuracy: 0.9741 - val_loss: 0.3268 - val_accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2102 - accuracy: 0.9750 - val_loss: 0.3197 - val_accuracy: 0.9433\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2108 - accuracy: 0.9769 - val_loss: 0.3106 - val_accuracy: 0.9433\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2073 - accuracy: 0.9810 - val_loss: 0.3199 - val_accuracy: 0.9467\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2071 - accuracy: 0.9769 - val_loss: 0.3095 - val_accuracy: 0.9433\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2040 - accuracy: 0.9810 - val_loss: 0.3172 - val_accuracy: 0.9367\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1955 - accuracy: 0.9847 - val_loss: 0.3211 - val_accuracy: 0.9367\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2069 - accuracy: 0.9741 - val_loss: 0.3330 - val_accuracy: 0.9367\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1936 - accuracy: 0.9815 - val_loss: 0.3305 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1991 - accuracy: 0.9806 - val_loss: 0.3251 - val_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1969 - accuracy: 0.9801 - val_loss: 0.3203 - val_accuracy: 0.9367\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1967 - accuracy: 0.9796 - val_loss: 0.3325 - val_accuracy: 0.9367\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1919 - accuracy: 0.9847 - val_loss: 0.3374 - val_accuracy: 0.9367\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1984 - accuracy: 0.9750 - val_loss: 0.3218 - val_accuracy: 0.9367\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1905 - accuracy: 0.9824 - val_loss: 0.3100 - val_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1943 - accuracy: 0.9815 - val_loss: 0.3193 - val_accuracy: 0.9367\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1916 - accuracy: 0.9787 - val_loss: 0.3241 - val_accuracy: 0.9300\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1881 - accuracy: 0.9806 - val_loss: 0.3124 - val_accuracy: 0.9400\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1880 - accuracy: 0.9861 - val_loss: 0.3094 - val_accuracy: 0.9400\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1870 - accuracy: 0.9838 - val_loss: 0.3036 - val_accuracy: 0.9433\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1857 - accuracy: 0.9833 - val_loss: 0.3144 - val_accuracy: 0.9367\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1867 - accuracy: 0.9829 - val_loss: 0.3263 - val_accuracy: 0.9400\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1914 - accuracy: 0.9796 - val_loss: 0.3153 - val_accuracy: 0.9433\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1898 - accuracy: 0.9782 - val_loss: 0.3287 - val_accuracy: 0.9333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1872 - accuracy: 0.9806 - val_loss: 0.3197 - val_accuracy: 0.9400\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1821 - accuracy: 0.9866 - val_loss: 0.3162 - val_accuracy: 0.9400\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1869 - accuracy: 0.9815 - val_loss: 0.3144 - val_accuracy: 0.9400\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1805 - accuracy: 0.9829 - val_loss: 0.3232 - val_accuracy: 0.9433\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1836 - accuracy: 0.9810 - val_loss: 0.3218 - val_accuracy: 0.9400\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1809 - accuracy: 0.9829 - val_loss: 0.3263 - val_accuracy: 0.9400\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1805 - accuracy: 0.9838 - val_loss: 0.3275 - val_accuracy: 0.9400\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1742 - accuracy: 0.9847 - val_loss: 0.3268 - val_accuracy: 0.9367\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1818 - accuracy: 0.9806 - val_loss: 0.3231 - val_accuracy: 0.9400\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1775 - accuracy: 0.9847 - val_loss: 0.3284 - val_accuracy: 0.9367\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1817 - accuracy: 0.9824 - val_loss: 0.3178 - val_accuracy: 0.9433\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1743 - accuracy: 0.9829 - val_loss: 0.3098 - val_accuracy: 0.9400\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1759 - accuracy: 0.9829 - val_loss: 0.3208 - val_accuracy: 0.9367\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1793 - accuracy: 0.9833 - val_loss: 0.3084 - val_accuracy: 0.9367\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1771 - accuracy: 0.9815 - val_loss: 0.3057 - val_accuracy: 0.9400\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1694 - accuracy: 0.9856 - val_loss: 0.3002 - val_accuracy: 0.9433\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1718 - accuracy: 0.9884 - val_loss: 0.3064 - val_accuracy: 0.9433\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1748 - accuracy: 0.9829 - val_loss: 0.3207 - val_accuracy: 0.9400\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1724 - accuracy: 0.9833 - val_loss: 0.3055 - val_accuracy: 0.9467\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1775 - accuracy: 0.9838 - val_loss: 0.3241 - val_accuracy: 0.9333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1785 - accuracy: 0.9792 - val_loss: 0.3138 - val_accuracy: 0.9333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1772 - accuracy: 0.9815 - val_loss: 0.3343 - val_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1729 - accuracy: 0.9833 - val_loss: 0.3121 - val_accuracy: 0.9300\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1802 - accuracy: 0.9792 - val_loss: 0.3163 - val_accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1750 - accuracy: 0.9810 - val_loss: 0.3265 - val_accuracy: 0.9367\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1818 - accuracy: 0.9810 - val_loss: 0.3116 - val_accuracy: 0.9400\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1755 - accuracy: 0.9833 - val_loss: 0.3122 - val_accuracy: 0.9433\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1689 - accuracy: 0.9833 - val_loss: 0.3308 - val_accuracy: 0.9400\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1730 - accuracy: 0.9819 - val_loss: 0.2942 - val_accuracy: 0.9400\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1714 - accuracy: 0.9829 - val_loss: 0.3117 - val_accuracy: 0.9400\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1654 - accuracy: 0.9838 - val_loss: 0.3358 - val_accuracy: 0.9367\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1689 - accuracy: 0.9852 - val_loss: 0.3196 - val_accuracy: 0.9367\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1624 - accuracy: 0.9875 - val_loss: 0.3206 - val_accuracy: 0.9367\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1717 - accuracy: 0.9838 - val_loss: 0.3227 - val_accuracy: 0.9333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1678 - accuracy: 0.9838 - val_loss: 0.3252 - val_accuracy: 0.9367\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1687 - accuracy: 0.9829 - val_loss: 0.3103 - val_accuracy: 0.9367\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1704 - accuracy: 0.9801 - val_loss: 0.3089 - val_accuracy: 0.9400\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1617 - accuracy: 0.9875 - val_loss: 0.3132 - val_accuracy: 0.9433\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1637 - accuracy: 0.9838 - val_loss: 0.3307 - val_accuracy: 0.9367\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1628 - accuracy: 0.9880 - val_loss: 0.3295 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1604 - accuracy: 0.9884 - val_loss: 0.3244 - val_accuracy: 0.9333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1581 - accuracy: 0.9884 - val_loss: 0.2964 - val_accuracy: 0.9367\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1658 - accuracy: 0.9847 - val_loss: 0.3343 - val_accuracy: 0.9300\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1708 - accuracy: 0.9810 - val_loss: 0.3204 - val_accuracy: 0.9367\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1593 - accuracy: 0.9870 - val_loss: 0.3266 - val_accuracy: 0.9367\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1627 - accuracy: 0.9861 - val_loss: 0.3179 - val_accuracy: 0.9400\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1640 - accuracy: 0.9824 - val_loss: 0.3232 - val_accuracy: 0.9333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1601 - accuracy: 0.9856 - val_loss: 0.3171 - val_accuracy: 0.9300\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1616 - accuracy: 0.9852 - val_loss: 0.3405 - val_accuracy: 0.9367\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1667 - accuracy: 0.9852 - val_loss: 0.3194 - val_accuracy: 0.9367\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1567 - accuracy: 0.9875 - val_loss: 0.3305 - val_accuracy: 0.9333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1645 - accuracy: 0.9819 - val_loss: 0.3189 - val_accuracy: 0.9400\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1580 - accuracy: 0.9838 - val_loss: 0.3406 - val_accuracy: 0.9400\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1687 - accuracy: 0.9801 - val_loss: 0.3361 - val_accuracy: 0.9333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1656 - accuracy: 0.9819 - val_loss: 0.3491 - val_accuracy: 0.9333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1653 - accuracy: 0.9838 - val_loss: 0.3226 - val_accuracy: 0.9367\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1709 - accuracy: 0.9787 - val_loss: 0.3752 - val_accuracy: 0.9300\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1665 - accuracy: 0.9829 - val_loss: 0.3423 - val_accuracy: 0.9267\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1723 - accuracy: 0.9796 - val_loss: 0.3314 - val_accuracy: 0.9400\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1534 - accuracy: 0.9894 - val_loss: 0.3348 - val_accuracy: 0.9400\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1587 - accuracy: 0.9866 - val_loss: 0.3393 - val_accuracy: 0.9367\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1609 - accuracy: 0.9833 - val_loss: 0.3333 - val_accuracy: 0.9400\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1629 - accuracy: 0.9815 - val_loss: 0.3046 - val_accuracy: 0.9467\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1580 - accuracy: 0.9870 - val_loss: 0.3119 - val_accuracy: 0.9367\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1578 - accuracy: 0.9843 - val_loss: 0.3334 - val_accuracy: 0.9333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1613 - accuracy: 0.9824 - val_loss: 0.3259 - val_accuracy: 0.9333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1549 - accuracy: 0.9884 - val_loss: 0.3121 - val_accuracy: 0.9300\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1588 - accuracy: 0.9847 - val_loss: 0.3080 - val_accuracy: 0.9300\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1558 - accuracy: 0.9894 - val_loss: 0.3252 - val_accuracy: 0.9333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1512 - accuracy: 0.9907 - val_loss: 0.3122 - val_accuracy: 0.9367\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1628 - accuracy: 0.9852 - val_loss: 0.3321 - val_accuracy: 0.9300\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1585 - accuracy: 0.9829 - val_loss: 0.3198 - val_accuracy: 0.9300\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1544 - accuracy: 0.9847 - val_loss: 0.3161 - val_accuracy: 0.9367\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1585 - accuracy: 0.9856 - val_loss: 0.3352 - val_accuracy: 0.9300\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1555 - accuracy: 0.9819 - val_loss: 0.3014 - val_accuracy: 0.9400\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1555 - accuracy: 0.9856 - val_loss: 0.3248 - val_accuracy: 0.9400\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1573 - accuracy: 0.9861 - val_loss: 0.3471 - val_accuracy: 0.9333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1595 - accuracy: 0.9833 - val_loss: 0.3208 - val_accuracy: 0.9400\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1583 - accuracy: 0.9852 - val_loss: 0.3238 - val_accuracy: 0.9400\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1598 - accuracy: 0.9833 - val_loss: 0.3284 - val_accuracy: 0.9367\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1528 - accuracy: 0.9856 - val_loss: 0.2914 - val_accuracy: 0.9367\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1534 - accuracy: 0.9866 - val_loss: 0.3034 - val_accuracy: 0.9333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1502 - accuracy: 0.9856 - val_loss: 0.3147 - val_accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1644 - accuracy: 0.9801 - val_loss: 0.3053 - val_accuracy: 0.9467\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1557 - accuracy: 0.9856 - val_loss: 0.3181 - val_accuracy: 0.9367\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1555 - accuracy: 0.9856 - val_loss: 0.3263 - val_accuracy: 0.9400\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1467 - accuracy: 0.9903 - val_loss: 0.3191 - val_accuracy: 0.9400\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1601 - accuracy: 0.9843 - val_loss: 0.3199 - val_accuracy: 0.9367\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1538 - accuracy: 0.9852 - val_loss: 0.3333 - val_accuracy: 0.9333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1470 - accuracy: 0.9884 - val_loss: 0.3609 - val_accuracy: 0.9333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1575 - accuracy: 0.9843 - val_loss: 0.3396 - val_accuracy: 0.9300\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1488 - accuracy: 0.9852 - val_loss: 0.3264 - val_accuracy: 0.9300\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1488 - accuracy: 0.9866 - val_loss: 0.3236 - val_accuracy: 0.9333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1463 - accuracy: 0.9894 - val_loss: 0.3468 - val_accuracy: 0.9333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1478 - accuracy: 0.9884 - val_loss: 0.3475 - val_accuracy: 0.9367\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1496 - accuracy: 0.9838 - val_loss: 0.3471 - val_accuracy: 0.9400\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1501 - accuracy: 0.9861 - val_loss: 0.3159 - val_accuracy: 0.9433\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1471 - accuracy: 0.9880 - val_loss: 0.3444 - val_accuracy: 0.9300\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1489 - accuracy: 0.9884 - val_loss: 0.3266 - val_accuracy: 0.9367\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1471 - accuracy: 0.9866 - val_loss: 0.3178 - val_accuracy: 0.9300\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1479 - accuracy: 0.9843 - val_loss: 0.3240 - val_accuracy: 0.9367\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1532 - accuracy: 0.9861 - val_loss: 0.3479 - val_accuracy: 0.9300\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1519 - accuracy: 0.9866 - val_loss: 0.3303 - val_accuracy: 0.9333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1444 - accuracy: 0.9898 - val_loss: 0.3374 - val_accuracy: 0.9433\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1481 - accuracy: 0.9847 - val_loss: 0.3496 - val_accuracy: 0.9300\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1464 - accuracy: 0.9875 - val_loss: 0.3372 - val_accuracy: 0.9367\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.1476 - accuracy: 0.9861 - val_loss: 0.3557 - val_accuracy: 0.9367\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1445 - accuracy: 0.9903 - val_loss: 0.3422 - val_accuracy: 0.9267\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1427 - accuracy: 0.9861 - val_loss: 0.3450 - val_accuracy: 0.9333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.1454 - accuracy: 0.9880 - val_loss: 0.3555 - val_accuracy: 0.9367\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.99 - 0s 20us/sample - loss: 0.1435 - accuracy: 0.9907 - val_loss: 0.3492 - val_accuracy: 0.9367\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1522 - accuracy: 0.9861 - val_loss: 0.3608 - val_accuracy: 0.9367\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1524 - accuracy: 0.9838 - val_loss: 0.3400 - val_accuracy: 0.9300\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.1409 - accuracy: 0.9931 - val_loss: 0.3522 - val_accuracy: 0.9333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1465 - accuracy: 0.9880 - val_loss: 0.3418 - val_accuracy: 0.9267\n",
      "540/540 [==============================] - 0s 271us/sample - loss: 0.2295 - accuracy: 0.9556\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 391us/sample - loss: 3.6562 - accuracy: 0.6343 - val_loss: 3.2848 - val_accuracy: 0.8267\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.1374 - accuracy: 0.8204 - val_loss: 2.8948 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.7419 - accuracy: 0.8481 - val_loss: 2.5506 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.4071 - accuracy: 0.8500 - val_loss: 2.2452 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.1254 - accuracy: 0.8551 - val_loss: 1.9769 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8654 - accuracy: 0.8597 - val_loss: 1.7426 - val_accuracy: 0.8533\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.6415 - accuracy: 0.8657 - val_loss: 1.5397 - val_accuracy: 0.8733\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.4543 - accuracy: 0.8708 - val_loss: 1.3687 - val_accuracy: 0.8767\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2827 - accuracy: 0.8773 - val_loss: 1.2187 - val_accuracy: 0.8800\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1429 - accuracy: 0.8769 - val_loss: 1.0939 - val_accuracy: 0.8833\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0286 - accuracy: 0.8833 - val_loss: 0.9824 - val_accuracy: 0.8867\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.9197 - accuracy: 0.8991 - val_loss: 0.8855 - val_accuracy: 0.8900\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8453 - accuracy: 0.8926 - val_loss: 0.8069 - val_accuracy: 0.8967\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7533 - accuracy: 0.9042 - val_loss: 0.7408 - val_accuracy: 0.9067\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6868 - accuracy: 0.9088 - val_loss: 0.6811 - val_accuracy: 0.9100\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6327 - accuracy: 0.9231 - val_loss: 0.6351 - val_accuracy: 0.9133\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5796 - accuracy: 0.9269 - val_loss: 0.5938 - val_accuracy: 0.9133\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5262 - accuracy: 0.9356 - val_loss: 0.5597 - val_accuracy: 0.9100\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4888 - accuracy: 0.9426 - val_loss: 0.5246 - val_accuracy: 0.9200\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4575 - accuracy: 0.9481 - val_loss: 0.5040 - val_accuracy: 0.9167\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4235 - accuracy: 0.9491 - val_loss: 0.4853 - val_accuracy: 0.9300\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3900 - accuracy: 0.9565 - val_loss: 0.4588 - val_accuracy: 0.9333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3690 - accuracy: 0.9560 - val_loss: 0.4453 - val_accuracy: 0.9267\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3603 - accuracy: 0.9602 - val_loss: 0.4135 - val_accuracy: 0.9267\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3314 - accuracy: 0.9657 - val_loss: 0.4049 - val_accuracy: 0.9333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3081 - accuracy: 0.9764 - val_loss: 0.4013 - val_accuracy: 0.9233\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2898 - accuracy: 0.9782 - val_loss: 0.3866 - val_accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2913 - accuracy: 0.9718 - val_loss: 0.3956 - val_accuracy: 0.9300\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2708 - accuracy: 0.9819 - val_loss: 0.3850 - val_accuracy: 0.9267\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2564 - accuracy: 0.9829 - val_loss: 0.3929 - val_accuracy: 0.9233\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2523 - accuracy: 0.9806 - val_loss: 0.3734 - val_accuracy: 0.9233\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2431 - accuracy: 0.9833 - val_loss: 0.3568 - val_accuracy: 0.9333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2399 - accuracy: 0.9819 - val_loss: 0.3794 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2330 - accuracy: 0.9810 - val_loss: 0.3580 - val_accuracy: 0.9333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2247 - accuracy: 0.9815 - val_loss: 0.3573 - val_accuracy: 0.9333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2207 - accuracy: 0.9833 - val_loss: 0.3549 - val_accuracy: 0.9300\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2073 - accuracy: 0.9907 - val_loss: 0.3428 - val_accuracy: 0.9267\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2079 - accuracy: 0.9856 - val_loss: 0.3519 - val_accuracy: 0.9267\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2094 - accuracy: 0.9852 - val_loss: 0.3486 - val_accuracy: 0.9267\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2051 - accuracy: 0.9838 - val_loss: 0.3671 - val_accuracy: 0.9300\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2032 - accuracy: 0.9856 - val_loss: 0.3654 - val_accuracy: 0.9267\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2000 - accuracy: 0.9843 - val_loss: 0.3633 - val_accuracy: 0.9267\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1971 - accuracy: 0.9884 - val_loss: 0.3554 - val_accuracy: 0.9233\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1894 - accuracy: 0.9866 - val_loss: 0.3392 - val_accuracy: 0.9300\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1828 - accuracy: 0.9921 - val_loss: 0.3479 - val_accuracy: 0.9333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1808 - accuracy: 0.9898 - val_loss: 0.3553 - val_accuracy: 0.9267\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1839 - accuracy: 0.9898 - val_loss: 0.3509 - val_accuracy: 0.9333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1788 - accuracy: 0.9917 - val_loss: 0.3611 - val_accuracy: 0.9333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1822 - accuracy: 0.9838 - val_loss: 0.3475 - val_accuracy: 0.9333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1756 - accuracy: 0.9889 - val_loss: 0.3311 - val_accuracy: 0.9367\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1710 - accuracy: 0.9921 - val_loss: 0.3150 - val_accuracy: 0.9300\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1725 - accuracy: 0.9880 - val_loss: 0.3250 - val_accuracy: 0.9333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1720 - accuracy: 0.9898 - val_loss: 0.3323 - val_accuracy: 0.9400\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1631 - accuracy: 0.9935 - val_loss: 0.3443 - val_accuracy: 0.9333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1664 - accuracy: 0.9907 - val_loss: 0.3441 - val_accuracy: 0.9367\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1662 - accuracy: 0.9907 - val_loss: 0.3193 - val_accuracy: 0.9433\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1660 - accuracy: 0.9889 - val_loss: 0.3302 - val_accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1655 - accuracy: 0.9894 - val_loss: 0.3257 - val_accuracy: 0.9333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1611 - accuracy: 0.9935 - val_loss: 0.3269 - val_accuracy: 0.9300\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1622 - accuracy: 0.9889 - val_loss: 0.3129 - val_accuracy: 0.9367\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1618 - accuracy: 0.9912 - val_loss: 0.3339 - val_accuracy: 0.9300\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1637 - accuracy: 0.9894 - val_loss: 0.3366 - val_accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1613 - accuracy: 0.9898 - val_loss: 0.3285 - val_accuracy: 0.9400\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1579 - accuracy: 0.9926 - val_loss: 0.3410 - val_accuracy: 0.9400\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1506 - accuracy: 0.9954 - val_loss: 0.3277 - val_accuracy: 0.9400\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1574 - accuracy: 0.9894 - val_loss: 0.3240 - val_accuracy: 0.9333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1530 - accuracy: 0.9917 - val_loss: 0.3215 - val_accuracy: 0.9300\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1557 - accuracy: 0.9931 - val_loss: 0.3191 - val_accuracy: 0.9367\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1527 - accuracy: 0.9940 - val_loss: 0.3487 - val_accuracy: 0.9333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1518 - accuracy: 0.9912 - val_loss: 0.3498 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1538 - accuracy: 0.9917 - val_loss: 0.3309 - val_accuracy: 0.9300\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1593 - accuracy: 0.9847 - val_loss: 0.3248 - val_accuracy: 0.9233\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1525 - accuracy: 0.9917 - val_loss: 0.3193 - val_accuracy: 0.9267\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1485 - accuracy: 0.9921 - val_loss: 0.3099 - val_accuracy: 0.9367\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1522 - accuracy: 0.9903 - val_loss: 0.3190 - val_accuracy: 0.9367\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1569 - accuracy: 0.9875 - val_loss: 0.3286 - val_accuracy: 0.9400\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1482 - accuracy: 0.9931 - val_loss: 0.3242 - val_accuracy: 0.9300\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1505 - accuracy: 0.9917 - val_loss: 0.3314 - val_accuracy: 0.9300\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1449 - accuracy: 0.9944 - val_loss: 0.3331 - val_accuracy: 0.9300\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1522 - accuracy: 0.9894 - val_loss: 0.3365 - val_accuracy: 0.9300\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1480 - accuracy: 0.9917 - val_loss: 0.3282 - val_accuracy: 0.9200\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1447 - accuracy: 0.9926 - val_loss: 0.3228 - val_accuracy: 0.9267\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1503 - accuracy: 0.9898 - val_loss: 0.3214 - val_accuracy: 0.9367\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1470 - accuracy: 0.9912 - val_loss: 0.3092 - val_accuracy: 0.9367\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1507 - accuracy: 0.9898 - val_loss: 0.2990 - val_accuracy: 0.9400\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1399 - accuracy: 0.9954 - val_loss: 0.3287 - val_accuracy: 0.9367\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1429 - accuracy: 0.9935 - val_loss: 0.3071 - val_accuracy: 0.9400\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1458 - accuracy: 0.9917 - val_loss: 0.3121 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1496 - accuracy: 0.9884 - val_loss: 0.3267 - val_accuracy: 0.9300\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1459 - accuracy: 0.9921 - val_loss: 0.3196 - val_accuracy: 0.9367\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1415 - accuracy: 0.9931 - val_loss: 0.3130 - val_accuracy: 0.9400\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1450 - accuracy: 0.9917 - val_loss: 0.3024 - val_accuracy: 0.9367\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1471 - accuracy: 0.9903 - val_loss: 0.3266 - val_accuracy: 0.9367\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1447 - accuracy: 0.9898 - val_loss: 0.3095 - val_accuracy: 0.9367\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1515 - accuracy: 0.9898 - val_loss: 0.3240 - val_accuracy: 0.9367\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1419 - accuracy: 0.9917 - val_loss: 0.3070 - val_accuracy: 0.9400\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1382 - accuracy: 0.9944 - val_loss: 0.2966 - val_accuracy: 0.9367\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1391 - accuracy: 0.9917 - val_loss: 0.3261 - val_accuracy: 0.9333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1419 - accuracy: 0.9921 - val_loss: 0.3261 - val_accuracy: 0.9300\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1436 - accuracy: 0.9940 - val_loss: 0.3098 - val_accuracy: 0.9300\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1399 - accuracy: 0.9926 - val_loss: 0.3255 - val_accuracy: 0.9400\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1363 - accuracy: 0.9935 - val_loss: 0.3155 - val_accuracy: 0.9400\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1369 - accuracy: 0.9940 - val_loss: 0.3013 - val_accuracy: 0.9467\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1407 - accuracy: 0.9912 - val_loss: 0.2996 - val_accuracy: 0.9367\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1436 - accuracy: 0.9903 - val_loss: 0.3278 - val_accuracy: 0.9333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1421 - accuracy: 0.9907 - val_loss: 0.3583 - val_accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1388 - accuracy: 0.9935 - val_loss: 0.3083 - val_accuracy: 0.9400\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1407 - accuracy: 0.9889 - val_loss: 0.2892 - val_accuracy: 0.9367\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1442 - accuracy: 0.9903 - val_loss: 0.3200 - val_accuracy: 0.9300\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1346 - accuracy: 0.9963 - val_loss: 0.3148 - val_accuracy: 0.9333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1406 - accuracy: 0.9926 - val_loss: 0.3295 - val_accuracy: 0.9400\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1389 - accuracy: 0.9926 - val_loss: 0.3145 - val_accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1411 - accuracy: 0.9889 - val_loss: 0.3044 - val_accuracy: 0.9333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1346 - accuracy: 0.9944 - val_loss: 0.3209 - val_accuracy: 0.9333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1364 - accuracy: 0.9903 - val_loss: 0.3092 - val_accuracy: 0.9333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1354 - accuracy: 0.9917 - val_loss: 0.3179 - val_accuracy: 0.9400\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1295 - accuracy: 0.9963 - val_loss: 0.3272 - val_accuracy: 0.9367\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1354 - accuracy: 0.9894 - val_loss: 0.3168 - val_accuracy: 0.9367\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1316 - accuracy: 0.9921 - val_loss: 0.3409 - val_accuracy: 0.9333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1354 - accuracy: 0.9931 - val_loss: 0.3221 - val_accuracy: 0.9267\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1310 - accuracy: 0.9940 - val_loss: 0.3097 - val_accuracy: 0.9333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1312 - accuracy: 0.9935 - val_loss: 0.2984 - val_accuracy: 0.9433\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1346 - accuracy: 0.9907 - val_loss: 0.3086 - val_accuracy: 0.9367\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1344 - accuracy: 0.9940 - val_loss: 0.3199 - val_accuracy: 0.9333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1330 - accuracy: 0.9931 - val_loss: 0.3070 - val_accuracy: 0.9400\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1248 - accuracy: 0.9972 - val_loss: 0.3135 - val_accuracy: 0.9367\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1253 - accuracy: 0.9968 - val_loss: 0.3156 - val_accuracy: 0.9367\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1283 - accuracy: 0.9926 - val_loss: 0.3068 - val_accuracy: 0.9367\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1276 - accuracy: 0.9940 - val_loss: 0.3280 - val_accuracy: 0.9367\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1283 - accuracy: 0.9935 - val_loss: 0.3067 - val_accuracy: 0.9367\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1307 - accuracy: 0.9931 - val_loss: 0.3010 - val_accuracy: 0.9267\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1240 - accuracy: 0.9968 - val_loss: 0.3073 - val_accuracy: 0.9333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1332 - accuracy: 0.9903 - val_loss: 0.3184 - val_accuracy: 0.9367\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1301 - accuracy: 0.9935 - val_loss: 0.3314 - val_accuracy: 0.9333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1287 - accuracy: 0.9931 - val_loss: 0.3407 - val_accuracy: 0.9367\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1268 - accuracy: 0.9954 - val_loss: 0.3117 - val_accuracy: 0.9367\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1337 - accuracy: 0.9898 - val_loss: 0.3019 - val_accuracy: 0.9367\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1252 - accuracy: 0.9958 - val_loss: 0.2948 - val_accuracy: 0.9367\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1251 - accuracy: 0.9949 - val_loss: 0.3198 - val_accuracy: 0.9333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1227 - accuracy: 0.9954 - val_loss: 0.3006 - val_accuracy: 0.9367\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1240 - accuracy: 0.9958 - val_loss: 0.3181 - val_accuracy: 0.9367\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1252 - accuracy: 0.9935 - val_loss: 0.2948 - val_accuracy: 0.9400\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1314 - accuracy: 0.9894 - val_loss: 0.3051 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1274 - accuracy: 0.9935 - val_loss: 0.3002 - val_accuracy: 0.9433\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1286 - accuracy: 0.9940 - val_loss: 0.3019 - val_accuracy: 0.9333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1286 - accuracy: 0.9944 - val_loss: 0.3022 - val_accuracy: 0.9300\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1275 - accuracy: 0.9944 - val_loss: 0.3162 - val_accuracy: 0.9400\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1269 - accuracy: 0.9944 - val_loss: 0.3161 - val_accuracy: 0.9267\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1323 - accuracy: 0.9907 - val_loss: 0.3092 - val_accuracy: 0.9300\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1227 - accuracy: 0.9944 - val_loss: 0.3305 - val_accuracy: 0.9300\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1274 - accuracy: 0.9921 - val_loss: 0.3230 - val_accuracy: 0.9300\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1239 - accuracy: 0.9940 - val_loss: 0.3018 - val_accuracy: 0.9433\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1291 - accuracy: 0.9912 - val_loss: 0.3149 - val_accuracy: 0.9333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1287 - accuracy: 0.9935 - val_loss: 0.3519 - val_accuracy: 0.9367\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1323 - accuracy: 0.9917 - val_loss: 0.3222 - val_accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1344 - accuracy: 0.9898 - val_loss: 0.3447 - val_accuracy: 0.9333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1314 - accuracy: 0.9921 - val_loss: 0.3457 - val_accuracy: 0.9267\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1283 - accuracy: 0.9944 - val_loss: 0.3593 - val_accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1303 - accuracy: 0.9944 - val_loss: 0.3418 - val_accuracy: 0.9267\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1243 - accuracy: 0.9958 - val_loss: 0.3481 - val_accuracy: 0.9333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1212 - accuracy: 0.9954 - val_loss: 0.3336 - val_accuracy: 0.9367\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1268 - accuracy: 0.9940 - val_loss: 0.3219 - val_accuracy: 0.9400\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1282 - accuracy: 0.9931 - val_loss: 0.3258 - val_accuracy: 0.9300\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1261 - accuracy: 0.9926 - val_loss: 0.3042 - val_accuracy: 0.9400\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1230 - accuracy: 0.9931 - val_loss: 0.3032 - val_accuracy: 0.9367\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1272 - accuracy: 0.9931 - val_loss: 0.3142 - val_accuracy: 0.9367\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1239 - accuracy: 0.9926 - val_loss: 0.3044 - val_accuracy: 0.9367\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1221 - accuracy: 0.9954 - val_loss: 0.3132 - val_accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1184 - accuracy: 0.9949 - val_loss: 0.2880 - val_accuracy: 0.9433\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1187 - accuracy: 0.9963 - val_loss: 0.3071 - val_accuracy: 0.9333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1194 - accuracy: 0.9944 - val_loss: 0.3132 - val_accuracy: 0.9400\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1155 - accuracy: 0.9968 - val_loss: 0.3092 - val_accuracy: 0.9400\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1190 - accuracy: 0.9940 - val_loss: 0.3176 - val_accuracy: 0.9367\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1188 - accuracy: 0.9921 - val_loss: 0.2927 - val_accuracy: 0.9400\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1188 - accuracy: 0.9949 - val_loss: 0.3252 - val_accuracy: 0.9333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1156 - accuracy: 0.9958 - val_loss: 0.3345 - val_accuracy: 0.9300\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1186 - accuracy: 0.9940 - val_loss: 0.3385 - val_accuracy: 0.9267\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1181 - accuracy: 0.9940 - val_loss: 0.3186 - val_accuracy: 0.9333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1231 - accuracy: 0.9917 - val_loss: 0.3313 - val_accuracy: 0.9333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1226 - accuracy: 0.9926 - val_loss: 0.3213 - val_accuracy: 0.9300\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1187 - accuracy: 0.9940 - val_loss: 0.3504 - val_accuracy: 0.9267\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1246 - accuracy: 0.9954 - val_loss: 0.3106 - val_accuracy: 0.9300\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1224 - accuracy: 0.9926 - val_loss: 0.2900 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1198 - accuracy: 0.9944 - val_loss: 0.2614 - val_accuracy: 0.9400\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1276 - accuracy: 0.9884 - val_loss: 0.2948 - val_accuracy: 0.9400\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1197 - accuracy: 0.9954 - val_loss: 0.3254 - val_accuracy: 0.9367\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1197 - accuracy: 0.9963 - val_loss: 0.2826 - val_accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1245 - accuracy: 0.9884 - val_loss: 0.2946 - val_accuracy: 0.9367\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1168 - accuracy: 0.9958 - val_loss: 0.3164 - val_accuracy: 0.9300\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1126 - accuracy: 0.9972 - val_loss: 0.3292 - val_accuracy: 0.9333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1204 - accuracy: 0.9931 - val_loss: 0.3193 - val_accuracy: 0.9333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1172 - accuracy: 0.9940 - val_loss: 0.3025 - val_accuracy: 0.9400\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1137 - accuracy: 0.9958 - val_loss: 0.3121 - val_accuracy: 0.9333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1169 - accuracy: 0.9926 - val_loss: 0.2660 - val_accuracy: 0.9300\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1180 - accuracy: 0.9926 - val_loss: 0.2932 - val_accuracy: 0.9333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1181 - accuracy: 0.9921 - val_loss: 0.2951 - val_accuracy: 0.9367\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1147 - accuracy: 0.9954 - val_loss: 0.3035 - val_accuracy: 0.9400\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1128 - accuracy: 0.9958 - val_loss: 0.3159 - val_accuracy: 0.9333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1184 - accuracy: 0.9944 - val_loss: 0.2824 - val_accuracy: 0.9367\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1146 - accuracy: 0.9935 - val_loss: 0.2815 - val_accuracy: 0.9367\n",
      "540/540 [==============================] - 0s 299us/sample - loss: 0.2461 - accuracy: 0.9593\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 371us/sample - loss: 3.6018 - accuracy: 0.6500 - val_loss: 3.1741 - val_accuracy: 0.8300\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 3.0824 - accuracy: 0.8315 - val_loss: 2.8540 - val_accuracy: 0.8300\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.7421 - accuracy: 0.8366 - val_loss: 2.5628 - val_accuracy: 0.8300\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.4555 - accuracy: 0.8435 - val_loss: 2.2971 - val_accuracy: 0.8300\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.1975 - accuracy: 0.8495 - val_loss: 2.0590 - val_accuracy: 0.8300\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.9665 - accuracy: 0.8514 - val_loss: 1.8465 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.7609 - accuracy: 0.8523 - val_loss: 1.6612 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.5850 - accuracy: 0.8556 - val_loss: 1.4931 - val_accuracy: 0.8400\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.87 - 0s 22us/sample - loss: 1.4349 - accuracy: 0.8602 - val_loss: 1.3472 - val_accuracy: 0.8433\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.2886 - accuracy: 0.8588 - val_loss: 1.2178 - val_accuracy: 0.8467\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.1656 - accuracy: 0.8597 - val_loss: 1.1036 - val_accuracy: 0.8633\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0576 - accuracy: 0.8653 - val_loss: 1.0004 - val_accuracy: 0.8633\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9562 - accuracy: 0.8593 - val_loss: 0.9113 - val_accuracy: 0.8733\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8729 - accuracy: 0.8759 - val_loss: 0.8292 - val_accuracy: 0.8933\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7983 - accuracy: 0.8847 - val_loss: 0.7625 - val_accuracy: 0.8933\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7334 - accuracy: 0.8940 - val_loss: 0.7025 - val_accuracy: 0.9033\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6721 - accuracy: 0.9060 - val_loss: 0.6565 - val_accuracy: 0.9100\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6153 - accuracy: 0.9157 - val_loss: 0.6033 - val_accuracy: 0.9300\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5709 - accuracy: 0.9204 - val_loss: 0.5666 - val_accuracy: 0.9300\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5272 - accuracy: 0.9301 - val_loss: 0.5441 - val_accuracy: 0.9300\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4912 - accuracy: 0.9366 - val_loss: 0.5079 - val_accuracy: 0.9367\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4652 - accuracy: 0.9458 - val_loss: 0.4869 - val_accuracy: 0.9400\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4248 - accuracy: 0.9551 - val_loss: 0.4509 - val_accuracy: 0.9367\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4107 - accuracy: 0.9551 - val_loss: 0.4394 - val_accuracy: 0.9400\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3834 - accuracy: 0.9602 - val_loss: 0.4302 - val_accuracy: 0.9433\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3624 - accuracy: 0.9671 - val_loss: 0.4255 - val_accuracy: 0.9333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3466 - accuracy: 0.9625 - val_loss: 0.3880 - val_accuracy: 0.9400\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3293 - accuracy: 0.9681 - val_loss: 0.3881 - val_accuracy: 0.9433\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3074 - accuracy: 0.9713 - val_loss: 0.3730 - val_accuracy: 0.9433\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2981 - accuracy: 0.9741 - val_loss: 0.3866 - val_accuracy: 0.9400\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2854 - accuracy: 0.9769 - val_loss: 0.3527 - val_accuracy: 0.9433\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2785 - accuracy: 0.9778 - val_loss: 0.3760 - val_accuracy: 0.9333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2675 - accuracy: 0.9773 - val_loss: 0.3672 - val_accuracy: 0.9300\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2523 - accuracy: 0.9819 - val_loss: 0.3626 - val_accuracy: 0.9333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2497 - accuracy: 0.9810 - val_loss: 0.3268 - val_accuracy: 0.9433\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2457 - accuracy: 0.9824 - val_loss: 0.3551 - val_accuracy: 0.9333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2399 - accuracy: 0.9815 - val_loss: 0.3581 - val_accuracy: 0.9400\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2291 - accuracy: 0.9843 - val_loss: 0.3340 - val_accuracy: 0.9400\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2284 - accuracy: 0.9843 - val_loss: 0.3142 - val_accuracy: 0.9400\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2198 - accuracy: 0.9852 - val_loss: 0.3401 - val_accuracy: 0.9333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2140 - accuracy: 0.9856 - val_loss: 0.3301 - val_accuracy: 0.9367\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2100 - accuracy: 0.9856 - val_loss: 0.3291 - val_accuracy: 0.9367\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2010 - accuracy: 0.9912 - val_loss: 0.3354 - val_accuracy: 0.9333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1989 - accuracy: 0.9903 - val_loss: 0.3151 - val_accuracy: 0.9367\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1988 - accuracy: 0.9852 - val_loss: 0.3122 - val_accuracy: 0.9333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1985 - accuracy: 0.9861 - val_loss: 0.3068 - val_accuracy: 0.9433\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1907 - accuracy: 0.9889 - val_loss: 0.3202 - val_accuracy: 0.9333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1879 - accuracy: 0.9875 - val_loss: 0.3119 - val_accuracy: 0.9500\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1878 - accuracy: 0.9880 - val_loss: 0.3107 - val_accuracy: 0.9367\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1838 - accuracy: 0.9861 - val_loss: 0.3217 - val_accuracy: 0.9367\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1843 - accuracy: 0.9870 - val_loss: 0.2969 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1818 - accuracy: 0.9880 - val_loss: 0.2953 - val_accuracy: 0.9533\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1843 - accuracy: 0.9875 - val_loss: 0.3085 - val_accuracy: 0.9333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1831 - accuracy: 0.9870 - val_loss: 0.3228 - val_accuracy: 0.9400\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1783 - accuracy: 0.9903 - val_loss: 0.2988 - val_accuracy: 0.9467\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1753 - accuracy: 0.9894 - val_loss: 0.2994 - val_accuracy: 0.9400\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1715 - accuracy: 0.9931 - val_loss: 0.2976 - val_accuracy: 0.9467\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1711 - accuracy: 0.9894 - val_loss: 0.2928 - val_accuracy: 0.9433\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1707 - accuracy: 0.9880 - val_loss: 0.2942 - val_accuracy: 0.9367\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1681 - accuracy: 0.9931 - val_loss: 0.2985 - val_accuracy: 0.9400\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1650 - accuracy: 0.9931 - val_loss: 0.3028 - val_accuracy: 0.9367\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1681 - accuracy: 0.9917 - val_loss: 0.2969 - val_accuracy: 0.9367\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1669 - accuracy: 0.9880 - val_loss: 0.3286 - val_accuracy: 0.9300\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1669 - accuracy: 0.9917 - val_loss: 0.2861 - val_accuracy: 0.9400\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1615 - accuracy: 0.9917 - val_loss: 0.2935 - val_accuracy: 0.9467\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1605 - accuracy: 0.9907 - val_loss: 0.2863 - val_accuracy: 0.9500\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1579 - accuracy: 0.9935 - val_loss: 0.2904 - val_accuracy: 0.9400\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1540 - accuracy: 0.9921 - val_loss: 0.2969 - val_accuracy: 0.9400\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1617 - accuracy: 0.9903 - val_loss: 0.2847 - val_accuracy: 0.9433\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1615 - accuracy: 0.9889 - val_loss: 0.2975 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1609 - accuracy: 0.9907 - val_loss: 0.3017 - val_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1556 - accuracy: 0.9907 - val_loss: 0.2809 - val_accuracy: 0.9333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1532 - accuracy: 0.9921 - val_loss: 0.2975 - val_accuracy: 0.9433\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1619 - accuracy: 0.9889 - val_loss: 0.2987 - val_accuracy: 0.9433\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1551 - accuracy: 0.9912 - val_loss: 0.2683 - val_accuracy: 0.9433\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1551 - accuracy: 0.9921 - val_loss: 0.3176 - val_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1601 - accuracy: 0.9889 - val_loss: 0.2919 - val_accuracy: 0.9367\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1597 - accuracy: 0.9880 - val_loss: 0.2956 - val_accuracy: 0.9300\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1526 - accuracy: 0.9907 - val_loss: 0.2958 - val_accuracy: 0.9300\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1514 - accuracy: 0.9940 - val_loss: 0.2804 - val_accuracy: 0.9400\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1533 - accuracy: 0.9903 - val_loss: 0.2780 - val_accuracy: 0.9400\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1522 - accuracy: 0.9912 - val_loss: 0.2847 - val_accuracy: 0.9400\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1517 - accuracy: 0.9935 - val_loss: 0.2690 - val_accuracy: 0.9467\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1552 - accuracy: 0.9894 - val_loss: 0.2852 - val_accuracy: 0.9367\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1512 - accuracy: 0.9935 - val_loss: 0.2816 - val_accuracy: 0.9433\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1476 - accuracy: 0.9940 - val_loss: 0.2988 - val_accuracy: 0.9367\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1499 - accuracy: 0.9926 - val_loss: 0.2896 - val_accuracy: 0.9400\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1510 - accuracy: 0.9931 - val_loss: 0.3140 - val_accuracy: 0.9400\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1521 - accuracy: 0.9894 - val_loss: 0.3041 - val_accuracy: 0.9367\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1507 - accuracy: 0.9917 - val_loss: 0.2894 - val_accuracy: 0.9467\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1455 - accuracy: 0.9917 - val_loss: 0.2970 - val_accuracy: 0.9467\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1469 - accuracy: 0.9921 - val_loss: 0.2944 - val_accuracy: 0.9400\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1444 - accuracy: 0.9931 - val_loss: 0.2763 - val_accuracy: 0.9400\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1450 - accuracy: 0.9921 - val_loss: 0.2718 - val_accuracy: 0.9367\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1462 - accuracy: 0.9931 - val_loss: 0.2928 - val_accuracy: 0.9400\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1470 - accuracy: 0.9940 - val_loss: 0.2745 - val_accuracy: 0.9400\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1411 - accuracy: 0.9944 - val_loss: 0.3084 - val_accuracy: 0.9433\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1486 - accuracy: 0.9894 - val_loss: 0.2928 - val_accuracy: 0.9400\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1508 - accuracy: 0.9912 - val_loss: 0.2727 - val_accuracy: 0.9467\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1529 - accuracy: 0.9889 - val_loss: 0.2967 - val_accuracy: 0.9400\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1474 - accuracy: 0.9917 - val_loss: 0.2840 - val_accuracy: 0.9367\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1405 - accuracy: 0.9954 - val_loss: 0.2936 - val_accuracy: 0.9400\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1477 - accuracy: 0.9898 - val_loss: 0.2717 - val_accuracy: 0.9400\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1451 - accuracy: 0.9912 - val_loss: 0.3024 - val_accuracy: 0.9467\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1416 - accuracy: 0.9940 - val_loss: 0.2755 - val_accuracy: 0.9400\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1428 - accuracy: 0.9921 - val_loss: 0.3309 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1484 - accuracy: 0.9926 - val_loss: 0.3021 - val_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1436 - accuracy: 0.9944 - val_loss: 0.2864 - val_accuracy: 0.9400\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1440 - accuracy: 0.9898 - val_loss: 0.2763 - val_accuracy: 0.9433\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1435 - accuracy: 0.9931 - val_loss: 0.2766 - val_accuracy: 0.9433\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1410 - accuracy: 0.9917 - val_loss: 0.2968 - val_accuracy: 0.9367\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1388 - accuracy: 0.9958 - val_loss: 0.2912 - val_accuracy: 0.9433\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1362 - accuracy: 0.9949 - val_loss: 0.2727 - val_accuracy: 0.9400\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1393 - accuracy: 0.9944 - val_loss: 0.3178 - val_accuracy: 0.9367\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1370 - accuracy: 0.9931 - val_loss: 0.2798 - val_accuracy: 0.9467\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1414 - accuracy: 0.9926 - val_loss: 0.2831 - val_accuracy: 0.9433\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1382 - accuracy: 0.9921 - val_loss: 0.2739 - val_accuracy: 0.9467\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1395 - accuracy: 0.9921 - val_loss: 0.2924 - val_accuracy: 0.9400\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1405 - accuracy: 0.9931 - val_loss: 0.3086 - val_accuracy: 0.9467\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1369 - accuracy: 0.9935 - val_loss: 0.3120 - val_accuracy: 0.9433\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1367 - accuracy: 0.9921 - val_loss: 0.2966 - val_accuracy: 0.9400\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1362 - accuracy: 0.9931 - val_loss: 0.2764 - val_accuracy: 0.9467\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1366 - accuracy: 0.9931 - val_loss: 0.2693 - val_accuracy: 0.9467\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1350 - accuracy: 0.9926 - val_loss: 0.2785 - val_accuracy: 0.9433\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1348 - accuracy: 0.9931 - val_loss: 0.2769 - val_accuracy: 0.9400\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1333 - accuracy: 0.9944 - val_loss: 0.2830 - val_accuracy: 0.9333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1349 - accuracy: 0.9931 - val_loss: 0.2841 - val_accuracy: 0.9367\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1377 - accuracy: 0.9921 - val_loss: 0.2700 - val_accuracy: 0.9367\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1351 - accuracy: 0.9931 - val_loss: 0.2705 - val_accuracy: 0.9400\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1327 - accuracy: 0.9944 - val_loss: 0.2583 - val_accuracy: 0.9433\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1339 - accuracy: 0.9958 - val_loss: 0.2481 - val_accuracy: 0.9400\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1357 - accuracy: 0.9921 - val_loss: 0.2526 - val_accuracy: 0.9500\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1334 - accuracy: 0.9935 - val_loss: 0.2982 - val_accuracy: 0.9433\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1350 - accuracy: 0.9949 - val_loss: 0.2617 - val_accuracy: 0.9433\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1328 - accuracy: 0.9944 - val_loss: 0.2689 - val_accuracy: 0.9467\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1298 - accuracy: 0.9958 - val_loss: 0.2886 - val_accuracy: 0.9400\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1281 - accuracy: 0.9954 - val_loss: 0.2780 - val_accuracy: 0.9433\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1240 - accuracy: 0.9986 - val_loss: 0.2898 - val_accuracy: 0.9433\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1337 - accuracy: 0.9907 - val_loss: 0.2909 - val_accuracy: 0.9400\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1356 - accuracy: 0.9926 - val_loss: 0.2980 - val_accuracy: 0.9400\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1371 - accuracy: 0.9894 - val_loss: 0.2983 - val_accuracy: 0.9367\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1362 - accuracy: 0.9935 - val_loss: 0.3262 - val_accuracy: 0.9400\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1393 - accuracy: 0.9903 - val_loss: 0.2835 - val_accuracy: 0.9467\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1443 - accuracy: 0.9917 - val_loss: 0.2947 - val_accuracy: 0.9433\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1378 - accuracy: 0.9903 - val_loss: 0.2999 - val_accuracy: 0.9400\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1333 - accuracy: 0.9935 - val_loss: 0.2919 - val_accuracy: 0.9367\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1341 - accuracy: 0.9907 - val_loss: 0.2747 - val_accuracy: 0.9367\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1322 - accuracy: 0.9949 - val_loss: 0.2775 - val_accuracy: 0.9467\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1329 - accuracy: 0.9940 - val_loss: 0.2803 - val_accuracy: 0.9400\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1306 - accuracy: 0.9931 - val_loss: 0.2858 - val_accuracy: 0.9433\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1315 - accuracy: 0.9944 - val_loss: 0.2876 - val_accuracy: 0.9400\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1374 - accuracy: 0.9907 - val_loss: 0.3088 - val_accuracy: 0.9367\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1349 - accuracy: 0.9931 - val_loss: 0.2836 - val_accuracy: 0.9500\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1385 - accuracy: 0.9912 - val_loss: 0.2699 - val_accuracy: 0.9400\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1357 - accuracy: 0.9935 - val_loss: 0.2713 - val_accuracy: 0.9433\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1313 - accuracy: 0.9935 - val_loss: 0.2628 - val_accuracy: 0.9367\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1290 - accuracy: 0.9931 - val_loss: 0.2943 - val_accuracy: 0.9367\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1345 - accuracy: 0.9912 - val_loss: 0.2772 - val_accuracy: 0.9367\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1348 - accuracy: 0.9917 - val_loss: 0.3095 - val_accuracy: 0.9400\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1311 - accuracy: 0.9931 - val_loss: 0.2633 - val_accuracy: 0.9467\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1275 - accuracy: 0.9944 - val_loss: 0.2888 - val_accuracy: 0.9400\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1310 - accuracy: 0.9917 - val_loss: 0.3008 - val_accuracy: 0.9433\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1257 - accuracy: 0.9958 - val_loss: 0.2957 - val_accuracy: 0.9400\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1293 - accuracy: 0.9940 - val_loss: 0.3014 - val_accuracy: 0.9433\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1320 - accuracy: 0.9935 - val_loss: 0.2932 - val_accuracy: 0.9400\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1305 - accuracy: 0.9949 - val_loss: 0.2724 - val_accuracy: 0.9400\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1269 - accuracy: 0.9935 - val_loss: 0.2796 - val_accuracy: 0.9400\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1280 - accuracy: 0.9944 - val_loss: 0.2904 - val_accuracy: 0.9400\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1312 - accuracy: 0.9912 - val_loss: 0.2804 - val_accuracy: 0.9333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1272 - accuracy: 0.9944 - val_loss: 0.2625 - val_accuracy: 0.9433\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1253 - accuracy: 0.9949 - val_loss: 0.2609 - val_accuracy: 0.9500\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1244 - accuracy: 0.9935 - val_loss: 0.2697 - val_accuracy: 0.9433\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1243 - accuracy: 0.9940 - val_loss: 0.2587 - val_accuracy: 0.9400\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1296 - accuracy: 0.9917 - val_loss: 0.2789 - val_accuracy: 0.9433\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1290 - accuracy: 0.9931 - val_loss: 0.2735 - val_accuracy: 0.9433\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1261 - accuracy: 0.9940 - val_loss: 0.2562 - val_accuracy: 0.9500\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1322 - accuracy: 0.9889 - val_loss: 0.2890 - val_accuracy: 0.9533\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1272 - accuracy: 0.9949 - val_loss: 0.2472 - val_accuracy: 0.9467\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1292 - accuracy: 0.9940 - val_loss: 0.2932 - val_accuracy: 0.9400\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1272 - accuracy: 0.9935 - val_loss: 0.2962 - val_accuracy: 0.9400\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1322 - accuracy: 0.9907 - val_loss: 0.2750 - val_accuracy: 0.9300\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1273 - accuracy: 0.9944 - val_loss: 0.2965 - val_accuracy: 0.9367\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1261 - accuracy: 0.9931 - val_loss: 0.2845 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1250 - accuracy: 0.9954 - val_loss: 0.2973 - val_accuracy: 0.9367\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1278 - accuracy: 0.9921 - val_loss: 0.2720 - val_accuracy: 0.9400\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1235 - accuracy: 0.9963 - val_loss: 0.2813 - val_accuracy: 0.9400\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1237 - accuracy: 0.9931 - val_loss: 0.2952 - val_accuracy: 0.9433\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1232 - accuracy: 0.9935 - val_loss: 0.2678 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1232 - accuracy: 0.9954 - val_loss: 0.3096 - val_accuracy: 0.9400\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1230 - accuracy: 0.9931 - val_loss: 0.2914 - val_accuracy: 0.9433\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1269 - accuracy: 0.9903 - val_loss: 0.2921 - val_accuracy: 0.9367\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1258 - accuracy: 0.9940 - val_loss: 0.2951 - val_accuracy: 0.9367\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1246 - accuracy: 0.9940 - val_loss: 0.3104 - val_accuracy: 0.9333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1214 - accuracy: 0.9968 - val_loss: 0.3070 - val_accuracy: 0.9400\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1241 - accuracy: 0.9926 - val_loss: 0.2732 - val_accuracy: 0.9400\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1239 - accuracy: 0.9921 - val_loss: 0.2656 - val_accuracy: 0.9467\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1231 - accuracy: 0.9926 - val_loss: 0.2800 - val_accuracy: 0.9433\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1238 - accuracy: 0.9949 - val_loss: 0.2965 - val_accuracy: 0.9467\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1252 - accuracy: 0.9921 - val_loss: 0.3076 - val_accuracy: 0.9400\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1249 - accuracy: 0.9940 - val_loss: 0.2889 - val_accuracy: 0.9467\n",
      "540/540 [==============================] - 0s 264us/sample - loss: 0.2365 - accuracy: 0.9574\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 371us/sample - loss: 3.3354 - accuracy: 0.7880 - val_loss: 3.0511 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 2.8996 - accuracy: 0.8514 - val_loss: 2.6597 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.5166 - accuracy: 0.8523 - val_loss: 2.3252 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.2201 - accuracy: 0.8537 - val_loss: 2.0297 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.9178 - accuracy: 0.8588 - val_loss: 1.7772 - val_accuracy: 0.8367\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.6815 - accuracy: 0.8602 - val_loss: 1.5551 - val_accuracy: 0.8400\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4799 - accuracy: 0.8602 - val_loss: 1.3653 - val_accuracy: 0.8467\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3014 - accuracy: 0.8597 - val_loss: 1.2021 - val_accuracy: 0.8467\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1433 - accuracy: 0.8671 - val_loss: 1.0608 - val_accuracy: 0.8600\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.0120 - accuracy: 0.8718 - val_loss: 0.9409 - val_accuracy: 0.8733\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8950 - accuracy: 0.8787 - val_loss: 0.8405 - val_accuracy: 0.8767\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8031 - accuracy: 0.8819 - val_loss: 0.7538 - val_accuracy: 0.8833\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7310 - accuracy: 0.8843 - val_loss: 0.6852 - val_accuracy: 0.9033\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.6613 - accuracy: 0.8847 - val_loss: 0.6261 - val_accuracy: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5895 - accuracy: 0.9046 - val_loss: 0.5745 - val_accuracy: 0.9167\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5439 - accuracy: 0.9162 - val_loss: 0.5361 - val_accuracy: 0.9133\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4985 - accuracy: 0.9292 - val_loss: 0.4982 - val_accuracy: 0.9233\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4493 - accuracy: 0.9375 - val_loss: 0.4625 - val_accuracy: 0.9233\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4201 - accuracy: 0.9463 - val_loss: 0.4344 - val_accuracy: 0.9367\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3863 - accuracy: 0.9486 - val_loss: 0.4195 - val_accuracy: 0.9300\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3677 - accuracy: 0.9532 - val_loss: 0.4015 - val_accuracy: 0.9267\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3452 - accuracy: 0.9611 - val_loss: 0.3861 - val_accuracy: 0.9367\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3226 - accuracy: 0.9593 - val_loss: 0.3633 - val_accuracy: 0.9433\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3037 - accuracy: 0.9639 - val_loss: 0.3675 - val_accuracy: 0.9300\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2913 - accuracy: 0.9671 - val_loss: 0.3462 - val_accuracy: 0.9367\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2764 - accuracy: 0.9657 - val_loss: 0.3505 - val_accuracy: 0.9400\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2599 - accuracy: 0.9736 - val_loss: 0.3561 - val_accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2548 - accuracy: 0.9722 - val_loss: 0.3243 - val_accuracy: 0.9467\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2461 - accuracy: 0.9787 - val_loss: 0.3359 - val_accuracy: 0.9333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2326 - accuracy: 0.9755 - val_loss: 0.3249 - val_accuracy: 0.9300\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2311 - accuracy: 0.9819 - val_loss: 0.3404 - val_accuracy: 0.9333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2198 - accuracy: 0.9796 - val_loss: 0.3166 - val_accuracy: 0.9333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2159 - accuracy: 0.9787 - val_loss: 0.3175 - val_accuracy: 0.9333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2102 - accuracy: 0.9829 - val_loss: 0.3184 - val_accuracy: 0.9333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.2089 - accuracy: 0.9833 - val_loss: 0.3287 - val_accuracy: 0.9333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1986 - accuracy: 0.9861 - val_loss: 0.3160 - val_accuracy: 0.9333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1949 - accuracy: 0.9861 - val_loss: 0.3260 - val_accuracy: 0.9400\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1975 - accuracy: 0.9829 - val_loss: 0.3536 - val_accuracy: 0.9333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1901 - accuracy: 0.9856 - val_loss: 0.3218 - val_accuracy: 0.9300\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1927 - accuracy: 0.9861 - val_loss: 0.3358 - val_accuracy: 0.9300\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1826 - accuracy: 0.9903 - val_loss: 0.3062 - val_accuracy: 0.9433\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1759 - accuracy: 0.9870 - val_loss: 0.2927 - val_accuracy: 0.9367\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1776 - accuracy: 0.9884 - val_loss: 0.3164 - val_accuracy: 0.9400\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1758 - accuracy: 0.9880 - val_loss: 0.3162 - val_accuracy: 0.9367\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1768 - accuracy: 0.9870 - val_loss: 0.3144 - val_accuracy: 0.9333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1687 - accuracy: 0.9903 - val_loss: 0.3073 - val_accuracy: 0.9400\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1665 - accuracy: 0.9894 - val_loss: 0.3203 - val_accuracy: 0.9367\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1665 - accuracy: 0.9894 - val_loss: 0.3121 - val_accuracy: 0.9367\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1637 - accuracy: 0.9903 - val_loss: 0.3140 - val_accuracy: 0.9300\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1667 - accuracy: 0.9870 - val_loss: 0.3393 - val_accuracy: 0.9333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1651 - accuracy: 0.9875 - val_loss: 0.3106 - val_accuracy: 0.9333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1592 - accuracy: 0.9917 - val_loss: 0.3311 - val_accuracy: 0.9233\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1668 - accuracy: 0.9875 - val_loss: 0.3085 - val_accuracy: 0.9300\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1602 - accuracy: 0.9894 - val_loss: 0.2846 - val_accuracy: 0.9433\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1577 - accuracy: 0.9935 - val_loss: 0.2911 - val_accuracy: 0.9400\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1623 - accuracy: 0.9917 - val_loss: 0.3185 - val_accuracy: 0.9367\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1572 - accuracy: 0.9944 - val_loss: 0.3268 - val_accuracy: 0.9400\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1518 - accuracy: 0.9944 - val_loss: 0.2986 - val_accuracy: 0.9400\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1522 - accuracy: 0.9931 - val_loss: 0.3087 - val_accuracy: 0.9333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1529 - accuracy: 0.9921 - val_loss: 0.3292 - val_accuracy: 0.9367\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1511 - accuracy: 0.9931 - val_loss: 0.3050 - val_accuracy: 0.9333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1536 - accuracy: 0.9898 - val_loss: 0.3490 - val_accuracy: 0.9300\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1522 - accuracy: 0.9884 - val_loss: 0.3129 - val_accuracy: 0.9300\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1494 - accuracy: 0.9926 - val_loss: 0.3498 - val_accuracy: 0.9300\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1521 - accuracy: 0.9907 - val_loss: 0.3280 - val_accuracy: 0.9300\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1521 - accuracy: 0.9903 - val_loss: 0.3087 - val_accuracy: 0.9200\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1562 - accuracy: 0.9884 - val_loss: 0.3106 - val_accuracy: 0.9300\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1473 - accuracy: 0.9931 - val_loss: 0.2932 - val_accuracy: 0.9400\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1473 - accuracy: 0.9917 - val_loss: 0.2964 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1471 - accuracy: 0.9926 - val_loss: 0.2875 - val_accuracy: 0.9400\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1478 - accuracy: 0.9940 - val_loss: 0.3246 - val_accuracy: 0.9300\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1482 - accuracy: 0.9898 - val_loss: 0.3217 - val_accuracy: 0.9333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1413 - accuracy: 0.9940 - val_loss: 0.3395 - val_accuracy: 0.9300\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1432 - accuracy: 0.9949 - val_loss: 0.3272 - val_accuracy: 0.9300\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1463 - accuracy: 0.9912 - val_loss: 0.3139 - val_accuracy: 0.9267\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1465 - accuracy: 0.9917 - val_loss: 0.3001 - val_accuracy: 0.9300\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1415 - accuracy: 0.9940 - val_loss: 0.3154 - val_accuracy: 0.9367\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1454 - accuracy: 0.9926 - val_loss: 0.3041 - val_accuracy: 0.9367\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1486 - accuracy: 0.9880 - val_loss: 0.2976 - val_accuracy: 0.9333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1440 - accuracy: 0.9912 - val_loss: 0.3352 - val_accuracy: 0.9367\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1468 - accuracy: 0.9917 - val_loss: 0.3139 - val_accuracy: 0.9333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1431 - accuracy: 0.9903 - val_loss: 0.3276 - val_accuracy: 0.9333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1389 - accuracy: 0.9949 - val_loss: 0.3135 - val_accuracy: 0.9267\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1405 - accuracy: 0.9958 - val_loss: 0.2976 - val_accuracy: 0.9300\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1344 - accuracy: 0.9954 - val_loss: 0.3302 - val_accuracy: 0.9300\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1381 - accuracy: 0.9935 - val_loss: 0.3137 - val_accuracy: 0.9367\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1379 - accuracy: 0.9931 - val_loss: 0.3063 - val_accuracy: 0.9333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1435 - accuracy: 0.9884 - val_loss: 0.2891 - val_accuracy: 0.9300\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1404 - accuracy: 0.9912 - val_loss: 0.3058 - val_accuracy: 0.9300\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1391 - accuracy: 0.9958 - val_loss: 0.3524 - val_accuracy: 0.9267\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1378 - accuracy: 0.9944 - val_loss: 0.3176 - val_accuracy: 0.9267\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1433 - accuracy: 0.9907 - val_loss: 0.3105 - val_accuracy: 0.9233\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1420 - accuracy: 0.9921 - val_loss: 0.3165 - val_accuracy: 0.9300\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1389 - accuracy: 0.9926 - val_loss: 0.3435 - val_accuracy: 0.9300\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1415 - accuracy: 0.9894 - val_loss: 0.3212 - val_accuracy: 0.9233\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1454 - accuracy: 0.9898 - val_loss: 0.2964 - val_accuracy: 0.9267\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1411 - accuracy: 0.9921 - val_loss: 0.3230 - val_accuracy: 0.9167\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1382 - accuracy: 0.9912 - val_loss: 0.3174 - val_accuracy: 0.9267\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1345 - accuracy: 0.9935 - val_loss: 0.3076 - val_accuracy: 0.9367\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1345 - accuracy: 0.9935 - val_loss: 0.3107 - val_accuracy: 0.9333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1327 - accuracy: 0.9935 - val_loss: 0.3090 - val_accuracy: 0.9333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1369 - accuracy: 0.9898 - val_loss: 0.3306 - val_accuracy: 0.9300\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1314 - accuracy: 0.9949 - val_loss: 0.3138 - val_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1321 - accuracy: 0.9935 - val_loss: 0.3260 - val_accuracy: 0.9333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1312 - accuracy: 0.9921 - val_loss: 0.3149 - val_accuracy: 0.9333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1312 - accuracy: 0.9912 - val_loss: 0.2795 - val_accuracy: 0.9367\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1340 - accuracy: 0.9917 - val_loss: 0.2930 - val_accuracy: 0.9300\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1316 - accuracy: 0.9935 - val_loss: 0.2924 - val_accuracy: 0.9333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1346 - accuracy: 0.9926 - val_loss: 0.3153 - val_accuracy: 0.9300\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1351 - accuracy: 0.9926 - val_loss: 0.2977 - val_accuracy: 0.9333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1327 - accuracy: 0.9921 - val_loss: 0.3403 - val_accuracy: 0.9233\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1353 - accuracy: 0.9907 - val_loss: 0.2757 - val_accuracy: 0.9433\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1382 - accuracy: 0.9898 - val_loss: 0.2529 - val_accuracy: 0.9400\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1389 - accuracy: 0.9898 - val_loss: 0.2692 - val_accuracy: 0.9367\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1347 - accuracy: 0.9926 - val_loss: 0.2978 - val_accuracy: 0.9333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1364 - accuracy: 0.9907 - val_loss: 0.2773 - val_accuracy: 0.9367\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1279 - accuracy: 0.9958 - val_loss: 0.3183 - val_accuracy: 0.9300\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1328 - accuracy: 0.9912 - val_loss: 0.3028 - val_accuracy: 0.9267\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1259 - accuracy: 0.9954 - val_loss: 0.2938 - val_accuracy: 0.9300\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1313 - accuracy: 0.9912 - val_loss: 0.2746 - val_accuracy: 0.9367\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1319 - accuracy: 0.9917 - val_loss: 0.3041 - val_accuracy: 0.9367\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1295 - accuracy: 0.9926 - val_loss: 0.3014 - val_accuracy: 0.9333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1349 - accuracy: 0.9907 - val_loss: 0.3055 - val_accuracy: 0.9267\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1281 - accuracy: 0.9940 - val_loss: 0.3184 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1291 - accuracy: 0.9921 - val_loss: 0.2909 - val_accuracy: 0.9333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1242 - accuracy: 0.9940 - val_loss: 0.2898 - val_accuracy: 0.9433\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1261 - accuracy: 0.9935 - val_loss: 0.2981 - val_accuracy: 0.9333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1276 - accuracy: 0.9917 - val_loss: 0.2930 - val_accuracy: 0.9367\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1294 - accuracy: 0.9898 - val_loss: 0.3263 - val_accuracy: 0.9300\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1277 - accuracy: 0.9944 - val_loss: 0.3576 - val_accuracy: 0.9367\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1236 - accuracy: 0.9949 - val_loss: 0.3180 - val_accuracy: 0.9333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1267 - accuracy: 0.9926 - val_loss: 0.3185 - val_accuracy: 0.9267\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1189 - accuracy: 0.9949 - val_loss: 0.3193 - val_accuracy: 0.9300\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1199 - accuracy: 0.9958 - val_loss: 0.3228 - val_accuracy: 0.9367\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1239 - accuracy: 0.9926 - val_loss: 0.3036 - val_accuracy: 0.9367\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1228 - accuracy: 0.9935 - val_loss: 0.3131 - val_accuracy: 0.9367\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1238 - accuracy: 0.9921 - val_loss: 0.2811 - val_accuracy: 0.9333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1321 - accuracy: 0.9912 - val_loss: 0.3057 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1232 - accuracy: 0.9963 - val_loss: 0.3120 - val_accuracy: 0.9267\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1222 - accuracy: 0.9968 - val_loss: 0.3241 - val_accuracy: 0.9100\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1198 - accuracy: 0.9944 - val_loss: 0.2979 - val_accuracy: 0.9200\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1189 - accuracy: 0.9944 - val_loss: 0.2985 - val_accuracy: 0.9267\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1188 - accuracy: 0.9963 - val_loss: 0.3220 - val_accuracy: 0.9233\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1167 - accuracy: 0.9954 - val_loss: 0.2896 - val_accuracy: 0.9267\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1162 - accuracy: 0.9958 - val_loss: 0.2997 - val_accuracy: 0.9333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1158 - accuracy: 0.9977 - val_loss: 0.3536 - val_accuracy: 0.9333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1219 - accuracy: 0.9944 - val_loss: 0.2865 - val_accuracy: 0.9367\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1228 - accuracy: 0.9926 - val_loss: 0.2685 - val_accuracy: 0.9433\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1269 - accuracy: 0.9926 - val_loss: 0.2676 - val_accuracy: 0.9400\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1232 - accuracy: 0.9917 - val_loss: 0.2793 - val_accuracy: 0.9300\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1244 - accuracy: 0.9926 - val_loss: 0.3027 - val_accuracy: 0.9333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1225 - accuracy: 0.9954 - val_loss: 0.3170 - val_accuracy: 0.9267\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1240 - accuracy: 0.9926 - val_loss: 0.3196 - val_accuracy: 0.9200\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1211 - accuracy: 0.9926 - val_loss: 0.3045 - val_accuracy: 0.9300\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1218 - accuracy: 0.9921 - val_loss: 0.2865 - val_accuracy: 0.9367\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1237 - accuracy: 0.9917 - val_loss: 0.3122 - val_accuracy: 0.9367\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1155 - accuracy: 0.9958 - val_loss: 0.3151 - val_accuracy: 0.9333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1212 - accuracy: 0.9940 - val_loss: 0.3037 - val_accuracy: 0.9333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1223 - accuracy: 0.9926 - val_loss: 0.3250 - val_accuracy: 0.9333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1190 - accuracy: 0.9954 - val_loss: 0.3281 - val_accuracy: 0.9233\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1267 - accuracy: 0.9921 - val_loss: 0.2977 - val_accuracy: 0.9333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1209 - accuracy: 0.9944 - val_loss: 0.2741 - val_accuracy: 0.9367\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1214 - accuracy: 0.9944 - val_loss: 0.2738 - val_accuracy: 0.9333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1233 - accuracy: 0.9921 - val_loss: 0.2749 - val_accuracy: 0.9367\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1188 - accuracy: 0.9949 - val_loss: 0.2883 - val_accuracy: 0.9333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1150 - accuracy: 0.9949 - val_loss: 0.2738 - val_accuracy: 0.9400\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1155 - accuracy: 0.9958 - val_loss: 0.2942 - val_accuracy: 0.9300\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1142 - accuracy: 0.9958 - val_loss: 0.2853 - val_accuracy: 0.9300\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1133 - accuracy: 0.9949 - val_loss: 0.2736 - val_accuracy: 0.9300\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1187 - accuracy: 0.9921 - val_loss: 0.2993 - val_accuracy: 0.9367\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1171 - accuracy: 0.9949 - val_loss: 0.2810 - val_accuracy: 0.9367\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1219 - accuracy: 0.9921 - val_loss: 0.2834 - val_accuracy: 0.9267\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1207 - accuracy: 0.9921 - val_loss: 0.2909 - val_accuracy: 0.9300\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1194 - accuracy: 0.9940 - val_loss: 0.2897 - val_accuracy: 0.9300\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1173 - accuracy: 0.9954 - val_loss: 0.2909 - val_accuracy: 0.9300\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1165 - accuracy: 0.9963 - val_loss: 0.2997 - val_accuracy: 0.9433\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1159 - accuracy: 0.9963 - val_loss: 0.3014 - val_accuracy: 0.9400\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1197 - accuracy: 0.9935 - val_loss: 0.2666 - val_accuracy: 0.9467\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1236 - accuracy: 0.9907 - val_loss: 0.2557 - val_accuracy: 0.9433\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1240 - accuracy: 0.9921 - val_loss: 0.2705 - val_accuracy: 0.9367\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1203 - accuracy: 0.9931 - val_loss: 0.2942 - val_accuracy: 0.9333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1184 - accuracy: 0.9949 - val_loss: 0.2958 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1201 - accuracy: 0.9931 - val_loss: 0.3161 - val_accuracy: 0.9233\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1239 - accuracy: 0.9917 - val_loss: 0.3434 - val_accuracy: 0.9300\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1253 - accuracy: 0.9912 - val_loss: 0.2794 - val_accuracy: 0.9300\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1174 - accuracy: 0.9958 - val_loss: 0.2901 - val_accuracy: 0.9333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1182 - accuracy: 0.9926 - val_loss: 0.2880 - val_accuracy: 0.9400\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1161 - accuracy: 0.9949 - val_loss: 0.3037 - val_accuracy: 0.9367\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 1.00 - 0s 21us/sample - loss: 0.1131 - accuracy: 0.9958 - val_loss: 0.3190 - val_accuracy: 0.9333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1144 - accuracy: 0.9935 - val_loss: 0.2891 - val_accuracy: 0.9333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1105 - accuracy: 0.9935 - val_loss: 0.2771 - val_accuracy: 0.9367\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1106 - accuracy: 0.9954 - val_loss: 0.2804 - val_accuracy: 0.9333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1157 - accuracy: 0.9917 - val_loss: 0.2683 - val_accuracy: 0.9367\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1077 - accuracy: 0.9958 - val_loss: 0.2704 - val_accuracy: 0.9433\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1146 - accuracy: 0.9940 - val_loss: 0.2829 - val_accuracy: 0.9333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1072 - accuracy: 0.9949 - val_loss: 0.2758 - val_accuracy: 0.9433\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1086 - accuracy: 0.9958 - val_loss: 0.3137 - val_accuracy: 0.9367\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1145 - accuracy: 0.9921 - val_loss: 0.3113 - val_accuracy: 0.9367\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1133 - accuracy: 0.9931 - val_loss: 0.2872 - val_accuracy: 0.9367\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1142 - accuracy: 0.9921 - val_loss: 0.2853 - val_accuracy: 0.9300\n",
      "540/540 [==============================] - 0s 275us/sample - loss: 0.3010 - accuracy: 0.9444\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 381us/sample - loss: 3.6001 - accuracy: 0.6264 - val_loss: 3.1745 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 3.1059 - accuracy: 0.8167 - val_loss: 2.8186 - val_accuracy: 0.8367\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.7263 - accuracy: 0.8255 - val_loss: 2.5099 - val_accuracy: 0.8367\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.4058 - accuracy: 0.8500 - val_loss: 2.2353 - val_accuracy: 0.8400\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.1672 - accuracy: 0.8454 - val_loss: 1.9920 - val_accuracy: 0.8400\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.9157 - accuracy: 0.8532 - val_loss: 1.7790 - val_accuracy: 0.8467\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.7118 - accuracy: 0.8597 - val_loss: 1.5874 - val_accuracy: 0.8533\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.5258 - accuracy: 0.8602 - val_loss: 1.4221 - val_accuracy: 0.8567\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3732 - accuracy: 0.8579 - val_loss: 1.2755 - val_accuracy: 0.8567\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.2181 - accuracy: 0.8713 - val_loss: 1.1482 - val_accuracy: 0.8633\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1021 - accuracy: 0.8690 - val_loss: 1.0363 - val_accuracy: 0.8700\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.9954 - accuracy: 0.8718 - val_loss: 0.9406 - val_accuracy: 0.8667\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8968 - accuracy: 0.8796 - val_loss: 0.8539 - val_accuracy: 0.8867\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.8145 - accuracy: 0.8972 - val_loss: 0.7862 - val_accuracy: 0.8900\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7467 - accuracy: 0.9023 - val_loss: 0.7204 - val_accuracy: 0.9033\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6794 - accuracy: 0.9120 - val_loss: 0.6683 - val_accuracy: 0.9067\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6215 - accuracy: 0.9213 - val_loss: 0.6257 - val_accuracy: 0.9167\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5817 - accuracy: 0.9213 - val_loss: 0.5794 - val_accuracy: 0.9133\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5284 - accuracy: 0.9315 - val_loss: 0.5478 - val_accuracy: 0.9200\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4985 - accuracy: 0.9356 - val_loss: 0.5174 - val_accuracy: 0.9300\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4598 - accuracy: 0.9412 - val_loss: 0.4886 - val_accuracy: 0.9367\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4264 - accuracy: 0.9463 - val_loss: 0.4654 - val_accuracy: 0.9333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4080 - accuracy: 0.9505 - val_loss: 0.4481 - val_accuracy: 0.9367\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3751 - accuracy: 0.9532 - val_loss: 0.4378 - val_accuracy: 0.9233\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3623 - accuracy: 0.9500 - val_loss: 0.4248 - val_accuracy: 0.9300\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3425 - accuracy: 0.9597 - val_loss: 0.4028 - val_accuracy: 0.9367\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3279 - accuracy: 0.9620 - val_loss: 0.3913 - val_accuracy: 0.9233\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3033 - accuracy: 0.9708 - val_loss: 0.3789 - val_accuracy: 0.9300\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3006 - accuracy: 0.9634 - val_loss: 0.3709 - val_accuracy: 0.9300\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2811 - accuracy: 0.9755 - val_loss: 0.3683 - val_accuracy: 0.9233\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2704 - accuracy: 0.9736 - val_loss: 0.3491 - val_accuracy: 0.9433\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2677 - accuracy: 0.9773 - val_loss: 0.3513 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2569 - accuracy: 0.9759 - val_loss: 0.3420 - val_accuracy: 0.9333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2476 - accuracy: 0.9806 - val_loss: 0.3279 - val_accuracy: 0.9367\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2416 - accuracy: 0.9787 - val_loss: 0.3393 - val_accuracy: 0.9333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2312 - accuracy: 0.9833 - val_loss: 0.3325 - val_accuracy: 0.9300\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2269 - accuracy: 0.9796 - val_loss: 0.3341 - val_accuracy: 0.9333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2203 - accuracy: 0.9833 - val_loss: 0.3469 - val_accuracy: 0.9367\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2173 - accuracy: 0.9810 - val_loss: 0.3064 - val_accuracy: 0.9433\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2092 - accuracy: 0.9861 - val_loss: 0.3120 - val_accuracy: 0.9367\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2042 - accuracy: 0.9856 - val_loss: 0.3439 - val_accuracy: 0.9300\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2043 - accuracy: 0.9861 - val_loss: 0.3376 - val_accuracy: 0.9367\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1995 - accuracy: 0.9866 - val_loss: 0.3192 - val_accuracy: 0.9400\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2040 - accuracy: 0.9819 - val_loss: 0.3187 - val_accuracy: 0.9367\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1989 - accuracy: 0.9843 - val_loss: 0.3230 - val_accuracy: 0.9267\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1986 - accuracy: 0.9847 - val_loss: 0.3189 - val_accuracy: 0.9400\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1936 - accuracy: 0.9838 - val_loss: 0.3103 - val_accuracy: 0.9400\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1868 - accuracy: 0.9907 - val_loss: 0.3555 - val_accuracy: 0.9300\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1869 - accuracy: 0.9889 - val_loss: 0.3257 - val_accuracy: 0.9333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1801 - accuracy: 0.9894 - val_loss: 0.3087 - val_accuracy: 0.9367\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1842 - accuracy: 0.9870 - val_loss: 0.3143 - val_accuracy: 0.9333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1797 - accuracy: 0.9898 - val_loss: 0.3169 - val_accuracy: 0.9333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1771 - accuracy: 0.9884 - val_loss: 0.2914 - val_accuracy: 0.9400\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1765 - accuracy: 0.9898 - val_loss: 0.3208 - val_accuracy: 0.9300\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1765 - accuracy: 0.9880 - val_loss: 0.3097 - val_accuracy: 0.9400\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1742 - accuracy: 0.9884 - val_loss: 0.3164 - val_accuracy: 0.9367\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1682 - accuracy: 0.9926 - val_loss: 0.3129 - val_accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1700 - accuracy: 0.9884 - val_loss: 0.3189 - val_accuracy: 0.9400\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1665 - accuracy: 0.9894 - val_loss: 0.3350 - val_accuracy: 0.9300\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1672 - accuracy: 0.9907 - val_loss: 0.3192 - val_accuracy: 0.9333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1673 - accuracy: 0.9898 - val_loss: 0.3137 - val_accuracy: 0.9333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1657 - accuracy: 0.9898 - val_loss: 0.3225 - val_accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1647 - accuracy: 0.9907 - val_loss: 0.3001 - val_accuracy: 0.9300\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1623 - accuracy: 0.9935 - val_loss: 0.2962 - val_accuracy: 0.9433\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1624 - accuracy: 0.9889 - val_loss: 0.2982 - val_accuracy: 0.9367\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1680 - accuracy: 0.9875 - val_loss: 0.3078 - val_accuracy: 0.9400\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1612 - accuracy: 0.9907 - val_loss: 0.3195 - val_accuracy: 0.9333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1620 - accuracy: 0.9907 - val_loss: 0.2651 - val_accuracy: 0.9467\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1641 - accuracy: 0.9894 - val_loss: 0.3177 - val_accuracy: 0.9433\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1612 - accuracy: 0.9903 - val_loss: 0.3463 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1549 - accuracy: 0.9912 - val_loss: 0.2840 - val_accuracy: 0.9300\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1572 - accuracy: 0.9926 - val_loss: 0.2982 - val_accuracy: 0.9400\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1573 - accuracy: 0.9894 - val_loss: 0.3050 - val_accuracy: 0.9400\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1544 - accuracy: 0.9926 - val_loss: 0.3183 - val_accuracy: 0.9367\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1495 - accuracy: 0.9931 - val_loss: 0.3148 - val_accuracy: 0.9333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1544 - accuracy: 0.9907 - val_loss: 0.2832 - val_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1587 - accuracy: 0.9894 - val_loss: 0.3111 - val_accuracy: 0.9333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1586 - accuracy: 0.9894 - val_loss: 0.2930 - val_accuracy: 0.9367\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1582 - accuracy: 0.9903 - val_loss: 0.2890 - val_accuracy: 0.9333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1576 - accuracy: 0.9903 - val_loss: 0.3029 - val_accuracy: 0.9300\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1528 - accuracy: 0.9926 - val_loss: 0.3134 - val_accuracy: 0.9333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1476 - accuracy: 0.9940 - val_loss: 0.2879 - val_accuracy: 0.9367\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1525 - accuracy: 0.9903 - val_loss: 0.2801 - val_accuracy: 0.9400\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1457 - accuracy: 0.9921 - val_loss: 0.3067 - val_accuracy: 0.9367\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1455 - accuracy: 0.9921 - val_loss: 0.3270 - val_accuracy: 0.9333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1475 - accuracy: 0.9921 - val_loss: 0.2827 - val_accuracy: 0.9367\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1520 - accuracy: 0.9907 - val_loss: 0.3184 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1464 - accuracy: 0.9926 - val_loss: 0.3077 - val_accuracy: 0.9367\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1513 - accuracy: 0.9903 - val_loss: 0.3314 - val_accuracy: 0.9300\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1476 - accuracy: 0.9926 - val_loss: 0.3244 - val_accuracy: 0.9300\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1423 - accuracy: 0.9935 - val_loss: 0.3404 - val_accuracy: 0.9267\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1437 - accuracy: 0.9912 - val_loss: 0.3107 - val_accuracy: 0.9333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1435 - accuracy: 0.9926 - val_loss: 0.2960 - val_accuracy: 0.9367\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1440 - accuracy: 0.9912 - val_loss: 0.3304 - val_accuracy: 0.9300\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1433 - accuracy: 0.9926 - val_loss: 0.3134 - val_accuracy: 0.9333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1420 - accuracy: 0.9921 - val_loss: 0.3117 - val_accuracy: 0.9300\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 1.00 - 0s 22us/sample - loss: 0.1488 - accuracy: 0.9894 - val_loss: 0.3225 - val_accuracy: 0.9200\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1536 - accuracy: 0.9889 - val_loss: 0.3243 - val_accuracy: 0.9233\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1467 - accuracy: 0.9912 - val_loss: 0.3437 - val_accuracy: 0.9267\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1474 - accuracy: 0.9894 - val_loss: 0.3379 - val_accuracy: 0.9300\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1464 - accuracy: 0.9921 - val_loss: 0.3394 - val_accuracy: 0.9267\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1454 - accuracy: 0.9931 - val_loss: 0.3064 - val_accuracy: 0.9333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1475 - accuracy: 0.9921 - val_loss: 0.3077 - val_accuracy: 0.9300\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1431 - accuracy: 0.9917 - val_loss: 0.2891 - val_accuracy: 0.9367\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1417 - accuracy: 0.9940 - val_loss: 0.3185 - val_accuracy: 0.9267\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1404 - accuracy: 0.9926 - val_loss: 0.3169 - val_accuracy: 0.9333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1491 - accuracy: 0.9898 - val_loss: 0.2662 - val_accuracy: 0.9400\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1463 - accuracy: 0.9894 - val_loss: 0.3089 - val_accuracy: 0.9300\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1419 - accuracy: 0.9931 - val_loss: 0.3347 - val_accuracy: 0.9167\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1421 - accuracy: 0.9921 - val_loss: 0.3121 - val_accuracy: 0.9200\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1420 - accuracy: 0.9931 - val_loss: 0.2909 - val_accuracy: 0.9333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1392 - accuracy: 0.9949 - val_loss: 0.3077 - val_accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1403 - accuracy: 0.9931 - val_loss: 0.3177 - val_accuracy: 0.9333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1416 - accuracy: 0.9935 - val_loss: 0.2960 - val_accuracy: 0.9267\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1333 - accuracy: 0.9968 - val_loss: 0.3054 - val_accuracy: 0.9267\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1366 - accuracy: 0.9940 - val_loss: 0.3037 - val_accuracy: 0.9267\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1342 - accuracy: 0.9949 - val_loss: 0.3093 - val_accuracy: 0.9300\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1353 - accuracy: 0.9912 - val_loss: 0.2914 - val_accuracy: 0.9300\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1331 - accuracy: 0.9931 - val_loss: 0.3198 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1309 - accuracy: 0.9949 - val_loss: 0.3327 - val_accuracy: 0.9267\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1328 - accuracy: 0.9935 - val_loss: 0.3290 - val_accuracy: 0.9167\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1345 - accuracy: 0.9944 - val_loss: 0.2743 - val_accuracy: 0.9367\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1412 - accuracy: 0.9912 - val_loss: 0.3200 - val_accuracy: 0.9300\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1355 - accuracy: 0.9917 - val_loss: 0.3271 - val_accuracy: 0.9300\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1375 - accuracy: 0.9894 - val_loss: 0.3270 - val_accuracy: 0.9167\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1399 - accuracy: 0.9917 - val_loss: 0.3245 - val_accuracy: 0.9233\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1368 - accuracy: 0.9931 - val_loss: 0.3551 - val_accuracy: 0.9267\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1401 - accuracy: 0.9912 - val_loss: 0.2855 - val_accuracy: 0.9333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1375 - accuracy: 0.9944 - val_loss: 0.3091 - val_accuracy: 0.9333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1370 - accuracy: 0.9935 - val_loss: 0.3217 - val_accuracy: 0.9300\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1340 - accuracy: 0.9944 - val_loss: 0.3428 - val_accuracy: 0.9233\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.1340 - accuracy: 0.9926 - val_loss: 0.3162 - val_accuracy: 0.9267\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1369 - accuracy: 0.9921 - val_loss: 0.2799 - val_accuracy: 0.9300\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1349 - accuracy: 0.9921 - val_loss: 0.3325 - val_accuracy: 0.9300\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1337 - accuracy: 0.9940 - val_loss: 0.3051 - val_accuracy: 0.9333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1331 - accuracy: 0.9921 - val_loss: 0.2969 - val_accuracy: 0.9300\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1369 - accuracy: 0.9926 - val_loss: 0.2831 - val_accuracy: 0.9400\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.1318 - accuracy: 0.9940 - val_loss: 0.3192 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1381 - accuracy: 0.9926 - val_loss: 0.3683 - val_accuracy: 0.9300\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1369 - accuracy: 0.9907 - val_loss: 0.3324 - val_accuracy: 0.9300\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1377 - accuracy: 0.9907 - val_loss: 0.3539 - val_accuracy: 0.9233\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1297 - accuracy: 0.9949 - val_loss: 0.3710 - val_accuracy: 0.9167\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1358 - accuracy: 0.9921 - val_loss: 0.3373 - val_accuracy: 0.9233\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1320 - accuracy: 0.9931 - val_loss: 0.3294 - val_accuracy: 0.9233\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1267 - accuracy: 0.9935 - val_loss: 0.3366 - val_accuracy: 0.9200\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1253 - accuracy: 0.9949 - val_loss: 0.3374 - val_accuracy: 0.9233\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1271 - accuracy: 0.9944 - val_loss: 0.3679 - val_accuracy: 0.9200\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1301 - accuracy: 0.9931 - val_loss: 0.3365 - val_accuracy: 0.9167\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1283 - accuracy: 0.9921 - val_loss: 0.3524 - val_accuracy: 0.9233\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1302 - accuracy: 0.9940 - val_loss: 0.3315 - val_accuracy: 0.9233\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1303 - accuracy: 0.9944 - val_loss: 0.3541 - val_accuracy: 0.9167\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1283 - accuracy: 0.9949 - val_loss: 0.3406 - val_accuracy: 0.9233\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1339 - accuracy: 0.9894 - val_loss: 0.3144 - val_accuracy: 0.9267\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1264 - accuracy: 0.9968 - val_loss: 0.2970 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1279 - accuracy: 0.9944 - val_loss: 0.3194 - val_accuracy: 0.9233\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1299 - accuracy: 0.9912 - val_loss: 0.3242 - val_accuracy: 0.9200\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1319 - accuracy: 0.9935 - val_loss: 0.3458 - val_accuracy: 0.9267\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1340 - accuracy: 0.9917 - val_loss: 0.3269 - val_accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1337 - accuracy: 0.9921 - val_loss: 0.2897 - val_accuracy: 0.9233\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1362 - accuracy: 0.9903 - val_loss: 0.2875 - val_accuracy: 0.9433\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1328 - accuracy: 0.9926 - val_loss: 0.3144 - val_accuracy: 0.9267\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1273 - accuracy: 0.9940 - val_loss: 0.3523 - val_accuracy: 0.9267\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1277 - accuracy: 0.9958 - val_loss: 0.3548 - val_accuracy: 0.9267\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1277 - accuracy: 0.9931 - val_loss: 0.3287 - val_accuracy: 0.9367\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1302 - accuracy: 0.9921 - val_loss: 0.3324 - val_accuracy: 0.9233\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1317 - accuracy: 0.9917 - val_loss: 0.3104 - val_accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1335 - accuracy: 0.9898 - val_loss: 0.3636 - val_accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1351 - accuracy: 0.9894 - val_loss: 0.3541 - val_accuracy: 0.9233\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1269 - accuracy: 0.9949 - val_loss: 0.3060 - val_accuracy: 0.9300\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1341 - accuracy: 0.9898 - val_loss: 0.3355 - val_accuracy: 0.9233\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1331 - accuracy: 0.9921 - val_loss: 0.3284 - val_accuracy: 0.9333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1323 - accuracy: 0.9907 - val_loss: 0.3443 - val_accuracy: 0.9233\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1246 - accuracy: 0.9963 - val_loss: 0.3136 - val_accuracy: 0.9267\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1268 - accuracy: 0.9926 - val_loss: 0.3495 - val_accuracy: 0.9200\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1316 - accuracy: 0.9912 - val_loss: 0.3593 - val_accuracy: 0.9233\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1267 - accuracy: 0.9963 - val_loss: 0.3574 - val_accuracy: 0.9233\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1254 - accuracy: 0.9940 - val_loss: 0.3493 - val_accuracy: 0.9267\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1261 - accuracy: 0.9944 - val_loss: 0.3376 - val_accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1288 - accuracy: 0.9921 - val_loss: 0.3658 - val_accuracy: 0.9233\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1267 - accuracy: 0.9907 - val_loss: 0.3394 - val_accuracy: 0.9333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1227 - accuracy: 0.9954 - val_loss: 0.3150 - val_accuracy: 0.9333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1283 - accuracy: 0.9926 - val_loss: 0.3114 - val_accuracy: 0.9333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1268 - accuracy: 0.9921 - val_loss: 0.3194 - val_accuracy: 0.9267\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1235 - accuracy: 0.9940 - val_loss: 0.3584 - val_accuracy: 0.9200\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1194 - accuracy: 0.9949 - val_loss: 0.3539 - val_accuracy: 0.9200\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1215 - accuracy: 0.9940 - val_loss: 0.3248 - val_accuracy: 0.9233\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1205 - accuracy: 0.9963 - val_loss: 0.3374 - val_accuracy: 0.9300\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1229 - accuracy: 0.9926 - val_loss: 0.2986 - val_accuracy: 0.9200\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1221 - accuracy: 0.9935 - val_loss: 0.3322 - val_accuracy: 0.9300\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1239 - accuracy: 0.9917 - val_loss: 0.3466 - val_accuracy: 0.9267\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1167 - accuracy: 0.9972 - val_loss: 0.3620 - val_accuracy: 0.9200\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1219 - accuracy: 0.9912 - val_loss: 0.3097 - val_accuracy: 0.9333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1266 - accuracy: 0.9903 - val_loss: 0.3527 - val_accuracy: 0.9200\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1258 - accuracy: 0.9931 - val_loss: 0.3435 - val_accuracy: 0.9233\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1235 - accuracy: 0.9944 - val_loss: 0.3191 - val_accuracy: 0.9267\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1238 - accuracy: 0.9940 - val_loss: 0.3426 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1239 - accuracy: 0.9944 - val_loss: 0.3497 - val_accuracy: 0.9267\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1219 - accuracy: 0.9949 - val_loss: 0.3312 - val_accuracy: 0.9333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1219 - accuracy: 0.9921 - val_loss: 0.3308 - val_accuracy: 0.9300\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1252 - accuracy: 0.9926 - val_loss: 0.3422 - val_accuracy: 0.9233\n",
      "540/540 [==============================] - 0s 284us/sample - loss: 0.2359 - accuracy: 0.9611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 491us/sample - loss: 3.5581 - accuracy: 0.6509 - val_loss: 3.1607 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.0573 - accuracy: 0.8227 - val_loss: 2.7901 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.6777 - accuracy: 0.8380 - val_loss: 2.4618 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.3363 - accuracy: 0.8435 - val_loss: 2.1666 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.0765 - accuracy: 0.8407 - val_loss: 1.9083 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8204 - accuracy: 0.8417 - val_loss: 1.6833 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6194 - accuracy: 0.8417 - val_loss: 1.4890 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.4310 - accuracy: 0.8435 - val_loss: 1.3229 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2771 - accuracy: 0.8435 - val_loss: 1.1766 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1338 - accuracy: 0.8435 - val_loss: 1.0485 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.0143 - accuracy: 0.8435 - val_loss: 0.9369 - val_accuracy: 0.8300\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.9140 - accuracy: 0.8449 - val_loss: 0.8434 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8276 - accuracy: 0.8532 - val_loss: 0.7652 - val_accuracy: 0.8467\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.7510 - accuracy: 0.8625 - val_loss: 0.6971 - val_accuracy: 0.8633\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6827 - accuracy: 0.8787 - val_loss: 0.6373 - val_accuracy: 0.8900\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6232 - accuracy: 0.8894 - val_loss: 0.5965 - val_accuracy: 0.8933\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5781 - accuracy: 0.8981 - val_loss: 0.5552 - val_accuracy: 0.9100\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5285 - accuracy: 0.9190 - val_loss: 0.5176 - val_accuracy: 0.9200\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4819 - accuracy: 0.9319 - val_loss: 0.4976 - val_accuracy: 0.9167\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4565 - accuracy: 0.9389 - val_loss: 0.4696 - val_accuracy: 0.9267\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4256 - accuracy: 0.9384 - val_loss: 0.4452 - val_accuracy: 0.9267\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3999 - accuracy: 0.9495 - val_loss: 0.4290 - val_accuracy: 0.9400\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3781 - accuracy: 0.9500 - val_loss: 0.4024 - val_accuracy: 0.9400\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3567 - accuracy: 0.9565 - val_loss: 0.3768 - val_accuracy: 0.9467\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3389 - accuracy: 0.9616 - val_loss: 0.3743 - val_accuracy: 0.9367\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3235 - accuracy: 0.9662 - val_loss: 0.3799 - val_accuracy: 0.9467\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3059 - accuracy: 0.9718 - val_loss: 0.3694 - val_accuracy: 0.9467\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3046 - accuracy: 0.9606 - val_loss: 0.3568 - val_accuracy: 0.9467\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2861 - accuracy: 0.9759 - val_loss: 0.3592 - val_accuracy: 0.9367\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2732 - accuracy: 0.9764 - val_loss: 0.3418 - val_accuracy: 0.9433\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2645 - accuracy: 0.9755 - val_loss: 0.3425 - val_accuracy: 0.9500\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2526 - accuracy: 0.9810 - val_loss: 0.3281 - val_accuracy: 0.9433\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2420 - accuracy: 0.9824 - val_loss: 0.3386 - val_accuracy: 0.9433\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2347 - accuracy: 0.9838 - val_loss: 0.3312 - val_accuracy: 0.9500\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2340 - accuracy: 0.9843 - val_loss: 0.3479 - val_accuracy: 0.9433\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2284 - accuracy: 0.9838 - val_loss: 0.3157 - val_accuracy: 0.9467\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2291 - accuracy: 0.9833 - val_loss: 0.3198 - val_accuracy: 0.9467\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2197 - accuracy: 0.9847 - val_loss: 0.3086 - val_accuracy: 0.9467\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2126 - accuracy: 0.9861 - val_loss: 0.3142 - val_accuracy: 0.9467\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2144 - accuracy: 0.9829 - val_loss: 0.3097 - val_accuracy: 0.9467\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2016 - accuracy: 0.9889 - val_loss: 0.3289 - val_accuracy: 0.9467\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2038 - accuracy: 0.9852 - val_loss: 0.3195 - val_accuracy: 0.9500\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2024 - accuracy: 0.9843 - val_loss: 0.3104 - val_accuracy: 0.9533\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2007 - accuracy: 0.9870 - val_loss: 0.3136 - val_accuracy: 0.9533\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1952 - accuracy: 0.9894 - val_loss: 0.3074 - val_accuracy: 0.9500\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1958 - accuracy: 0.9875 - val_loss: 0.3255 - val_accuracy: 0.9500\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1919 - accuracy: 0.9856 - val_loss: 0.3065 - val_accuracy: 0.9367\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.98 - 0s 22us/sample - loss: 0.1897 - accuracy: 0.9875 - val_loss: 0.3041 - val_accuracy: 0.9433\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 1.00 - 0s 24us/sample - loss: 0.1893 - accuracy: 0.9884 - val_loss: 0.3112 - val_accuracy: 0.9467\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1811 - accuracy: 0.9921 - val_loss: 0.3145 - val_accuracy: 0.9400\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1823 - accuracy: 0.9875 - val_loss: 0.2993 - val_accuracy: 0.9433\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1837 - accuracy: 0.9907 - val_loss: 0.3130 - val_accuracy: 0.9400\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1834 - accuracy: 0.9884 - val_loss: 0.3032 - val_accuracy: 0.9400\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1831 - accuracy: 0.9884 - val_loss: 0.3118 - val_accuracy: 0.9467\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1843 - accuracy: 0.9889 - val_loss: 0.2996 - val_accuracy: 0.9533\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1770 - accuracy: 0.9880 - val_loss: 0.3101 - val_accuracy: 0.9500\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1763 - accuracy: 0.9884 - val_loss: 0.2781 - val_accuracy: 0.9467\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1754 - accuracy: 0.9898 - val_loss: 0.3132 - val_accuracy: 0.9367\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1717 - accuracy: 0.9894 - val_loss: 0.2885 - val_accuracy: 0.9467\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1711 - accuracy: 0.9903 - val_loss: 0.2925 - val_accuracy: 0.9433\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1681 - accuracy: 0.9903 - val_loss: 0.2960 - val_accuracy: 0.9567\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1686 - accuracy: 0.9907 - val_loss: 0.2812 - val_accuracy: 0.9500\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1662 - accuracy: 0.9907 - val_loss: 0.2869 - val_accuracy: 0.9500\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1656 - accuracy: 0.9907 - val_loss: 0.3025 - val_accuracy: 0.9467\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1703 - accuracy: 0.9856 - val_loss: 0.2940 - val_accuracy: 0.9467\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1620 - accuracy: 0.9917 - val_loss: 0.2891 - val_accuracy: 0.9467\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1623 - accuracy: 0.9917 - val_loss: 0.2867 - val_accuracy: 0.9500\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1614 - accuracy: 0.9931 - val_loss: 0.2893 - val_accuracy: 0.9567\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1652 - accuracy: 0.9898 - val_loss: 0.2947 - val_accuracy: 0.9500\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1648 - accuracy: 0.9903 - val_loss: 0.3030 - val_accuracy: 0.9533\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1669 - accuracy: 0.9889 - val_loss: 0.3110 - val_accuracy: 0.9533\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1643 - accuracy: 0.9889 - val_loss: 0.3047 - val_accuracy: 0.9533\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1669 - accuracy: 0.9917 - val_loss: 0.2908 - val_accuracy: 0.9533\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1641 - accuracy: 0.9894 - val_loss: 0.2960 - val_accuracy: 0.9467\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.97 - 0s 23us/sample - loss: 0.1652 - accuracy: 0.9866 - val_loss: 0.3240 - val_accuracy: 0.9433\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1594 - accuracy: 0.9898 - val_loss: 0.3060 - val_accuracy: 0.9500\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1512 - accuracy: 0.9954 - val_loss: 0.2900 - val_accuracy: 0.9467\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1586 - accuracy: 0.9907 - val_loss: 0.2876 - val_accuracy: 0.9533\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1564 - accuracy: 0.9907 - val_loss: 0.2983 - val_accuracy: 0.9500\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1579 - accuracy: 0.9903 - val_loss: 0.2809 - val_accuracy: 0.9500\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1579 - accuracy: 0.9907 - val_loss: 0.2957 - val_accuracy: 0.9467\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1575 - accuracy: 0.9894 - val_loss: 0.3175 - val_accuracy: 0.9467\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1550 - accuracy: 0.9926 - val_loss: 0.3130 - val_accuracy: 0.9400\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1581 - accuracy: 0.9912 - val_loss: 0.2955 - val_accuracy: 0.9533\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1522 - accuracy: 0.9917 - val_loss: 0.2990 - val_accuracy: 0.9500\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1568 - accuracy: 0.9912 - val_loss: 0.2932 - val_accuracy: 0.9500\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1594 - accuracy: 0.9894 - val_loss: 0.3177 - val_accuracy: 0.9500\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1515 - accuracy: 0.9926 - val_loss: 0.3052 - val_accuracy: 0.9467\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1506 - accuracy: 0.9921 - val_loss: 0.2974 - val_accuracy: 0.9467\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1563 - accuracy: 0.9861 - val_loss: 0.3171 - val_accuracy: 0.9433\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1473 - accuracy: 0.9921 - val_loss: 0.3173 - val_accuracy: 0.9467\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1473 - accuracy: 0.9921 - val_loss: 0.3139 - val_accuracy: 0.9467\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1459 - accuracy: 0.9940 - val_loss: 0.3190 - val_accuracy: 0.9433\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1491 - accuracy: 0.9921 - val_loss: 0.3062 - val_accuracy: 0.9500\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1438 - accuracy: 0.9944 - val_loss: 0.2699 - val_accuracy: 0.9533\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1515 - accuracy: 0.9894 - val_loss: 0.2846 - val_accuracy: 0.9500\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1485 - accuracy: 0.9931 - val_loss: 0.2894 - val_accuracy: 0.9500\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1556 - accuracy: 0.9903 - val_loss: 0.3127 - val_accuracy: 0.9467\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1556 - accuracy: 0.9912 - val_loss: 0.3065 - val_accuracy: 0.9467\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1534 - accuracy: 0.9894 - val_loss: 0.2885 - val_accuracy: 0.9433\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1488 - accuracy: 0.9931 - val_loss: 0.3008 - val_accuracy: 0.9467\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1411 - accuracy: 0.9958 - val_loss: 0.2757 - val_accuracy: 0.9533\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1480 - accuracy: 0.9894 - val_loss: 0.2830 - val_accuracy: 0.9533\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1485 - accuracy: 0.9917 - val_loss: 0.2856 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1455 - accuracy: 0.9931 - val_loss: 0.2940 - val_accuracy: 0.9533\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1396 - accuracy: 0.9958 - val_loss: 0.2764 - val_accuracy: 0.9533\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1440 - accuracy: 0.9931 - val_loss: 0.2862 - val_accuracy: 0.9467\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1426 - accuracy: 0.9931 - val_loss: 0.3138 - val_accuracy: 0.9467\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1403 - accuracy: 0.9931 - val_loss: 0.3055 - val_accuracy: 0.9467\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1462 - accuracy: 0.9894 - val_loss: 0.2706 - val_accuracy: 0.9600\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1386 - accuracy: 0.9931 - val_loss: 0.2798 - val_accuracy: 0.9567\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1479 - accuracy: 0.9907 - val_loss: 0.2820 - val_accuracy: 0.9567\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1448 - accuracy: 0.9884 - val_loss: 0.3003 - val_accuracy: 0.9500\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1463 - accuracy: 0.9907 - val_loss: 0.2869 - val_accuracy: 0.9533\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1486 - accuracy: 0.9907 - val_loss: 0.2866 - val_accuracy: 0.9467\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1429 - accuracy: 0.9926 - val_loss: 0.2780 - val_accuracy: 0.9500\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1469 - accuracy: 0.9907 - val_loss: 0.2772 - val_accuracy: 0.9533\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1463 - accuracy: 0.9921 - val_loss: 0.3065 - val_accuracy: 0.9433\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1449 - accuracy: 0.9912 - val_loss: 0.2845 - val_accuracy: 0.9433\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1436 - accuracy: 0.9912 - val_loss: 0.2904 - val_accuracy: 0.9400\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1422 - accuracy: 0.9926 - val_loss: 0.2824 - val_accuracy: 0.9467\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1414 - accuracy: 0.9912 - val_loss: 0.3114 - val_accuracy: 0.9433\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1438 - accuracy: 0.9907 - val_loss: 0.3029 - val_accuracy: 0.9433\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1413 - accuracy: 0.9907 - val_loss: 0.2958 - val_accuracy: 0.9467\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1430 - accuracy: 0.9903 - val_loss: 0.3163 - val_accuracy: 0.9467\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1395 - accuracy: 0.9944 - val_loss: 0.3004 - val_accuracy: 0.9500\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1428 - accuracy: 0.9926 - val_loss: 0.2701 - val_accuracy: 0.9500\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1354 - accuracy: 0.9931 - val_loss: 0.3040 - val_accuracy: 0.9500\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1356 - accuracy: 0.9940 - val_loss: 0.2922 - val_accuracy: 0.9433\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1409 - accuracy: 0.9917 - val_loss: 0.2807 - val_accuracy: 0.9467\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1469 - accuracy: 0.9875 - val_loss: 0.2884 - val_accuracy: 0.9500\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1384 - accuracy: 0.9935 - val_loss: 0.2837 - val_accuracy: 0.9433\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1407 - accuracy: 0.9917 - val_loss: 0.3051 - val_accuracy: 0.9467\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1407 - accuracy: 0.9917 - val_loss: 0.2971 - val_accuracy: 0.9400\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1440 - accuracy: 0.9907 - val_loss: 0.2777 - val_accuracy: 0.9500\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1461 - accuracy: 0.9898 - val_loss: 0.3056 - val_accuracy: 0.9400\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1360 - accuracy: 0.9949 - val_loss: 0.2768 - val_accuracy: 0.9467\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1382 - accuracy: 0.9912 - val_loss: 0.3210 - val_accuracy: 0.9400\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1416 - accuracy: 0.9898 - val_loss: 0.3211 - val_accuracy: 0.9467\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1394 - accuracy: 0.9917 - val_loss: 0.2892 - val_accuracy: 0.9400\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1393 - accuracy: 0.9917 - val_loss: 0.3232 - val_accuracy: 0.9433\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1356 - accuracy: 0.9931 - val_loss: 0.2592 - val_accuracy: 0.9467\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1382 - accuracy: 0.9921 - val_loss: 0.2950 - val_accuracy: 0.9500\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1336 - accuracy: 0.9954 - val_loss: 0.2933 - val_accuracy: 0.9467\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1322 - accuracy: 0.9944 - val_loss: 0.2728 - val_accuracy: 0.9567\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1325 - accuracy: 0.9926 - val_loss: 0.2895 - val_accuracy: 0.9500\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1353 - accuracy: 0.9954 - val_loss: 0.2970 - val_accuracy: 0.9433\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1346 - accuracy: 0.9954 - val_loss: 0.2797 - val_accuracy: 0.9467\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1341 - accuracy: 0.9921 - val_loss: 0.3086 - val_accuracy: 0.9433\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1344 - accuracy: 0.9917 - val_loss: 0.3048 - val_accuracy: 0.9367\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1326 - accuracy: 0.9935 - val_loss: 0.2968 - val_accuracy: 0.9433\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1322 - accuracy: 0.9940 - val_loss: 0.2897 - val_accuracy: 0.9467\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1313 - accuracy: 0.9917 - val_loss: 0.2801 - val_accuracy: 0.9433\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1291 - accuracy: 0.9944 - val_loss: 0.2923 - val_accuracy: 0.9533\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1336 - accuracy: 0.9921 - val_loss: 0.2918 - val_accuracy: 0.9500\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1274 - accuracy: 0.9940 - val_loss: 0.3073 - val_accuracy: 0.9433\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1264 - accuracy: 0.9949 - val_loss: 0.2809 - val_accuracy: 0.9500\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1331 - accuracy: 0.9921 - val_loss: 0.2819 - val_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1345 - accuracy: 0.9926 - val_loss: 0.2775 - val_accuracy: 0.9533\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1301 - accuracy: 0.9940 - val_loss: 0.2720 - val_accuracy: 0.9467\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1334 - accuracy: 0.9903 - val_loss: 0.2813 - val_accuracy: 0.9433\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1338 - accuracy: 0.9907 - val_loss: 0.2755 - val_accuracy: 0.9500\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1311 - accuracy: 0.9917 - val_loss: 0.3102 - val_accuracy: 0.9500\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1295 - accuracy: 0.9949 - val_loss: 0.2839 - val_accuracy: 0.9567\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1294 - accuracy: 0.9944 - val_loss: 0.3257 - val_accuracy: 0.9367\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1307 - accuracy: 0.9921 - val_loss: 0.3083 - val_accuracy: 0.9533\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1342 - accuracy: 0.9921 - val_loss: 0.3049 - val_accuracy: 0.9467\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1353 - accuracy: 0.9907 - val_loss: 0.3175 - val_accuracy: 0.9433\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1334 - accuracy: 0.9921 - val_loss: 0.3193 - val_accuracy: 0.9467\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1333 - accuracy: 0.9935 - val_loss: 0.2832 - val_accuracy: 0.9467\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1280 - accuracy: 0.9940 - val_loss: 0.3049 - val_accuracy: 0.9467\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1279 - accuracy: 0.9940 - val_loss: 0.2872 - val_accuracy: 0.9467\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1286 - accuracy: 0.9940 - val_loss: 0.3007 - val_accuracy: 0.9467\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1283 - accuracy: 0.9921 - val_loss: 0.2865 - val_accuracy: 0.9400\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1249 - accuracy: 0.9954 - val_loss: 0.2939 - val_accuracy: 0.9533\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1364 - accuracy: 0.9889 - val_loss: 0.3060 - val_accuracy: 0.9533\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1318 - accuracy: 0.9921 - val_loss: 0.3195 - val_accuracy: 0.9467\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1320 - accuracy: 0.9903 - val_loss: 0.3033 - val_accuracy: 0.9433\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1275 - accuracy: 0.9949 - val_loss: 0.2969 - val_accuracy: 0.9467\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1288 - accuracy: 0.9944 - val_loss: 0.2885 - val_accuracy: 0.9533\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1270 - accuracy: 0.9935 - val_loss: 0.3018 - val_accuracy: 0.9533\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1262 - accuracy: 0.9940 - val_loss: 0.2989 - val_accuracy: 0.9467\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1286 - accuracy: 0.9921 - val_loss: 0.3168 - val_accuracy: 0.9500\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1245 - accuracy: 0.9963 - val_loss: 0.2895 - val_accuracy: 0.9500\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1277 - accuracy: 0.9935 - val_loss: 0.2773 - val_accuracy: 0.9567\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1259 - accuracy: 0.9940 - val_loss: 0.2780 - val_accuracy: 0.9467\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1271 - accuracy: 0.9921 - val_loss: 0.3099 - val_accuracy: 0.9467\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1290 - accuracy: 0.9931 - val_loss: 0.3012 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1269 - accuracy: 0.9912 - val_loss: 0.3183 - val_accuracy: 0.9467\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1284 - accuracy: 0.9870 - val_loss: 0.3148 - val_accuracy: 0.9467\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1270 - accuracy: 0.9931 - val_loss: 0.3207 - val_accuracy: 0.9533\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1258 - accuracy: 0.9944 - val_loss: 0.3097 - val_accuracy: 0.9533\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1239 - accuracy: 0.9949 - val_loss: 0.3013 - val_accuracy: 0.9467\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1244 - accuracy: 0.9954 - val_loss: 0.3017 - val_accuracy: 0.9467\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1245 - accuracy: 0.9949 - val_loss: 0.3049 - val_accuracy: 0.9400\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1294 - accuracy: 0.9917 - val_loss: 0.2998 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1281 - accuracy: 0.9931 - val_loss: 0.2912 - val_accuracy: 0.9433\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1279 - accuracy: 0.9921 - val_loss: 0.2923 - val_accuracy: 0.9500\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1263 - accuracy: 0.9926 - val_loss: 0.2708 - val_accuracy: 0.9467\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1218 - accuracy: 0.9949 - val_loss: 0.2886 - val_accuracy: 0.9467\n",
      "540/540 [==============================] - 0s 311us/sample - loss: 0.2363 - accuracy: 0.9630\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 383us/sample - loss: 2.4984 - accuracy: 0.6051 - val_loss: 2.0163 - val_accuracy: 0.7667\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.2126 - accuracy: 0.6782 - val_loss: 1.8846 - val_accuracy: 0.8267\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.9998 - accuracy: 0.7356 - val_loss: 1.7849 - val_accuracy: 0.8433\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.8531 - accuracy: 0.7750 - val_loss: 1.6964 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.7350 - accuracy: 0.8005 - val_loss: 1.6144 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.6444 - accuracy: 0.7991 - val_loss: 1.5290 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.5498 - accuracy: 0.8245 - val_loss: 1.4478 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4580 - accuracy: 0.8315 - val_loss: 1.3709 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3730 - accuracy: 0.8370 - val_loss: 1.3003 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.3025 - accuracy: 0.8412 - val_loss: 1.2350 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2520 - accuracy: 0.8440 - val_loss: 1.1761 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.1678 - accuracy: 0.8477 - val_loss: 1.1212 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.1036 - accuracy: 0.8495 - val_loss: 1.0685 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0575 - accuracy: 0.8481 - val_loss: 1.0192 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.9984 - accuracy: 0.8495 - val_loss: 0.9749 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.9707 - accuracy: 0.8514 - val_loss: 0.9344 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9132 - accuracy: 0.8523 - val_loss: 0.8964 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8808 - accuracy: 0.8509 - val_loss: 0.8612 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8451 - accuracy: 0.8523 - val_loss: 0.8292 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8094 - accuracy: 0.8528 - val_loss: 0.7998 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7852 - accuracy: 0.8519 - val_loss: 0.7726 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7567 - accuracy: 0.8519 - val_loss: 0.7473 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7235 - accuracy: 0.8523 - val_loss: 0.7233 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6987 - accuracy: 0.8523 - val_loss: 0.7007 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6923 - accuracy: 0.8523 - val_loss: 0.6803 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6667 - accuracy: 0.8523 - val_loss: 0.6609 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6409 - accuracy: 0.8523 - val_loss: 0.6428 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6317 - accuracy: 0.8523 - val_loss: 0.6264 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6090 - accuracy: 0.8523 - val_loss: 0.6110 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5926 - accuracy: 0.8523 - val_loss: 0.5961 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5812 - accuracy: 0.8523 - val_loss: 0.5817 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5674 - accuracy: 0.8523 - val_loss: 0.5675 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5544 - accuracy: 0.8523 - val_loss: 0.5539 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5405 - accuracy: 0.8523 - val_loss: 0.5411 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5389 - accuracy: 0.8523 - val_loss: 0.5285 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5183 - accuracy: 0.8523 - val_loss: 0.5166 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5104 - accuracy: 0.8523 - val_loss: 0.5045 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4992 - accuracy: 0.8523 - val_loss: 0.4922 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4970 - accuracy: 0.8523 - val_loss: 0.4808 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4817 - accuracy: 0.8523 - val_loss: 0.4706 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4672 - accuracy: 0.8523 - val_loss: 0.4593 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4570 - accuracy: 0.8523 - val_loss: 0.4498 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4526 - accuracy: 0.8523 - val_loss: 0.4401 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4345 - accuracy: 0.8523 - val_loss: 0.4300 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4379 - accuracy: 0.8523 - val_loss: 0.4228 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4235 - accuracy: 0.8523 - val_loss: 0.4144 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4267 - accuracy: 0.8523 - val_loss: 0.4108 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4092 - accuracy: 0.8523 - val_loss: 0.4057 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4041 - accuracy: 0.8523 - val_loss: 0.4001 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3981 - accuracy: 0.8523 - val_loss: 0.3975 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3958 - accuracy: 0.8523 - val_loss: 0.3925 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3946 - accuracy: 0.8523 - val_loss: 0.3915 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3846 - accuracy: 0.8523 - val_loss: 0.3872 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3759 - accuracy: 0.8523 - val_loss: 0.3885 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3762 - accuracy: 0.8523 - val_loss: 0.3807 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3672 - accuracy: 0.8523 - val_loss: 0.3791 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3671 - accuracy: 0.8523 - val_loss: 0.3818 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3657 - accuracy: 0.8523 - val_loss: 0.3893 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3608 - accuracy: 0.8523 - val_loss: 0.3813 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3551 - accuracy: 0.8523 - val_loss: 0.3734 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3512 - accuracy: 0.8523 - val_loss: 0.3821 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3604 - accuracy: 0.8523 - val_loss: 0.3799 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3479 - accuracy: 0.8523 - val_loss: 0.3904 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3480 - accuracy: 0.8523 - val_loss: 0.3826 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3468 - accuracy: 0.8523 - val_loss: 0.3695 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3440 - accuracy: 0.8523 - val_loss: 0.3776 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3374 - accuracy: 0.8523 - val_loss: 0.3820 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3407 - accuracy: 0.8523 - val_loss: 0.3782 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3287 - accuracy: 0.8523 - val_loss: 0.3731 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3281 - accuracy: 0.8523 - val_loss: 0.3741 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3241 - accuracy: 0.8523 - val_loss: 0.3745 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.3227 - accuracy: 0.8523 - val_loss: 0.3866 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3306 - accuracy: 0.8523 - val_loss: 0.3888 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.3254 - accuracy: 0.8523 - val_loss: 0.3834 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3239 - accuracy: 0.8523 - val_loss: 0.3842 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.3158 - accuracy: 0.8523 - val_loss: 0.3837 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3188 - accuracy: 0.8523 - val_loss: 0.3852 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3325 - accuracy: 0.8523 - val_loss: 0.3816 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3190 - accuracy: 0.8523 - val_loss: 0.3841 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3187 - accuracy: 0.8523 - val_loss: 0.3819 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3092 - accuracy: 0.8523 - val_loss: 0.3808 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3048 - accuracy: 0.8523 - val_loss: 0.3853 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3145 - accuracy: 0.8523 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.3111 - accuracy: 0.8523 - val_loss: 0.3843 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.3094 - accuracy: 0.8523 - val_loss: 0.3814 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3021 - accuracy: 0.8523 - val_loss: 0.3962 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3070 - accuracy: 0.8523 - val_loss: 0.3951 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3029 - accuracy: 0.8523 - val_loss: 0.3902 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3055 - accuracy: 0.8523 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3128 - accuracy: 0.8824 - val_loss: 0.4030 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3042 - accuracy: 0.8843 - val_loss: 0.3832 - val_accuracy: 0.9033\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3035 - accuracy: 0.9269 - val_loss: 0.3704 - val_accuracy: 0.9067\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2969 - accuracy: 0.9199 - val_loss: 0.3744 - val_accuracy: 0.8967\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3052 - accuracy: 0.9310 - val_loss: 0.3808 - val_accuracy: 0.9000\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2955 - accuracy: 0.9255 - val_loss: 0.3858 - val_accuracy: 0.9167\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2988 - accuracy: 0.9319 - val_loss: 0.3835 - val_accuracy: 0.9233\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2983 - accuracy: 0.9329 - val_loss: 0.3815 - val_accuracy: 0.9133\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2965 - accuracy: 0.9375 - val_loss: 0.3794 - val_accuracy: 0.9167\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2979 - accuracy: 0.9310 - val_loss: 0.3785 - val_accuracy: 0.9200\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2946 - accuracy: 0.9306 - val_loss: 0.3781 - val_accuracy: 0.9267\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2921 - accuracy: 0.9370 - val_loss: 0.3877 - val_accuracy: 0.9133\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2965 - accuracy: 0.9315 - val_loss: 0.3782 - val_accuracy: 0.9133\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2973 - accuracy: 0.9329 - val_loss: 0.3805 - val_accuracy: 0.9167\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2927 - accuracy: 0.9398 - val_loss: 0.3816 - val_accuracy: 0.9167\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2917 - accuracy: 0.9426 - val_loss: 0.3701 - val_accuracy: 0.9167\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2887 - accuracy: 0.9394 - val_loss: 0.3626 - val_accuracy: 0.9233\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2874 - accuracy: 0.9398 - val_loss: 0.3694 - val_accuracy: 0.9267\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2851 - accuracy: 0.9380 - val_loss: 0.3751 - val_accuracy: 0.9200\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2788 - accuracy: 0.9421 - val_loss: 0.3733 - val_accuracy: 0.9233\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2790 - accuracy: 0.9403 - val_loss: 0.3769 - val_accuracy: 0.9200\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2796 - accuracy: 0.9389 - val_loss: 0.3682 - val_accuracy: 0.9200\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2936 - accuracy: 0.9407 - val_loss: 0.3745 - val_accuracy: 0.9267\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2863 - accuracy: 0.9440 - val_loss: 0.3709 - val_accuracy: 0.9167\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2895 - accuracy: 0.9352 - val_loss: 0.3813 - val_accuracy: 0.9267\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2795 - accuracy: 0.9431 - val_loss: 0.3809 - val_accuracy: 0.9300\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2930 - accuracy: 0.9431 - val_loss: 0.3699 - val_accuracy: 0.9200\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2800 - accuracy: 0.9426 - val_loss: 0.3801 - val_accuracy: 0.9100\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2949 - accuracy: 0.9389 - val_loss: 0.3823 - val_accuracy: 0.9200\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2893 - accuracy: 0.9380 - val_loss: 0.3821 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2762 - accuracy: 0.9417 - val_loss: 0.3910 - val_accuracy: 0.9267\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2769 - accuracy: 0.9449 - val_loss: 0.4016 - val_accuracy: 0.9267\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2773 - accuracy: 0.9417 - val_loss: 0.3920 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2750 - accuracy: 0.9468 - val_loss: 0.3967 - val_accuracy: 0.9233\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2806 - accuracy: 0.9417 - val_loss: 0.3827 - val_accuracy: 0.9300\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2745 - accuracy: 0.9468 - val_loss: 0.3849 - val_accuracy: 0.9267\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2668 - accuracy: 0.9505 - val_loss: 0.3943 - val_accuracy: 0.9267\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2748 - accuracy: 0.9472 - val_loss: 0.3961 - val_accuracy: 0.9233\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2776 - accuracy: 0.9444 - val_loss: 0.3749 - val_accuracy: 0.9367\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2726 - accuracy: 0.9472 - val_loss: 0.3861 - val_accuracy: 0.9367\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2735 - accuracy: 0.9537 - val_loss: 0.4024 - val_accuracy: 0.9333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2737 - accuracy: 0.9407 - val_loss: 0.3996 - val_accuracy: 0.9267\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2640 - accuracy: 0.9579 - val_loss: 0.4016 - val_accuracy: 0.9267\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2682 - accuracy: 0.9565 - val_loss: 0.3734 - val_accuracy: 0.9333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2765 - accuracy: 0.9532 - val_loss: 0.3637 - val_accuracy: 0.9267\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2747 - accuracy: 0.9444 - val_loss: 0.3674 - val_accuracy: 0.9267\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2732 - accuracy: 0.9458 - val_loss: 0.3937 - val_accuracy: 0.9300\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2717 - accuracy: 0.9519 - val_loss: 0.4002 - val_accuracy: 0.9267\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2762 - accuracy: 0.9495 - val_loss: 0.3813 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2722 - accuracy: 0.9477 - val_loss: 0.3833 - val_accuracy: 0.9333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2670 - accuracy: 0.9495 - val_loss: 0.3859 - val_accuracy: 0.9333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2689 - accuracy: 0.9532 - val_loss: 0.3886 - val_accuracy: 0.9300\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2712 - accuracy: 0.9472 - val_loss: 0.4009 - val_accuracy: 0.9267\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2648 - accuracy: 0.9495 - val_loss: 0.4025 - val_accuracy: 0.9233\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2687 - accuracy: 0.9444 - val_loss: 0.4048 - val_accuracy: 0.9100\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2730 - accuracy: 0.9454 - val_loss: 0.3854 - val_accuracy: 0.9167\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2635 - accuracy: 0.9491 - val_loss: 0.3864 - val_accuracy: 0.9300\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2663 - accuracy: 0.9514 - val_loss: 0.3940 - val_accuracy: 0.9200\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2704 - accuracy: 0.9463 - val_loss: 0.3723 - val_accuracy: 0.9267\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2664 - accuracy: 0.9500 - val_loss: 0.3671 - val_accuracy: 0.9233\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2672 - accuracy: 0.9495 - val_loss: 0.3900 - val_accuracy: 0.9267\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2597 - accuracy: 0.9523 - val_loss: 0.3987 - val_accuracy: 0.9333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2663 - accuracy: 0.9435 - val_loss: 0.3946 - val_accuracy: 0.9333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2549 - accuracy: 0.9556 - val_loss: 0.4012 - val_accuracy: 0.9300\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2562 - accuracy: 0.9560 - val_loss: 0.3863 - val_accuracy: 0.9300\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2564 - accuracy: 0.9509 - val_loss: 0.3882 - val_accuracy: 0.9300\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2579 - accuracy: 0.9509 - val_loss: 0.3869 - val_accuracy: 0.9300\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2571 - accuracy: 0.9542 - val_loss: 0.3687 - val_accuracy: 0.9200\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2640 - accuracy: 0.9468 - val_loss: 0.3784 - val_accuracy: 0.9300\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2644 - accuracy: 0.9514 - val_loss: 0.3793 - val_accuracy: 0.9300\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2626 - accuracy: 0.9491 - val_loss: 0.3778 - val_accuracy: 0.9233\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2606 - accuracy: 0.9532 - val_loss: 0.4081 - val_accuracy: 0.9200\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2555 - accuracy: 0.9523 - val_loss: 0.4172 - val_accuracy: 0.9267\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2593 - accuracy: 0.9505 - val_loss: 0.4190 - val_accuracy: 0.9200\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2556 - accuracy: 0.9519 - val_loss: 0.4146 - val_accuracy: 0.9233\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2643 - accuracy: 0.9500 - val_loss: 0.4123 - val_accuracy: 0.9267\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2579 - accuracy: 0.9519 - val_loss: 0.4215 - val_accuracy: 0.9233\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2565 - accuracy: 0.9486 - val_loss: 0.4294 - val_accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2622 - accuracy: 0.9514 - val_loss: 0.4012 - val_accuracy: 0.9267\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2540 - accuracy: 0.9556 - val_loss: 0.4020 - val_accuracy: 0.9333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2592 - accuracy: 0.9463 - val_loss: 0.4098 - val_accuracy: 0.9267\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2438 - accuracy: 0.9593 - val_loss: 0.4205 - val_accuracy: 0.9300\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2549 - accuracy: 0.9551 - val_loss: 0.4090 - val_accuracy: 0.9367\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2472 - accuracy: 0.9574 - val_loss: 0.3873 - val_accuracy: 0.9267\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2516 - accuracy: 0.9574 - val_loss: 0.4100 - val_accuracy: 0.9300\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2473 - accuracy: 0.9569 - val_loss: 0.4288 - val_accuracy: 0.9233\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2491 - accuracy: 0.9630 - val_loss: 0.4294 - val_accuracy: 0.9233\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2462 - accuracy: 0.9574 - val_loss: 0.4240 - val_accuracy: 0.9233\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2507 - accuracy: 0.9625 - val_loss: 0.4341 - val_accuracy: 0.9267\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2447 - accuracy: 0.9593 - val_loss: 0.4287 - val_accuracy: 0.9300\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2556 - accuracy: 0.9523 - val_loss: 0.4148 - val_accuracy: 0.9267\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2485 - accuracy: 0.9528 - val_loss: 0.4074 - val_accuracy: 0.9267\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2509 - accuracy: 0.9532 - val_loss: 0.4042 - val_accuracy: 0.9300\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2441 - accuracy: 0.9537 - val_loss: 0.4176 - val_accuracy: 0.9233\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2492 - accuracy: 0.9574 - val_loss: 0.4129 - val_accuracy: 0.9200\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2484 - accuracy: 0.9542 - val_loss: 0.4173 - val_accuracy: 0.9233\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2510 - accuracy: 0.9486 - val_loss: 0.3942 - val_accuracy: 0.9233\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2458 - accuracy: 0.9565 - val_loss: 0.3924 - val_accuracy: 0.9267\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2479 - accuracy: 0.9505 - val_loss: 0.4160 - val_accuracy: 0.9233\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2505 - accuracy: 0.9556 - val_loss: 0.4214 - val_accuracy: 0.9233\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2448 - accuracy: 0.9551 - val_loss: 0.4267 - val_accuracy: 0.9167\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2516 - accuracy: 0.9509 - val_loss: 0.3968 - val_accuracy: 0.9133\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2377 - accuracy: 0.9556 - val_loss: 0.3938 - val_accuracy: 0.9133\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2463 - accuracy: 0.9523 - val_loss: 0.3940 - val_accuracy: 0.9200\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2481 - accuracy: 0.9542 - val_loss: 0.4100 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2493 - accuracy: 0.9528 - val_loss: 0.4105 - val_accuracy: 0.9200\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2556 - accuracy: 0.9463 - val_loss: 0.3955 - val_accuracy: 0.9200\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2466 - accuracy: 0.9565 - val_loss: 0.3965 - val_accuracy: 0.9267\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2541 - accuracy: 0.9495 - val_loss: 0.4062 - val_accuracy: 0.9300\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2397 - accuracy: 0.9551 - val_loss: 0.3880 - val_accuracy: 0.9233\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2642 - accuracy: 0.9394 - val_loss: 0.4081 - val_accuracy: 0.9300\n",
      "540/540 [==============================] - 0s 291us/sample - loss: 0.4144 - accuracy: 0.9352\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 379us/sample - loss: 3.4089 - accuracy: 0.3519 - val_loss: 2.1910 - val_accuracy: 0.5467\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 2.6422 - accuracy: 0.4884 - val_loss: 1.9764 - val_accuracy: 0.8467\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.2593 - accuracy: 0.5755 - val_loss: 1.8537 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.0407 - accuracy: 0.6630 - val_loss: 1.7611 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8818 - accuracy: 0.7315 - val_loss: 1.6792 - val_accuracy: 0.8300\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.7806 - accuracy: 0.7407 - val_loss: 1.6027 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6870 - accuracy: 0.7685 - val_loss: 1.5278 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.5892 - accuracy: 0.7773 - val_loss: 1.4564 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.4957 - accuracy: 0.8000 - val_loss: 1.3887 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.4262 - accuracy: 0.8032 - val_loss: 1.3244 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.3546 - accuracy: 0.8213 - val_loss: 1.2626 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2697 - accuracy: 0.8213 - val_loss: 1.2053 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2218 - accuracy: 0.8278 - val_loss: 1.1512 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1637 - accuracy: 0.8380 - val_loss: 1.1007 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.1124 - accuracy: 0.8347 - val_loss: 1.0530 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0463 - accuracy: 0.8398 - val_loss: 1.0089 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0119 - accuracy: 0.8380 - val_loss: 0.9673 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9697 - accuracy: 0.8407 - val_loss: 0.9301 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9376 - accuracy: 0.8472 - val_loss: 0.8955 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8919 - accuracy: 0.8468 - val_loss: 0.8631 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8599 - accuracy: 0.8463 - val_loss: 0.8318 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8433 - accuracy: 0.8472 - val_loss: 0.8039 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8125 - accuracy: 0.8472 - val_loss: 0.7783 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7836 - accuracy: 0.8481 - val_loss: 0.7539 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7608 - accuracy: 0.8495 - val_loss: 0.7313 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7329 - accuracy: 0.8495 - val_loss: 0.7098 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7123 - accuracy: 0.8500 - val_loss: 0.6905 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6933 - accuracy: 0.8505 - val_loss: 0.6723 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6682 - accuracy: 0.8500 - val_loss: 0.6541 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6596 - accuracy: 0.8505 - val_loss: 0.6391 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6354 - accuracy: 0.8505 - val_loss: 0.6235 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6293 - accuracy: 0.8500 - val_loss: 0.6092 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6108 - accuracy: 0.8505 - val_loss: 0.5956 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6001 - accuracy: 0.8500 - val_loss: 0.5818 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5985 - accuracy: 0.8505 - val_loss: 0.5704 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5765 - accuracy: 0.8505 - val_loss: 0.5598 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5566 - accuracy: 0.8505 - val_loss: 0.5465 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5548 - accuracy: 0.8505 - val_loss: 0.5346 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5408 - accuracy: 0.8505 - val_loss: 0.5221 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5252 - accuracy: 0.8505 - val_loss: 0.5106 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5222 - accuracy: 0.8500 - val_loss: 0.5022 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5162 - accuracy: 0.8500 - val_loss: 0.4935 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4996 - accuracy: 0.8500 - val_loss: 0.4832 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4922 - accuracy: 0.8500 - val_loss: 0.4759 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4856 - accuracy: 0.8495 - val_loss: 0.4684 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4815 - accuracy: 0.8505 - val_loss: 0.4607 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4682 - accuracy: 0.8500 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4657 - accuracy: 0.8500 - val_loss: 0.4456 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4612 - accuracy: 0.8500 - val_loss: 0.4399 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4480 - accuracy: 0.8500 - val_loss: 0.4318 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4509 - accuracy: 0.8505 - val_loss: 0.4258 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4347 - accuracy: 0.8505 - val_loss: 0.4189 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4411 - accuracy: 0.8505 - val_loss: 0.4144 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4331 - accuracy: 0.8505 - val_loss: 0.4117 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4188 - accuracy: 0.8505 - val_loss: 0.4059 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4155 - accuracy: 0.8505 - val_loss: 0.4009 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4064 - accuracy: 0.8505 - val_loss: 0.3966 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4086 - accuracy: 0.8505 - val_loss: 0.3977 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4055 - accuracy: 0.8500 - val_loss: 0.3930 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3900 - accuracy: 0.8500 - val_loss: 0.3901 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3942 - accuracy: 0.8500 - val_loss: 0.3921 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3837 - accuracy: 0.8505 - val_loss: 0.3850 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3820 - accuracy: 0.8505 - val_loss: 0.3828 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3809 - accuracy: 0.8505 - val_loss: 0.3770 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3767 - accuracy: 0.8505 - val_loss: 0.3801 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3744 - accuracy: 0.8505 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3745 - accuracy: 0.8495 - val_loss: 0.3777 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3728 - accuracy: 0.8505 - val_loss: 0.3788 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3693 - accuracy: 0.8505 - val_loss: 0.3727 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3609 - accuracy: 0.8505 - val_loss: 0.3674 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3648 - accuracy: 0.8500 - val_loss: 0.3719 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3585 - accuracy: 0.8500 - val_loss: 0.3730 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3581 - accuracy: 0.8505 - val_loss: 0.3736 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3574 - accuracy: 0.8505 - val_loss: 0.3719 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3550 - accuracy: 0.8505 - val_loss: 0.3748 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3521 - accuracy: 0.8505 - val_loss: 0.3721 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3500 - accuracy: 0.8505 - val_loss: 0.3650 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3480 - accuracy: 0.8505 - val_loss: 0.3672 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3416 - accuracy: 0.8505 - val_loss: 0.3649 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3416 - accuracy: 0.8505 - val_loss: 0.3677 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3420 - accuracy: 0.8505 - val_loss: 0.3646 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3418 - accuracy: 0.8505 - val_loss: 0.3621 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3342 - accuracy: 0.8505 - val_loss: 0.3606 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3421 - accuracy: 0.8505 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3351 - accuracy: 0.8505 - val_loss: 0.3580 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3381 - accuracy: 0.8505 - val_loss: 0.3582 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3341 - accuracy: 0.8505 - val_loss: 0.3610 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3389 - accuracy: 0.8505 - val_loss: 0.3551 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3292 - accuracy: 0.8505 - val_loss: 0.3573 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3394 - accuracy: 0.8505 - val_loss: 0.3597 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3307 - accuracy: 0.8505 - val_loss: 0.3629 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3342 - accuracy: 0.8505 - val_loss: 0.3610 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3308 - accuracy: 0.8505 - val_loss: 0.3534 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3302 - accuracy: 0.8505 - val_loss: 0.3538 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3235 - accuracy: 0.8505 - val_loss: 0.3568 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3257 - accuracy: 0.8505 - val_loss: 0.3572 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.3204 - accuracy: 0.8505 - val_loss: 0.3564 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3283 - accuracy: 0.8505 - val_loss: 0.3464 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3247 - accuracy: 0.8505 - val_loss: 0.3470 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3233 - accuracy: 0.8505 - val_loss: 0.3552 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3273 - accuracy: 0.8505 - val_loss: 0.3507 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3161 - accuracy: 0.8505 - val_loss: 0.3516 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3142 - accuracy: 0.8505 - val_loss: 0.3579 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3242 - accuracy: 0.8505 - val_loss: 0.3565 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3182 - accuracy: 0.8505 - val_loss: 0.3566 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3152 - accuracy: 0.8500 - val_loss: 0.3499 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3236 - accuracy: 0.8500 - val_loss: 0.3484 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3154 - accuracy: 0.8505 - val_loss: 0.3493 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3110 - accuracy: 0.8505 - val_loss: 0.3501 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3132 - accuracy: 0.8505 - val_loss: 0.3532 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3110 - accuracy: 0.8505 - val_loss: 0.3485 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3186 - accuracy: 0.8505 - val_loss: 0.3409 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3156 - accuracy: 0.8505 - val_loss: 0.3334 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3165 - accuracy: 0.8500 - val_loss: 0.3398 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3179 - accuracy: 0.8491 - val_loss: 0.3412 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3093 - accuracy: 0.8505 - val_loss: 0.3483 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3076 - accuracy: 0.8505 - val_loss: 0.3525 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3120 - accuracy: 0.8523 - val_loss: 0.3524 - val_accuracy: 0.8700\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2997 - accuracy: 0.9125 - val_loss: 0.3501 - val_accuracy: 0.8800\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3094 - accuracy: 0.9139 - val_loss: 0.3428 - val_accuracy: 0.9067\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3022 - accuracy: 0.9241 - val_loss: 0.3393 - val_accuracy: 0.9067\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3063 - accuracy: 0.9292 - val_loss: 0.3494 - val_accuracy: 0.9033\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3033 - accuracy: 0.9241 - val_loss: 0.3523 - val_accuracy: 0.9167\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3092 - accuracy: 0.9319 - val_loss: 0.3444 - val_accuracy: 0.9167\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3062 - accuracy: 0.9329 - val_loss: 0.3433 - val_accuracy: 0.9033\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3006 - accuracy: 0.9296 - val_loss: 0.3361 - val_accuracy: 0.9033\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3091 - accuracy: 0.9245 - val_loss: 0.3427 - val_accuracy: 0.9033\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2937 - accuracy: 0.9343 - val_loss: 0.3581 - val_accuracy: 0.9100\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3018 - accuracy: 0.9366 - val_loss: 0.3553 - val_accuracy: 0.9200\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3013 - accuracy: 0.9282 - val_loss: 0.3437 - val_accuracy: 0.9300\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2940 - accuracy: 0.9282 - val_loss: 0.3523 - val_accuracy: 0.9167\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3029 - accuracy: 0.9329 - val_loss: 0.3470 - val_accuracy: 0.9233\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3004 - accuracy: 0.9319 - val_loss: 0.3466 - val_accuracy: 0.9233\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2985 - accuracy: 0.9375 - val_loss: 0.3492 - val_accuracy: 0.9167\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2981 - accuracy: 0.9356 - val_loss: 0.3455 - val_accuracy: 0.9233\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2981 - accuracy: 0.9398 - val_loss: 0.3413 - val_accuracy: 0.9333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3005 - accuracy: 0.9310 - val_loss: 0.3471 - val_accuracy: 0.9267\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2962 - accuracy: 0.9394 - val_loss: 0.3568 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3054 - accuracy: 0.9292 - val_loss: 0.3598 - val_accuracy: 0.9133\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3046 - accuracy: 0.9380 - val_loss: 0.3483 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3041 - accuracy: 0.9375 - val_loss: 0.3468 - val_accuracy: 0.9167\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3067 - accuracy: 0.9329 - val_loss: 0.3577 - val_accuracy: 0.9200\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2981 - accuracy: 0.9412 - val_loss: 0.3587 - val_accuracy: 0.9067\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2965 - accuracy: 0.9366 - val_loss: 0.3581 - val_accuracy: 0.9067\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2950 - accuracy: 0.9375 - val_loss: 0.3585 - val_accuracy: 0.9200\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2959 - accuracy: 0.9412 - val_loss: 0.3669 - val_accuracy: 0.9233\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2945 - accuracy: 0.9343 - val_loss: 0.3554 - val_accuracy: 0.9267\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2943 - accuracy: 0.9338 - val_loss: 0.3588 - val_accuracy: 0.9233\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2945 - accuracy: 0.9384 - val_loss: 0.3556 - val_accuracy: 0.9233\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2864 - accuracy: 0.9472 - val_loss: 0.3720 - val_accuracy: 0.9200\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2873 - accuracy: 0.9417 - val_loss: 0.3679 - val_accuracy: 0.9267\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2931 - accuracy: 0.9407 - val_loss: 0.3714 - val_accuracy: 0.9200\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2931 - accuracy: 0.9398 - val_loss: 0.3572 - val_accuracy: 0.9167\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3041 - accuracy: 0.9273 - val_loss: 0.3593 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2884 - accuracy: 0.9435 - val_loss: 0.3634 - val_accuracy: 0.9267\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2894 - accuracy: 0.9449 - val_loss: 0.3557 - val_accuracy: 0.9233\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2881 - accuracy: 0.9426 - val_loss: 0.3534 - val_accuracy: 0.9267\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2837 - accuracy: 0.9403 - val_loss: 0.3429 - val_accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2857 - accuracy: 0.9449 - val_loss: 0.3510 - val_accuracy: 0.9267\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2861 - accuracy: 0.9412 - val_loss: 0.3488 - val_accuracy: 0.9233\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2874 - accuracy: 0.9440 - val_loss: 0.3460 - val_accuracy: 0.9267\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2883 - accuracy: 0.9398 - val_loss: 0.3499 - val_accuracy: 0.9267\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2798 - accuracy: 0.9463 - val_loss: 0.3526 - val_accuracy: 0.9300\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2769 - accuracy: 0.9505 - val_loss: 0.3574 - val_accuracy: 0.9233\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2786 - accuracy: 0.9458 - val_loss: 0.3537 - val_accuracy: 0.9333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2802 - accuracy: 0.9454 - val_loss: 0.3502 - val_accuracy: 0.9367\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2760 - accuracy: 0.9481 - val_loss: 0.3383 - val_accuracy: 0.9300\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2821 - accuracy: 0.9407 - val_loss: 0.3524 - val_accuracy: 0.9300\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2792 - accuracy: 0.9454 - val_loss: 0.3561 - val_accuracy: 0.9267\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2779 - accuracy: 0.9454 - val_loss: 0.3543 - val_accuracy: 0.9300\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2784 - accuracy: 0.9472 - val_loss: 0.3613 - val_accuracy: 0.9267\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2898 - accuracy: 0.9370 - val_loss: 0.3613 - val_accuracy: 0.9233\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2806 - accuracy: 0.9417 - val_loss: 0.3614 - val_accuracy: 0.9300\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2830 - accuracy: 0.9375 - val_loss: 0.3636 - val_accuracy: 0.9267\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2788 - accuracy: 0.9472 - val_loss: 0.3476 - val_accuracy: 0.9367\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2826 - accuracy: 0.9500 - val_loss: 0.3485 - val_accuracy: 0.9333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2823 - accuracy: 0.9468 - val_loss: 0.3605 - val_accuracy: 0.9200\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2842 - accuracy: 0.9398 - val_loss: 0.3530 - val_accuracy: 0.9233\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2865 - accuracy: 0.9417 - val_loss: 0.3386 - val_accuracy: 0.9200\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2776 - accuracy: 0.9458 - val_loss: 0.3536 - val_accuracy: 0.9167\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2711 - accuracy: 0.9495 - val_loss: 0.3575 - val_accuracy: 0.9300\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2728 - accuracy: 0.9551 - val_loss: 0.3528 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2837 - accuracy: 0.9426 - val_loss: 0.3420 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2849 - accuracy: 0.9421 - val_loss: 0.3457 - val_accuracy: 0.9367\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2800 - accuracy: 0.9444 - val_loss: 0.3369 - val_accuracy: 0.9400\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2882 - accuracy: 0.9407 - val_loss: 0.3328 - val_accuracy: 0.9433\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2787 - accuracy: 0.9481 - val_loss: 0.3429 - val_accuracy: 0.9433\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2732 - accuracy: 0.9500 - val_loss: 0.3553 - val_accuracy: 0.9367\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2739 - accuracy: 0.9444 - val_loss: 0.3520 - val_accuracy: 0.9333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.92 - 0s 19us/sample - loss: 0.2729 - accuracy: 0.9435 - val_loss: 0.3454 - val_accuracy: 0.9400\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2714 - accuracy: 0.9505 - val_loss: 0.3451 - val_accuracy: 0.9400\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2745 - accuracy: 0.9468 - val_loss: 0.3604 - val_accuracy: 0.9233\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2772 - accuracy: 0.9440 - val_loss: 0.3550 - val_accuracy: 0.9267\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2792 - accuracy: 0.9431 - val_loss: 0.3555 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2782 - accuracy: 0.9477 - val_loss: 0.3516 - val_accuracy: 0.9300\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2815 - accuracy: 0.9458 - val_loss: 0.3639 - val_accuracy: 0.9300\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2817 - accuracy: 0.9435 - val_loss: 0.3467 - val_accuracy: 0.9300\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2803 - accuracy: 0.9449 - val_loss: 0.3553 - val_accuracy: 0.9300\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2739 - accuracy: 0.9500 - val_loss: 0.3546 - val_accuracy: 0.9300\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2707 - accuracy: 0.9509 - val_loss: 0.3692 - val_accuracy: 0.9300\n",
      "540/540 [==============================] - 0s 284us/sample - loss: 0.3793 - accuracy: 0.9481\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 505us/sample - loss: 2.8656 - accuracy: 0.4574 - val_loss: 2.2294 - val_accuracy: 0.4733\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.4516 - accuracy: 0.5796 - val_loss: 2.0485 - val_accuracy: 0.7100\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.1609 - accuracy: 0.6759 - val_loss: 1.9208 - val_accuracy: 0.8233\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.9911 - accuracy: 0.7176 - val_loss: 1.8157 - val_accuracy: 0.8300\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8216 - accuracy: 0.7704 - val_loss: 1.7207 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.7306 - accuracy: 0.7792 - val_loss: 1.6322 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.6273 - accuracy: 0.7907 - val_loss: 1.5496 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.5311 - accuracy: 0.8130 - val_loss: 1.4704 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4542 - accuracy: 0.8134 - val_loss: 1.3944 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3667 - accuracy: 0.8306 - val_loss: 1.3238 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2830 - accuracy: 0.8375 - val_loss: 1.2562 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2278 - accuracy: 0.8380 - val_loss: 1.1929 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.1594 - accuracy: 0.8454 - val_loss: 1.1345 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0911 - accuracy: 0.8519 - val_loss: 1.0811 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0412 - accuracy: 0.8528 - val_loss: 1.0325 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0003 - accuracy: 0.8542 - val_loss: 0.9870 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9536 - accuracy: 0.8509 - val_loss: 0.9459 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.9062 - accuracy: 0.8569 - val_loss: 0.9072 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8764 - accuracy: 0.8565 - val_loss: 0.8723 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8353 - accuracy: 0.8569 - val_loss: 0.8397 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7996 - accuracy: 0.8579 - val_loss: 0.8092 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7755 - accuracy: 0.8579 - val_loss: 0.7810 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7483 - accuracy: 0.8579 - val_loss: 0.7553 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7194 - accuracy: 0.8569 - val_loss: 0.7318 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6987 - accuracy: 0.8583 - val_loss: 0.7096 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6804 - accuracy: 0.8579 - val_loss: 0.6893 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6578 - accuracy: 0.8583 - val_loss: 0.6703 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6392 - accuracy: 0.8583 - val_loss: 0.6522 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6258 - accuracy: 0.8583 - val_loss: 0.6349 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6014 - accuracy: 0.8583 - val_loss: 0.6185 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5878 - accuracy: 0.8583 - val_loss: 0.6020 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5745 - accuracy: 0.8583 - val_loss: 0.5874 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5605 - accuracy: 0.8583 - val_loss: 0.5734 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5495 - accuracy: 0.8579 - val_loss: 0.5610 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5330 - accuracy: 0.8583 - val_loss: 0.5489 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5320 - accuracy: 0.8583 - val_loss: 0.5363 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5179 - accuracy: 0.8583 - val_loss: 0.5238 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5079 - accuracy: 0.8583 - val_loss: 0.5127 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4889 - accuracy: 0.8579 - val_loss: 0.5004 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4793 - accuracy: 0.8583 - val_loss: 0.4891 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4761 - accuracy: 0.8583 - val_loss: 0.4796 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4676 - accuracy: 0.8583 - val_loss: 0.4700 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4604 - accuracy: 0.8579 - val_loss: 0.4621 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4513 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4447 - accuracy: 0.8583 - val_loss: 0.4461 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4374 - accuracy: 0.8583 - val_loss: 0.4385 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4335 - accuracy: 0.8583 - val_loss: 0.4306 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4245 - accuracy: 0.8579 - val_loss: 0.4234 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4172 - accuracy: 0.8583 - val_loss: 0.4173 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4187 - accuracy: 0.8583 - val_loss: 0.4123 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4044 - accuracy: 0.8583 - val_loss: 0.4049 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3952 - accuracy: 0.8583 - val_loss: 0.4012 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3904 - accuracy: 0.8583 - val_loss: 0.3956 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3851 - accuracy: 0.8579 - val_loss: 0.3947 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3774 - accuracy: 0.8583 - val_loss: 0.3894 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3756 - accuracy: 0.8583 - val_loss: 0.3870 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3799 - accuracy: 0.8583 - val_loss: 0.3903 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3726 - accuracy: 0.8583 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3706 - accuracy: 0.8583 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3716 - accuracy: 0.8583 - val_loss: 0.3786 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3612 - accuracy: 0.8583 - val_loss: 0.3757 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3557 - accuracy: 0.8583 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3538 - accuracy: 0.8583 - val_loss: 0.3680 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3528 - accuracy: 0.8583 - val_loss: 0.3733 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3407 - accuracy: 0.8583 - val_loss: 0.3695 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3359 - accuracy: 0.8583 - val_loss: 0.3705 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3427 - accuracy: 0.8579 - val_loss: 0.3664 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3400 - accuracy: 0.8583 - val_loss: 0.3601 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3327 - accuracy: 0.8583 - val_loss: 0.3662 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3367 - accuracy: 0.8583 - val_loss: 0.3629 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3351 - accuracy: 0.8583 - val_loss: 0.3572 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3257 - accuracy: 0.8583 - val_loss: 0.3642 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3261 - accuracy: 0.8583 - val_loss: 0.3648 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3277 - accuracy: 0.8583 - val_loss: 0.3686 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3235 - accuracy: 0.8583 - val_loss: 0.3643 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3201 - accuracy: 0.8583 - val_loss: 0.3598 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3197 - accuracy: 0.8574 - val_loss: 0.3599 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3250 - accuracy: 0.8583 - val_loss: 0.3629 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3223 - accuracy: 0.8583 - val_loss: 0.3673 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3199 - accuracy: 0.8583 - val_loss: 0.3608 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3150 - accuracy: 0.8583 - val_loss: 0.3662 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3087 - accuracy: 0.8583 - val_loss: 0.3617 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3185 - accuracy: 0.8583 - val_loss: 0.3621 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3219 - accuracy: 0.8579 - val_loss: 0.3532 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3124 - accuracy: 0.8583 - val_loss: 0.3568 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3111 - accuracy: 0.8583 - val_loss: 0.3636 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3177 - accuracy: 0.8579 - val_loss: 0.3591 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3143 - accuracy: 0.8583 - val_loss: 0.3600 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3116 - accuracy: 0.8583 - val_loss: 0.3529 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.85 - 0s 20us/sample - loss: 0.3014 - accuracy: 0.8579 - val_loss: 0.3621 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3121 - accuracy: 0.8583 - val_loss: 0.3570 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3052 - accuracy: 0.8583 - val_loss: 0.3629 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3043 - accuracy: 0.8583 - val_loss: 0.3641 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3006 - accuracy: 0.8583 - val_loss: 0.3596 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3034 - accuracy: 0.8583 - val_loss: 0.3663 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2972 - accuracy: 0.8583 - val_loss: 0.3755 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2966 - accuracy: 0.8583 - val_loss: 0.3715 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2997 - accuracy: 0.8583 - val_loss: 0.3702 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3033 - accuracy: 0.8583 - val_loss: 0.3642 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3014 - accuracy: 0.8583 - val_loss: 0.3637 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2948 - accuracy: 0.8583 - val_loss: 0.3593 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2987 - accuracy: 0.8745 - val_loss: 0.3662 - val_accuracy: 0.9000\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2905 - accuracy: 0.9306 - val_loss: 0.3725 - val_accuracy: 0.8967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2852 - accuracy: 0.9426 - val_loss: 0.3748 - val_accuracy: 0.9100\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2907 - accuracy: 0.9426 - val_loss: 0.3800 - val_accuracy: 0.9133\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2864 - accuracy: 0.9440 - val_loss: 0.3729 - val_accuracy: 0.9033\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2883 - accuracy: 0.9532 - val_loss: 0.3813 - val_accuracy: 0.8967\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2834 - accuracy: 0.9426 - val_loss: 0.3727 - val_accuracy: 0.9067\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2907 - accuracy: 0.9523 - val_loss: 0.3686 - val_accuracy: 0.9167\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2825 - accuracy: 0.9472 - val_loss: 0.3735 - val_accuracy: 0.9033\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2804 - accuracy: 0.9458 - val_loss: 0.3692 - val_accuracy: 0.9067\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2776 - accuracy: 0.9505 - val_loss: 0.3641 - val_accuracy: 0.9067\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2872 - accuracy: 0.9532 - val_loss: 0.3705 - val_accuracy: 0.9067\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2851 - accuracy: 0.9509 - val_loss: 0.3696 - val_accuracy: 0.9067\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2848 - accuracy: 0.9486 - val_loss: 0.3660 - val_accuracy: 0.9100\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2807 - accuracy: 0.9495 - val_loss: 0.3678 - val_accuracy: 0.9100\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2800 - accuracy: 0.9519 - val_loss: 0.3768 - val_accuracy: 0.9067\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2790 - accuracy: 0.9546 - val_loss: 0.3622 - val_accuracy: 0.9133\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2832 - accuracy: 0.9523 - val_loss: 0.3638 - val_accuracy: 0.9167\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2700 - accuracy: 0.9593 - val_loss: 0.3724 - val_accuracy: 0.9100\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2688 - accuracy: 0.9569 - val_loss: 0.3663 - val_accuracy: 0.9100\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2767 - accuracy: 0.9514 - val_loss: 0.3670 - val_accuracy: 0.9100\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2774 - accuracy: 0.9491 - val_loss: 0.3670 - val_accuracy: 0.9167\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2782 - accuracy: 0.9583 - val_loss: 0.3705 - val_accuracy: 0.9167\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2750 - accuracy: 0.9542 - val_loss: 0.3752 - val_accuracy: 0.9100\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2804 - accuracy: 0.9542 - val_loss: 0.3715 - val_accuracy: 0.9200\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2747 - accuracy: 0.9597 - val_loss: 0.3788 - val_accuracy: 0.9233\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2747 - accuracy: 0.9616 - val_loss: 0.3650 - val_accuracy: 0.9200\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2740 - accuracy: 0.9537 - val_loss: 0.3526 - val_accuracy: 0.9200\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2688 - accuracy: 0.9597 - val_loss: 0.3682 - val_accuracy: 0.9133\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2689 - accuracy: 0.9676 - val_loss: 0.3698 - val_accuracy: 0.9200\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2628 - accuracy: 0.9574 - val_loss: 0.3724 - val_accuracy: 0.9167\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2701 - accuracy: 0.9588 - val_loss: 0.3678 - val_accuracy: 0.9133\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2679 - accuracy: 0.9588 - val_loss: 0.3830 - val_accuracy: 0.9167\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2634 - accuracy: 0.9620 - val_loss: 0.3644 - val_accuracy: 0.9167\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2672 - accuracy: 0.9560 - val_loss: 0.3571 - val_accuracy: 0.9133\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2686 - accuracy: 0.9574 - val_loss: 0.3714 - val_accuracy: 0.9100\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2642 - accuracy: 0.9602 - val_loss: 0.3794 - val_accuracy: 0.9167\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2664 - accuracy: 0.9537 - val_loss: 0.3767 - val_accuracy: 0.9133\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2630 - accuracy: 0.9634 - val_loss: 0.3696 - val_accuracy: 0.9133\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2549 - accuracy: 0.9671 - val_loss: 0.3700 - val_accuracy: 0.9200\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2602 - accuracy: 0.9588 - val_loss: 0.3850 - val_accuracy: 0.9133\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2591 - accuracy: 0.9625 - val_loss: 0.3783 - val_accuracy: 0.9167\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2612 - accuracy: 0.9583 - val_loss: 0.3807 - val_accuracy: 0.9133\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2665 - accuracy: 0.9574 - val_loss: 0.3603 - val_accuracy: 0.9167\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2649 - accuracy: 0.9583 - val_loss: 0.3819 - val_accuracy: 0.9200\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2626 - accuracy: 0.9588 - val_loss: 0.3925 - val_accuracy: 0.9200\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2745 - accuracy: 0.9528 - val_loss: 0.3752 - val_accuracy: 0.9167\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2561 - accuracy: 0.9662 - val_loss: 0.3836 - val_accuracy: 0.9133\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2553 - accuracy: 0.9616 - val_loss: 0.3916 - val_accuracy: 0.9133\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2538 - accuracy: 0.9639 - val_loss: 0.3764 - val_accuracy: 0.9233\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2561 - accuracy: 0.9676 - val_loss: 0.3737 - val_accuracy: 0.9200\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2561 - accuracy: 0.9653 - val_loss: 0.3757 - val_accuracy: 0.9167\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2551 - accuracy: 0.9662 - val_loss: 0.4079 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2639 - accuracy: 0.9565 - val_loss: 0.3583 - val_accuracy: 0.9167\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2564 - accuracy: 0.9611 - val_loss: 0.3731 - val_accuracy: 0.9200\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2541 - accuracy: 0.9625 - val_loss: 0.3723 - val_accuracy: 0.9133\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2563 - accuracy: 0.9634 - val_loss: 0.3620 - val_accuracy: 0.9167\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2576 - accuracy: 0.9556 - val_loss: 0.3668 - val_accuracy: 0.9167\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2584 - accuracy: 0.9625 - val_loss: 0.3744 - val_accuracy: 0.9200\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2526 - accuracy: 0.9630 - val_loss: 0.3904 - val_accuracy: 0.9200\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2578 - accuracy: 0.9616 - val_loss: 0.3789 - val_accuracy: 0.9200\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2560 - accuracy: 0.9579 - val_loss: 0.3634 - val_accuracy: 0.9167\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2633 - accuracy: 0.9569 - val_loss: 0.3715 - val_accuracy: 0.9200\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2568 - accuracy: 0.9611 - val_loss: 0.3701 - val_accuracy: 0.9200\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2509 - accuracy: 0.9694 - val_loss: 0.3602 - val_accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2578 - accuracy: 0.9597 - val_loss: 0.3588 - val_accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2520 - accuracy: 0.9620 - val_loss: 0.3685 - val_accuracy: 0.9100\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2512 - accuracy: 0.9630 - val_loss: 0.3799 - val_accuracy: 0.9167\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2498 - accuracy: 0.9606 - val_loss: 0.3720 - val_accuracy: 0.9133\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2486 - accuracy: 0.9681 - val_loss: 0.3979 - val_accuracy: 0.9133\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2469 - accuracy: 0.9597 - val_loss: 0.4098 - val_accuracy: 0.9167\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2566 - accuracy: 0.9667 - val_loss: 0.3953 - val_accuracy: 0.9200\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2509 - accuracy: 0.9583 - val_loss: 0.3906 - val_accuracy: 0.9200\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2525 - accuracy: 0.9551 - val_loss: 0.3921 - val_accuracy: 0.9200\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2460 - accuracy: 0.9648 - val_loss: 0.3922 - val_accuracy: 0.9233\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2447 - accuracy: 0.9630 - val_loss: 0.3756 - val_accuracy: 0.9233\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2443 - accuracy: 0.9606 - val_loss: 0.3814 - val_accuracy: 0.9133\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2433 - accuracy: 0.9593 - val_loss: 0.3751 - val_accuracy: 0.9100\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2399 - accuracy: 0.9662 - val_loss: 0.3563 - val_accuracy: 0.9167\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2439 - accuracy: 0.9648 - val_loss: 0.3650 - val_accuracy: 0.9233\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2498 - accuracy: 0.9588 - val_loss: 0.3457 - val_accuracy: 0.9200\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2534 - accuracy: 0.9537 - val_loss: 0.3683 - val_accuracy: 0.9133\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2535 - accuracy: 0.9583 - val_loss: 0.3730 - val_accuracy: 0.9200\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2457 - accuracy: 0.9606 - val_loss: 0.3865 - val_accuracy: 0.9233\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2474 - accuracy: 0.9639 - val_loss: 0.3846 - val_accuracy: 0.9200\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2456 - accuracy: 0.9676 - val_loss: 0.3684 - val_accuracy: 0.9267\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2492 - accuracy: 0.9593 - val_loss: 0.3711 - val_accuracy: 0.9233\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2453 - accuracy: 0.9657 - val_loss: 0.3853 - val_accuracy: 0.9200\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2520 - accuracy: 0.9611 - val_loss: 0.3965 - val_accuracy: 0.9200\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2419 - accuracy: 0.9657 - val_loss: 0.3902 - val_accuracy: 0.9233\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2346 - accuracy: 0.9690 - val_loss: 0.4029 - val_accuracy: 0.9167\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2448 - accuracy: 0.9574 - val_loss: 0.4117 - val_accuracy: 0.9267\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2405 - accuracy: 0.9625 - val_loss: 0.4036 - val_accuracy: 0.9233\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2479 - accuracy: 0.9597 - val_loss: 0.3963 - val_accuracy: 0.9267\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2469 - accuracy: 0.9634 - val_loss: 0.3817 - val_accuracy: 0.9233\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2345 - accuracy: 0.9690 - val_loss: 0.4085 - val_accuracy: 0.9233\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2346 - accuracy: 0.9690 - val_loss: 0.3996 - val_accuracy: 0.9200\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2314 - accuracy: 0.9685 - val_loss: 0.4236 - val_accuracy: 0.9233\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2367 - accuracy: 0.9644 - val_loss: 0.4105 - val_accuracy: 0.9233\n",
      "540/540 [==============================] - 0s 277us/sample - loss: 0.5008 - accuracy: 0.9241\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 382us/sample - loss: 2.3978 - accuracy: 0.5968 - val_loss: 2.0476 - val_accuracy: 0.8400\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0698 - accuracy: 0.7083 - val_loss: 1.9046 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.9354 - accuracy: 0.7583 - val_loss: 1.7902 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.7882 - accuracy: 0.7884 - val_loss: 1.6844 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6496 - accuracy: 0.8051 - val_loss: 1.5892 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.5536 - accuracy: 0.8190 - val_loss: 1.4966 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4494 - accuracy: 0.8292 - val_loss: 1.4098 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.3682 - accuracy: 0.8333 - val_loss: 1.3277 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2764 - accuracy: 0.8370 - val_loss: 1.2530 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2093 - accuracy: 0.8426 - val_loss: 1.1836 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.1428 - accuracy: 0.8431 - val_loss: 1.1194 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0651 - accuracy: 0.8426 - val_loss: 1.0597 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0162 - accuracy: 0.8449 - val_loss: 1.0027 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9713 - accuracy: 0.8468 - val_loss: 0.9555 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9284 - accuracy: 0.8477 - val_loss: 0.9089 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8746 - accuracy: 0.8477 - val_loss: 0.8663 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8334 - accuracy: 0.8472 - val_loss: 0.8253 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8025 - accuracy: 0.8472 - val_loss: 0.7900 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7706 - accuracy: 0.8468 - val_loss: 0.7564 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7373 - accuracy: 0.8477 - val_loss: 0.7258 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7122 - accuracy: 0.8477 - val_loss: 0.6996 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6814 - accuracy: 0.8477 - val_loss: 0.6733 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6565 - accuracy: 0.8477 - val_loss: 0.6482 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6346 - accuracy: 0.8477 - val_loss: 0.6254 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6206 - accuracy: 0.8477 - val_loss: 0.6042 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5993 - accuracy: 0.8477 - val_loss: 0.5841 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5755 - accuracy: 0.8477 - val_loss: 0.5634 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5549 - accuracy: 0.8477 - val_loss: 0.5448 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5388 - accuracy: 0.8477 - val_loss: 0.5283 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5252 - accuracy: 0.8477 - val_loss: 0.5147 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5057 - accuracy: 0.8477 - val_loss: 0.4993 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4943 - accuracy: 0.8477 - val_loss: 0.4856 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4874 - accuracy: 0.8477 - val_loss: 0.4733 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4728 - accuracy: 0.8477 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4593 - accuracy: 0.8477 - val_loss: 0.4546 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4559 - accuracy: 0.8477 - val_loss: 0.4472 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4317 - accuracy: 0.8477 - val_loss: 0.4390 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4223 - accuracy: 0.8477 - val_loss: 0.4275 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4195 - accuracy: 0.8477 - val_loss: 0.4211 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4088 - accuracy: 0.8477 - val_loss: 0.4156 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3954 - accuracy: 0.8477 - val_loss: 0.4072 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3865 - accuracy: 0.8477 - val_loss: 0.4113 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3955 - accuracy: 0.8477 - val_loss: 0.4133 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3876 - accuracy: 0.8477 - val_loss: 0.4061 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3839 - accuracy: 0.8477 - val_loss: 0.3985 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3741 - accuracy: 0.8477 - val_loss: 0.3948 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3647 - accuracy: 0.8477 - val_loss: 0.3910 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3602 - accuracy: 0.8477 - val_loss: 0.3845 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3557 - accuracy: 0.8477 - val_loss: 0.3911 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3590 - accuracy: 0.8477 - val_loss: 0.3938 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3477 - accuracy: 0.8477 - val_loss: 0.3877 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3492 - accuracy: 0.8472 - val_loss: 0.3922 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3518 - accuracy: 0.8477 - val_loss: 0.3872 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3429 - accuracy: 0.8477 - val_loss: 0.3923 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3409 - accuracy: 0.8477 - val_loss: 0.3914 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3379 - accuracy: 0.8477 - val_loss: 0.3772 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3319 - accuracy: 0.8477 - val_loss: 0.3776 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3293 - accuracy: 0.8477 - val_loss: 0.3789 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3280 - accuracy: 0.8477 - val_loss: 0.3760 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3223 - accuracy: 0.8477 - val_loss: 0.3810 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3211 - accuracy: 0.8477 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3218 - accuracy: 0.8477 - val_loss: 0.3784 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3282 - accuracy: 0.8477 - val_loss: 0.3759 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3217 - accuracy: 0.8477 - val_loss: 0.3715 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3129 - accuracy: 0.8472 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3166 - accuracy: 0.8477 - val_loss: 0.3807 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3070 - accuracy: 0.8477 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3173 - accuracy: 0.8477 - val_loss: 0.3886 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3146 - accuracy: 0.8472 - val_loss: 0.3652 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3004 - accuracy: 0.8861 - val_loss: 0.3860 - val_accuracy: 0.8867\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3071 - accuracy: 0.9250 - val_loss: 0.3839 - val_accuracy: 0.8967\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3003 - accuracy: 0.9384 - val_loss: 0.3942 - val_accuracy: 0.8967\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3075 - accuracy: 0.9310 - val_loss: 0.3814 - val_accuracy: 0.8900\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2992 - accuracy: 0.9435 - val_loss: 0.3753 - val_accuracy: 0.8833\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3047 - accuracy: 0.9394 - val_loss: 0.3741 - val_accuracy: 0.8967\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2956 - accuracy: 0.9444 - val_loss: 0.3799 - val_accuracy: 0.8967\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3019 - accuracy: 0.9431 - val_loss: 0.3750 - val_accuracy: 0.8967\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2997 - accuracy: 0.9426 - val_loss: 0.3969 - val_accuracy: 0.8967\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2952 - accuracy: 0.9407 - val_loss: 0.3909 - val_accuracy: 0.9000\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2958 - accuracy: 0.9449 - val_loss: 0.3877 - val_accuracy: 0.9100\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2993 - accuracy: 0.9444 - val_loss: 0.3875 - val_accuracy: 0.9033\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2926 - accuracy: 0.9523 - val_loss: 0.3767 - val_accuracy: 0.8933\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2870 - accuracy: 0.9523 - val_loss: 0.3757 - val_accuracy: 0.8967\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2902 - accuracy: 0.9509 - val_loss: 0.3743 - val_accuracy: 0.9167\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2929 - accuracy: 0.9542 - val_loss: 0.3797 - val_accuracy: 0.9167\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2915 - accuracy: 0.9532 - val_loss: 0.3870 - val_accuracy: 0.9133\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3064 - accuracy: 0.9435 - val_loss: 0.3877 - val_accuracy: 0.9000\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2932 - accuracy: 0.9468 - val_loss: 0.3771 - val_accuracy: 0.9067\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2912 - accuracy: 0.9542 - val_loss: 0.3620 - val_accuracy: 0.9133\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2889 - accuracy: 0.9532 - val_loss: 0.3875 - val_accuracy: 0.9133\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2887 - accuracy: 0.9560 - val_loss: 0.3794 - val_accuracy: 0.9133\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2845 - accuracy: 0.9606 - val_loss: 0.3771 - val_accuracy: 0.9167\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2898 - accuracy: 0.9491 - val_loss: 0.3654 - val_accuracy: 0.9233\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2785 - accuracy: 0.9546 - val_loss: 0.3694 - val_accuracy: 0.9133\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2822 - accuracy: 0.9537 - val_loss: 0.3814 - val_accuracy: 0.9133\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2827 - accuracy: 0.9560 - val_loss: 0.3840 - val_accuracy: 0.9100\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2752 - accuracy: 0.9574 - val_loss: 0.3777 - val_accuracy: 0.9167\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2725 - accuracy: 0.9620 - val_loss: 0.3838 - val_accuracy: 0.9167\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2891 - accuracy: 0.9509 - val_loss: 0.3751 - val_accuracy: 0.9233\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2744 - accuracy: 0.9625 - val_loss: 0.3726 - val_accuracy: 0.9100\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2763 - accuracy: 0.9597 - val_loss: 0.3772 - val_accuracy: 0.9100\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2725 - accuracy: 0.9634 - val_loss: 0.3926 - val_accuracy: 0.9100\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2698 - accuracy: 0.9593 - val_loss: 0.3819 - val_accuracy: 0.9133\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2768 - accuracy: 0.9556 - val_loss: 0.3675 - val_accuracy: 0.9067\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2761 - accuracy: 0.9542 - val_loss: 0.3795 - val_accuracy: 0.9100\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2714 - accuracy: 0.9560 - val_loss: 0.3973 - val_accuracy: 0.9033\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2751 - accuracy: 0.9546 - val_loss: 0.3942 - val_accuracy: 0.9033\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2793 - accuracy: 0.9597 - val_loss: 0.3748 - val_accuracy: 0.9033\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2672 - accuracy: 0.9588 - val_loss: 0.3894 - val_accuracy: 0.9133\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2687 - accuracy: 0.9565 - val_loss: 0.3901 - val_accuracy: 0.9100\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2653 - accuracy: 0.9616 - val_loss: 0.3731 - val_accuracy: 0.9100\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2669 - accuracy: 0.9588 - val_loss: 0.4021 - val_accuracy: 0.9200\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2644 - accuracy: 0.9611 - val_loss: 0.4000 - val_accuracy: 0.9167\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2682 - accuracy: 0.9653 - val_loss: 0.3996 - val_accuracy: 0.9133\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2709 - accuracy: 0.9583 - val_loss: 0.4153 - val_accuracy: 0.9067\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2661 - accuracy: 0.9620 - val_loss: 0.3885 - val_accuracy: 0.9133\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2560 - accuracy: 0.9708 - val_loss: 0.4167 - val_accuracy: 0.9167\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2615 - accuracy: 0.9616 - val_loss: 0.4128 - val_accuracy: 0.9167\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2621 - accuracy: 0.9644 - val_loss: 0.4156 - val_accuracy: 0.9100\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2694 - accuracy: 0.9565 - val_loss: 0.4112 - val_accuracy: 0.9100\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2570 - accuracy: 0.9667 - val_loss: 0.4073 - val_accuracy: 0.9133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2603 - accuracy: 0.9620 - val_loss: 0.4149 - val_accuracy: 0.9167\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2542 - accuracy: 0.9662 - val_loss: 0.4034 - val_accuracy: 0.9167\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2630 - accuracy: 0.9634 - val_loss: 0.4303 - val_accuracy: 0.9167\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2606 - accuracy: 0.9569 - val_loss: 0.4213 - val_accuracy: 0.9167\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2657 - accuracy: 0.9556 - val_loss: 0.4112 - val_accuracy: 0.9167\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2496 - accuracy: 0.9704 - val_loss: 0.4388 - val_accuracy: 0.9133\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2606 - accuracy: 0.9579 - val_loss: 0.4369 - val_accuracy: 0.9167\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2512 - accuracy: 0.9713 - val_loss: 0.4152 - val_accuracy: 0.9167\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2550 - accuracy: 0.9657 - val_loss: 0.4093 - val_accuracy: 0.9167\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2533 - accuracy: 0.9644 - val_loss: 0.3943 - val_accuracy: 0.9167\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2563 - accuracy: 0.9616 - val_loss: 0.3942 - val_accuracy: 0.9167\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2621 - accuracy: 0.9588 - val_loss: 0.4071 - val_accuracy: 0.9067\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2558 - accuracy: 0.9620 - val_loss: 0.4125 - val_accuracy: 0.9067\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2596 - accuracy: 0.9662 - val_loss: 0.4343 - val_accuracy: 0.9067\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2587 - accuracy: 0.9588 - val_loss: 0.4256 - val_accuracy: 0.9100\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2577 - accuracy: 0.9588 - val_loss: 0.4286 - val_accuracy: 0.9133\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2537 - accuracy: 0.9662 - val_loss: 0.4324 - val_accuracy: 0.9100\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2588 - accuracy: 0.9616 - val_loss: 0.4160 - val_accuracy: 0.9200\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2635 - accuracy: 0.9583 - val_loss: 0.4311 - val_accuracy: 0.9200\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2521 - accuracy: 0.9620 - val_loss: 0.4443 - val_accuracy: 0.9133\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2619 - accuracy: 0.9565 - val_loss: 0.4458 - val_accuracy: 0.9133\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2610 - accuracy: 0.9546 - val_loss: 0.4054 - val_accuracy: 0.9167\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2490 - accuracy: 0.9676 - val_loss: 0.4185 - val_accuracy: 0.9133\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2524 - accuracy: 0.9681 - val_loss: 0.4258 - val_accuracy: 0.9167\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2511 - accuracy: 0.9653 - val_loss: 0.4404 - val_accuracy: 0.9167\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2443 - accuracy: 0.9662 - val_loss: 0.4516 - val_accuracy: 0.9200\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2508 - accuracy: 0.9611 - val_loss: 0.4511 - val_accuracy: 0.9133\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2450 - accuracy: 0.9648 - val_loss: 0.4363 - val_accuracy: 0.9133\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2512 - accuracy: 0.9583 - val_loss: 0.4288 - val_accuracy: 0.9200\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2452 - accuracy: 0.9667 - val_loss: 0.4510 - val_accuracy: 0.9233\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2517 - accuracy: 0.9634 - val_loss: 0.4513 - val_accuracy: 0.9167\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2512 - accuracy: 0.9583 - val_loss: 0.4192 - val_accuracy: 0.9167\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2409 - accuracy: 0.9681 - val_loss: 0.4566 - val_accuracy: 0.9133\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2452 - accuracy: 0.9671 - val_loss: 0.4147 - val_accuracy: 0.9167\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2431 - accuracy: 0.9648 - val_loss: 0.4452 - val_accuracy: 0.9167\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2365 - accuracy: 0.9639 - val_loss: 0.4521 - val_accuracy: 0.9167\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2424 - accuracy: 0.9657 - val_loss: 0.4424 - val_accuracy: 0.9133\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.93 - 0s 19us/sample - loss: 0.2452 - accuracy: 0.9625 - val_loss: 0.4419 - val_accuracy: 0.9133\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2352 - accuracy: 0.9667 - val_loss: 0.4727 - val_accuracy: 0.9133\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2418 - accuracy: 0.9662 - val_loss: 0.4658 - val_accuracy: 0.9133\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2485 - accuracy: 0.9606 - val_loss: 0.4636 - val_accuracy: 0.9100\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2402 - accuracy: 0.9671 - val_loss: 0.4726 - val_accuracy: 0.9200\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2536 - accuracy: 0.9560 - val_loss: 0.4599 - val_accuracy: 0.9200\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2353 - accuracy: 0.9657 - val_loss: 0.4246 - val_accuracy: 0.9200\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2360 - accuracy: 0.9681 - val_loss: 0.4425 - val_accuracy: 0.9167\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2420 - accuracy: 0.9634 - val_loss: 0.4308 - val_accuracy: 0.9167\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2512 - accuracy: 0.9588 - val_loss: 0.4141 - val_accuracy: 0.9133\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2406 - accuracy: 0.9690 - val_loss: 0.4676 - val_accuracy: 0.9133\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2389 - accuracy: 0.9606 - val_loss: 0.4585 - val_accuracy: 0.9200\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2355 - accuracy: 0.9690 - val_loss: 0.4403 - val_accuracy: 0.9167\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2412 - accuracy: 0.9611 - val_loss: 0.4316 - val_accuracy: 0.9133\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2354 - accuracy: 0.9694 - val_loss: 0.4655 - val_accuracy: 0.9200\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2373 - accuracy: 0.9639 - val_loss: 0.4473 - val_accuracy: 0.9100\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2445 - accuracy: 0.9630 - val_loss: 0.4765 - val_accuracy: 0.9167\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2365 - accuracy: 0.9667 - val_loss: 0.4660 - val_accuracy: 0.9167\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2438 - accuracy: 0.9606 - val_loss: 0.4790 - val_accuracy: 0.9133\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2456 - accuracy: 0.9574 - val_loss: 0.4899 - val_accuracy: 0.9133\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2318 - accuracy: 0.9694 - val_loss: 0.5052 - val_accuracy: 0.9133\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2449 - accuracy: 0.9588 - val_loss: 0.4826 - val_accuracy: 0.9233\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2413 - accuracy: 0.9639 - val_loss: 0.5003 - val_accuracy: 0.9133\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2266 - accuracy: 0.9676 - val_loss: 0.4843 - val_accuracy: 0.9100\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2328 - accuracy: 0.9671 - val_loss: 0.4625 - val_accuracy: 0.9167\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2317 - accuracy: 0.9667 - val_loss: 0.4746 - val_accuracy: 0.9200\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2321 - accuracy: 0.9671 - val_loss: 0.4605 - val_accuracy: 0.9233\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2345 - accuracy: 0.9653 - val_loss: 0.4347 - val_accuracy: 0.9200\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2304 - accuracy: 0.9657 - val_loss: 0.4720 - val_accuracy: 0.9167\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2270 - accuracy: 0.9718 - val_loss: 0.4668 - val_accuracy: 0.9200\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2299 - accuracy: 0.9685 - val_loss: 0.4622 - val_accuracy: 0.9200\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2330 - accuracy: 0.9648 - val_loss: 0.4647 - val_accuracy: 0.9167\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2389 - accuracy: 0.9639 - val_loss: 0.4650 - val_accuracy: 0.9200\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2377 - accuracy: 0.9583 - val_loss: 0.4639 - val_accuracy: 0.9200\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2366 - accuracy: 0.9620 - val_loss: 0.4742 - val_accuracy: 0.9200\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2209 - accuracy: 0.9736 - val_loss: 0.4725 - val_accuracy: 0.9167\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2214 - accuracy: 0.9718 - val_loss: 0.4974 - val_accuracy: 0.9200\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2325 - accuracy: 0.9671 - val_loss: 0.4822 - val_accuracy: 0.9233\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2365 - accuracy: 0.9630 - val_loss: 0.4498 - val_accuracy: 0.9200\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2257 - accuracy: 0.9704 - val_loss: 0.4590 - val_accuracy: 0.9167\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2298 - accuracy: 0.9667 - val_loss: 0.4858 - val_accuracy: 0.9167\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2262 - accuracy: 0.9708 - val_loss: 0.4858 - val_accuracy: 0.9133\n",
      "540/540 [==============================] - 0s 281us/sample - loss: 0.4024 - accuracy: 0.9426\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 376us/sample - loss: 2.6442 - accuracy: 0.5898 - val_loss: 2.0469 - val_accuracy: 0.7800\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.2340 - accuracy: 0.6782 - val_loss: 1.9027 - val_accuracy: 0.8400\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 2.0741 - accuracy: 0.7412 - val_loss: 1.8014 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.8950 - accuracy: 0.7625 - val_loss: 1.7102 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.7512 - accuracy: 0.7875 - val_loss: 1.6251 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.6514 - accuracy: 0.7931 - val_loss: 1.5434 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.5487 - accuracy: 0.7954 - val_loss: 1.4653 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 1.4513 - accuracy: 0.8125 - val_loss: 1.3876 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.3834 - accuracy: 0.8250 - val_loss: 1.3155 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2962 - accuracy: 0.8236 - val_loss: 1.2473 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 1.2201 - accuracy: 0.8343 - val_loss: 1.1839 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1572 - accuracy: 0.8356 - val_loss: 1.1234 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0988 - accuracy: 0.8352 - val_loss: 1.0665 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0531 - accuracy: 0.8398 - val_loss: 1.0157 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0072 - accuracy: 0.8384 - val_loss: 0.9695 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9510 - accuracy: 0.8412 - val_loss: 0.9268 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9061 - accuracy: 0.8412 - val_loss: 0.8858 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8718 - accuracy: 0.8417 - val_loss: 0.8484 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8328 - accuracy: 0.8426 - val_loss: 0.8142 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8018 - accuracy: 0.8431 - val_loss: 0.7824 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7679 - accuracy: 0.8431 - val_loss: 0.7526 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7419 - accuracy: 0.8431 - val_loss: 0.7251 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7140 - accuracy: 0.8431 - val_loss: 0.7015 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6869 - accuracy: 0.8426 - val_loss: 0.6772 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6756 - accuracy: 0.8431 - val_loss: 0.6553 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6457 - accuracy: 0.8426 - val_loss: 0.6356 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6251 - accuracy: 0.8431 - val_loss: 0.6156 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6119 - accuracy: 0.8426 - val_loss: 0.5960 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5879 - accuracy: 0.8431 - val_loss: 0.5780 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5748 - accuracy: 0.8431 - val_loss: 0.5626 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5612 - accuracy: 0.8431 - val_loss: 0.5470 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5466 - accuracy: 0.8431 - val_loss: 0.5333 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5299 - accuracy: 0.8431 - val_loss: 0.5195 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5187 - accuracy: 0.8431 - val_loss: 0.5065 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5041 - accuracy: 0.8431 - val_loss: 0.4943 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4911 - accuracy: 0.8431 - val_loss: 0.4820 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4853 - accuracy: 0.8431 - val_loss: 0.4742 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4686 - accuracy: 0.8431 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4548 - accuracy: 0.8431 - val_loss: 0.4563 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4543 - accuracy: 0.8431 - val_loss: 0.4428 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4335 - accuracy: 0.8431 - val_loss: 0.4340 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4284 - accuracy: 0.8431 - val_loss: 0.4297 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4214 - accuracy: 0.8431 - val_loss: 0.4248 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8431 - val_loss: 0.4191 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3972 - accuracy: 0.8431 - val_loss: 0.4171 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3966 - accuracy: 0.8431 - val_loss: 0.4160 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3922 - accuracy: 0.8431 - val_loss: 0.4133 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3973 - accuracy: 0.8431 - val_loss: 0.4093 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3772 - accuracy: 0.8431 - val_loss: 0.4081 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3749 - accuracy: 0.8431 - val_loss: 0.4069 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3695 - accuracy: 0.8431 - val_loss: 0.4039 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3597 - accuracy: 0.8431 - val_loss: 0.3982 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3636 - accuracy: 0.8426 - val_loss: 0.3983 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3679 - accuracy: 0.8426 - val_loss: 0.3929 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3541 - accuracy: 0.8431 - val_loss: 0.4004 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3513 - accuracy: 0.8431 - val_loss: 0.4008 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3532 - accuracy: 0.8431 - val_loss: 0.3982 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3414 - accuracy: 0.8431 - val_loss: 0.3939 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3418 - accuracy: 0.8431 - val_loss: 0.3981 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3393 - accuracy: 0.8431 - val_loss: 0.3917 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3307 - accuracy: 0.8431 - val_loss: 0.3845 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3361 - accuracy: 0.8431 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3278 - accuracy: 0.8431 - val_loss: 0.3838 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3273 - accuracy: 0.8431 - val_loss: 0.3844 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3301 - accuracy: 0.8431 - val_loss: 0.3818 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3235 - accuracy: 0.8431 - val_loss: 0.3782 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.3189 - accuracy: 0.8431 - val_loss: 0.3831 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3271 - accuracy: 0.8431 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3132 - accuracy: 0.8431 - val_loss: 0.3795 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3136 - accuracy: 0.8616 - val_loss: 0.3882 - val_accuracy: 0.8967\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3225 - accuracy: 0.9208 - val_loss: 0.3887 - val_accuracy: 0.9033\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3175 - accuracy: 0.9292 - val_loss: 0.3781 - val_accuracy: 0.9000\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3162 - accuracy: 0.9375 - val_loss: 0.3772 - val_accuracy: 0.9033\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3155 - accuracy: 0.9315 - val_loss: 0.3857 - val_accuracy: 0.9167\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3047 - accuracy: 0.9435 - val_loss: 0.3751 - val_accuracy: 0.9200\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3066 - accuracy: 0.9403 - val_loss: 0.3664 - val_accuracy: 0.9267\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3074 - accuracy: 0.9468 - val_loss: 0.3749 - val_accuracy: 0.9167\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3066 - accuracy: 0.9417 - val_loss: 0.3759 - val_accuracy: 0.9133\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2998 - accuracy: 0.9505 - val_loss: 0.3698 - val_accuracy: 0.9133\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2997 - accuracy: 0.9486 - val_loss: 0.3812 - val_accuracy: 0.9200\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3045 - accuracy: 0.9509 - val_loss: 0.3737 - val_accuracy: 0.9200\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3022 - accuracy: 0.9495 - val_loss: 0.3792 - val_accuracy: 0.9133\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2987 - accuracy: 0.9528 - val_loss: 0.3829 - val_accuracy: 0.9100\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3108 - accuracy: 0.9444 - val_loss: 0.3755 - val_accuracy: 0.9167\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3011 - accuracy: 0.9551 - val_loss: 0.3719 - val_accuracy: 0.9200\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.3062 - accuracy: 0.9537 - val_loss: 0.3723 - val_accuracy: 0.9233\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2939 - accuracy: 0.9523 - val_loss: 0.3776 - val_accuracy: 0.9200\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2992 - accuracy: 0.9495 - val_loss: 0.3738 - val_accuracy: 0.9233\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2906 - accuracy: 0.9551 - val_loss: 0.3827 - val_accuracy: 0.9300\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2861 - accuracy: 0.9593 - val_loss: 0.3887 - val_accuracy: 0.9233\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2910 - accuracy: 0.9523 - val_loss: 0.3843 - val_accuracy: 0.9233\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2836 - accuracy: 0.9532 - val_loss: 0.3828 - val_accuracy: 0.9267\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2861 - accuracy: 0.9556 - val_loss: 0.3947 - val_accuracy: 0.9333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2827 - accuracy: 0.9583 - val_loss: 0.3973 - val_accuracy: 0.9300\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2931 - accuracy: 0.9606 - val_loss: 0.3851 - val_accuracy: 0.9300\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2780 - accuracy: 0.9597 - val_loss: 0.3785 - val_accuracy: 0.9267\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.2974 - accuracy: 0.9491 - val_loss: 0.3839 - val_accuracy: 0.9367\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2883 - accuracy: 0.9569 - val_loss: 0.3892 - val_accuracy: 0.9267\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2775 - accuracy: 0.9606 - val_loss: 0.3840 - val_accuracy: 0.9267\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.2854 - accuracy: 0.9551 - val_loss: 0.4030 - val_accuracy: 0.9267\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2803 - accuracy: 0.9597 - val_loss: 0.3984 - val_accuracy: 0.9300\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2799 - accuracy: 0.9569 - val_loss: 0.3882 - val_accuracy: 0.9300\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2765 - accuracy: 0.9583 - val_loss: 0.3998 - val_accuracy: 0.9200\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2736 - accuracy: 0.9602 - val_loss: 0.3976 - val_accuracy: 0.9167\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2816 - accuracy: 0.9532 - val_loss: 0.3784 - val_accuracy: 0.9233\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2879 - accuracy: 0.9565 - val_loss: 0.3786 - val_accuracy: 0.9200\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2847 - accuracy: 0.9569 - val_loss: 0.3814 - val_accuracy: 0.9267\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2769 - accuracy: 0.9574 - val_loss: 0.3859 - val_accuracy: 0.9333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2745 - accuracy: 0.9588 - val_loss: 0.3801 - val_accuracy: 0.9300\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2681 - accuracy: 0.9620 - val_loss: 0.3921 - val_accuracy: 0.9233\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2686 - accuracy: 0.9579 - val_loss: 0.3941 - val_accuracy: 0.9300\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2653 - accuracy: 0.9574 - val_loss: 0.3953 - val_accuracy: 0.9233\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2675 - accuracy: 0.9639 - val_loss: 0.3930 - val_accuracy: 0.9333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2667 - accuracy: 0.9639 - val_loss: 0.4023 - val_accuracy: 0.9267\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2713 - accuracy: 0.9565 - val_loss: 0.3795 - val_accuracy: 0.9300\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2687 - accuracy: 0.9616 - val_loss: 0.3896 - val_accuracy: 0.9333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2667 - accuracy: 0.9630 - val_loss: 0.3900 - val_accuracy: 0.9333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2757 - accuracy: 0.9537 - val_loss: 0.3929 - val_accuracy: 0.9233\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2558 - accuracy: 0.9718 - val_loss: 0.4033 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2676 - accuracy: 0.9616 - val_loss: 0.3935 - val_accuracy: 0.9200\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2699 - accuracy: 0.9657 - val_loss: 0.3938 - val_accuracy: 0.9133\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2594 - accuracy: 0.9630 - val_loss: 0.3969 - val_accuracy: 0.9200\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2640 - accuracy: 0.9639 - val_loss: 0.4034 - val_accuracy: 0.9233\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2671 - accuracy: 0.9616 - val_loss: 0.3915 - val_accuracy: 0.9267\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2620 - accuracy: 0.9602 - val_loss: 0.3828 - val_accuracy: 0.9233\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.93 - 0s 18us/sample - loss: 0.2569 - accuracy: 0.9648 - val_loss: 0.3936 - val_accuracy: 0.9233\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2643 - accuracy: 0.9620 - val_loss: 0.3994 - val_accuracy: 0.9267\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2551 - accuracy: 0.9625 - val_loss: 0.3985 - val_accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2617 - accuracy: 0.9593 - val_loss: 0.4012 - val_accuracy: 0.9233\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2558 - accuracy: 0.9667 - val_loss: 0.4031 - val_accuracy: 0.9233\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2587 - accuracy: 0.9639 - val_loss: 0.4133 - val_accuracy: 0.9300\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2549 - accuracy: 0.9616 - val_loss: 0.4041 - val_accuracy: 0.9267\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2508 - accuracy: 0.9653 - val_loss: 0.4146 - val_accuracy: 0.9267\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2490 - accuracy: 0.9681 - val_loss: 0.4182 - val_accuracy: 0.9167\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2526 - accuracy: 0.9630 - val_loss: 0.4200 - val_accuracy: 0.9167\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2605 - accuracy: 0.9644 - val_loss: 0.4175 - val_accuracy: 0.9233\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2605 - accuracy: 0.9569 - val_loss: 0.4143 - val_accuracy: 0.9233\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2596 - accuracy: 0.9662 - val_loss: 0.4192 - val_accuracy: 0.9167\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2551 - accuracy: 0.9625 - val_loss: 0.4110 - val_accuracy: 0.9233\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2565 - accuracy: 0.9653 - val_loss: 0.4115 - val_accuracy: 0.9300\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2571 - accuracy: 0.9606 - val_loss: 0.4017 - val_accuracy: 0.9333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2600 - accuracy: 0.9583 - val_loss: 0.4167 - val_accuracy: 0.9333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2500 - accuracy: 0.9657 - val_loss: 0.4102 - val_accuracy: 0.9267\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2477 - accuracy: 0.9713 - val_loss: 0.3993 - val_accuracy: 0.9267\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2492 - accuracy: 0.9644 - val_loss: 0.4032 - val_accuracy: 0.9267\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2495 - accuracy: 0.9644 - val_loss: 0.4029 - val_accuracy: 0.9400\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2558 - accuracy: 0.9630 - val_loss: 0.4071 - val_accuracy: 0.9333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2520 - accuracy: 0.9602 - val_loss: 0.4097 - val_accuracy: 0.9267\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2510 - accuracy: 0.9671 - val_loss: 0.4078 - val_accuracy: 0.9233\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2495 - accuracy: 0.9625 - val_loss: 0.4065 - val_accuracy: 0.9267\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2440 - accuracy: 0.9718 - val_loss: 0.4123 - val_accuracy: 0.9333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2499 - accuracy: 0.9639 - val_loss: 0.4065 - val_accuracy: 0.9233\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2440 - accuracy: 0.9681 - val_loss: 0.4137 - val_accuracy: 0.9200\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2432 - accuracy: 0.9644 - val_loss: 0.4339 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2565 - accuracy: 0.9583 - val_loss: 0.4196 - val_accuracy: 0.9233\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2482 - accuracy: 0.9630 - val_loss: 0.4129 - val_accuracy: 0.9300\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2482 - accuracy: 0.9653 - val_loss: 0.4169 - val_accuracy: 0.9300\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2429 - accuracy: 0.9616 - val_loss: 0.4159 - val_accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2452 - accuracy: 0.9639 - val_loss: 0.4054 - val_accuracy: 0.9267\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2463 - accuracy: 0.9611 - val_loss: 0.4138 - val_accuracy: 0.9267\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2521 - accuracy: 0.9602 - val_loss: 0.3991 - val_accuracy: 0.9300\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2531 - accuracy: 0.9560 - val_loss: 0.4222 - val_accuracy: 0.9233\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2495 - accuracy: 0.9639 - val_loss: 0.4214 - val_accuracy: 0.9233\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2430 - accuracy: 0.9634 - val_loss: 0.4062 - val_accuracy: 0.9300\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2563 - accuracy: 0.9634 - val_loss: 0.4066 - val_accuracy: 0.9300\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2489 - accuracy: 0.9648 - val_loss: 0.4005 - val_accuracy: 0.9333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2434 - accuracy: 0.9597 - val_loss: 0.4086 - val_accuracy: 0.9333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2519 - accuracy: 0.9648 - val_loss: 0.4302 - val_accuracy: 0.9300\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2393 - accuracy: 0.9694 - val_loss: 0.4238 - val_accuracy: 0.9267\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2450 - accuracy: 0.9597 - val_loss: 0.4306 - val_accuracy: 0.9333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2358 - accuracy: 0.9722 - val_loss: 0.4184 - val_accuracy: 0.9300\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2431 - accuracy: 0.9606 - val_loss: 0.4322 - val_accuracy: 0.9333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2405 - accuracy: 0.9694 - val_loss: 0.4247 - val_accuracy: 0.9333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2447 - accuracy: 0.9616 - val_loss: 0.4434 - val_accuracy: 0.9267\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2453 - accuracy: 0.9625 - val_loss: 0.4268 - val_accuracy: 0.9300\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2441 - accuracy: 0.9616 - val_loss: 0.4146 - val_accuracy: 0.9300\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2434 - accuracy: 0.9620 - val_loss: 0.4071 - val_accuracy: 0.9333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2403 - accuracy: 0.9648 - val_loss: 0.4133 - val_accuracy: 0.9200\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2404 - accuracy: 0.9616 - val_loss: 0.4266 - val_accuracy: 0.9300\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2347 - accuracy: 0.9681 - val_loss: 0.4241 - val_accuracy: 0.9267\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2366 - accuracy: 0.9671 - val_loss: 0.4345 - val_accuracy: 0.9233\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2390 - accuracy: 0.9644 - val_loss: 0.4256 - val_accuracy: 0.9233\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2397 - accuracy: 0.9657 - val_loss: 0.4266 - val_accuracy: 0.9200\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2301 - accuracy: 0.9671 - val_loss: 0.4433 - val_accuracy: 0.9267\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2310 - accuracy: 0.9713 - val_loss: 0.4489 - val_accuracy: 0.9267\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2332 - accuracy: 0.9667 - val_loss: 0.4358 - val_accuracy: 0.9300\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2407 - accuracy: 0.9657 - val_loss: 0.4153 - val_accuracy: 0.9233\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2356 - accuracy: 0.9625 - val_loss: 0.4065 - val_accuracy: 0.9200\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2332 - accuracy: 0.9671 - val_loss: 0.4302 - val_accuracy: 0.9333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2350 - accuracy: 0.9685 - val_loss: 0.4682 - val_accuracy: 0.9233\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2329 - accuracy: 0.9657 - val_loss: 0.4624 - val_accuracy: 0.9233\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2302 - accuracy: 0.9713 - val_loss: 0.4460 - val_accuracy: 0.9267\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2263 - accuracy: 0.9741 - val_loss: 0.4363 - val_accuracy: 0.9233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.2384 - accuracy: 0.9574 - val_loss: 0.4094 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2276 - accuracy: 0.9713 - val_loss: 0.4116 - val_accuracy: 0.9400\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2265 - accuracy: 0.9704 - val_loss: 0.4216 - val_accuracy: 0.9367\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2349 - accuracy: 0.9681 - val_loss: 0.4125 - val_accuracy: 0.9367\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2293 - accuracy: 0.9648 - val_loss: 0.3912 - val_accuracy: 0.9400\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.2437 - accuracy: 0.9565 - val_loss: 0.4201 - val_accuracy: 0.9333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.2266 - accuracy: 0.9681 - val_loss: 0.4401 - val_accuracy: 0.9333\n",
      "540/540 [==============================] - 0s 277us/sample - loss: 0.3155 - accuracy: 0.9519\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 510us/sample - loss: 3.8405 - accuracy: 0.7157 - val_loss: 3.2220 - val_accuracy: 0.8367\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 3.4381 - accuracy: 0.7509 - val_loss: 2.9982 - val_accuracy: 0.8367\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.1113 - accuracy: 0.7750 - val_loss: 2.7981 - val_accuracy: 0.8367\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.8521 - accuracy: 0.8093 - val_loss: 2.6032 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.5891 - accuracy: 0.8199 - val_loss: 2.4139 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.3850 - accuracy: 0.8250 - val_loss: 2.2348 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.1932 - accuracy: 0.8407 - val_loss: 2.0695 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.0130 - accuracy: 0.8481 - val_loss: 1.9073 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8808 - accuracy: 0.8431 - val_loss: 1.7629 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6982 - accuracy: 0.8486 - val_loss: 1.6246 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.5935 - accuracy: 0.8523 - val_loss: 1.5016 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.4606 - accuracy: 0.8537 - val_loss: 1.3908 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.3561 - accuracy: 0.8514 - val_loss: 1.2896 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2517 - accuracy: 0.8523 - val_loss: 1.1991 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.1617 - accuracy: 0.8532 - val_loss: 1.1168 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0860 - accuracy: 0.8537 - val_loss: 1.0434 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0130 - accuracy: 0.8523 - val_loss: 0.9756 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9492 - accuracy: 0.8519 - val_loss: 0.9147 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8925 - accuracy: 0.8523 - val_loss: 0.8601 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8475 - accuracy: 0.8528 - val_loss: 0.8089 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7836 - accuracy: 0.8528 - val_loss: 0.7616 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7519 - accuracy: 0.8523 - val_loss: 0.7199 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7031 - accuracy: 0.8523 - val_loss: 0.6815 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6686 - accuracy: 0.8523 - val_loss: 0.6465 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6414 - accuracy: 0.8523 - val_loss: 0.6150 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6164 - accuracy: 0.8523 - val_loss: 0.5850 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5899 - accuracy: 0.8523 - val_loss: 0.5604 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5537 - accuracy: 0.8523 - val_loss: 0.5368 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5339 - accuracy: 0.8523 - val_loss: 0.5143 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5200 - accuracy: 0.8523 - val_loss: 0.4928 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4934 - accuracy: 0.8528 - val_loss: 0.4782 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4789 - accuracy: 0.8523 - val_loss: 0.4610 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4546 - accuracy: 0.8523 - val_loss: 0.4459 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4383 - accuracy: 0.8528 - val_loss: 0.4341 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4244 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4123 - accuracy: 0.8523 - val_loss: 0.4103 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3991 - accuracy: 0.8523 - val_loss: 0.4033 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3938 - accuracy: 0.8523 - val_loss: 0.3949 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3822 - accuracy: 0.8523 - val_loss: 0.3935 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3802 - accuracy: 0.8528 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3643 - accuracy: 0.8523 - val_loss: 0.3837 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3545 - accuracy: 0.8523 - val_loss: 0.3735 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3514 - accuracy: 0.8523 - val_loss: 0.3813 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3406 - accuracy: 0.8523 - val_loss: 0.3796 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3361 - accuracy: 0.8523 - val_loss: 0.3733 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.3368 - accuracy: 0.8523 - val_loss: 0.3694 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3295 - accuracy: 0.8523 - val_loss: 0.3650 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 16us/sample - loss: 0.3243 - accuracy: 0.8523 - val_loss: 0.3684 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3246 - accuracy: 0.8523 - val_loss: 0.3563 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3129 - accuracy: 0.8898 - val_loss: 0.3549 - val_accuracy: 0.9000\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3142 - accuracy: 0.9032 - val_loss: 0.3520 - val_accuracy: 0.9067\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3134 - accuracy: 0.9306 - val_loss: 0.3556 - val_accuracy: 0.9167\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3125 - accuracy: 0.9231 - val_loss: 0.3502 - val_accuracy: 0.9267\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3095 - accuracy: 0.9333 - val_loss: 0.3517 - val_accuracy: 0.9300\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3074 - accuracy: 0.9310 - val_loss: 0.3549 - val_accuracy: 0.9167\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.3007 - accuracy: 0.9380 - val_loss: 0.3559 - val_accuracy: 0.9067\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2986 - accuracy: 0.9384 - val_loss: 0.3669 - val_accuracy: 0.9167\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3011 - accuracy: 0.9421 - val_loss: 0.3577 - val_accuracy: 0.9033\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2934 - accuracy: 0.9370 - val_loss: 0.3664 - val_accuracy: 0.9033\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2904 - accuracy: 0.9440 - val_loss: 0.3644 - val_accuracy: 0.9000\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2842 - accuracy: 0.9398 - val_loss: 0.3546 - val_accuracy: 0.9033\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2883 - accuracy: 0.9426 - val_loss: 0.3555 - val_accuracy: 0.9200\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2833 - accuracy: 0.9454 - val_loss: 0.3466 - val_accuracy: 0.9167\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2787 - accuracy: 0.9509 - val_loss: 0.3549 - val_accuracy: 0.9167\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2744 - accuracy: 0.9505 - val_loss: 0.3625 - val_accuracy: 0.9133\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.2790 - accuracy: 0.9532 - val_loss: 0.3495 - val_accuracy: 0.9200\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2843 - accuracy: 0.9546 - val_loss: 0.3573 - val_accuracy: 0.9133\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2765 - accuracy: 0.9537 - val_loss: 0.3541 - val_accuracy: 0.9167\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2747 - accuracy: 0.9606 - val_loss: 0.3601 - val_accuracy: 0.9167\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2689 - accuracy: 0.9556 - val_loss: 0.3620 - val_accuracy: 0.9200\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2666 - accuracy: 0.9593 - val_loss: 0.3664 - val_accuracy: 0.9133\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2664 - accuracy: 0.9588 - val_loss: 0.3806 - val_accuracy: 0.9200\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2699 - accuracy: 0.9597 - val_loss: 0.3624 - val_accuracy: 0.9167\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2601 - accuracy: 0.9662 - val_loss: 0.3711 - val_accuracy: 0.9167\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2604 - accuracy: 0.9634 - val_loss: 0.3656 - val_accuracy: 0.9167\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2669 - accuracy: 0.9639 - val_loss: 0.3641 - val_accuracy: 0.9100\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2603 - accuracy: 0.9625 - val_loss: 0.3721 - val_accuracy: 0.9167\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2566 - accuracy: 0.9653 - val_loss: 0.3707 - val_accuracy: 0.9200\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2555 - accuracy: 0.9676 - val_loss: 0.3843 - val_accuracy: 0.9233\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2582 - accuracy: 0.9597 - val_loss: 0.3602 - val_accuracy: 0.9133\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2576 - accuracy: 0.9657 - val_loss: 0.3672 - val_accuracy: 0.9200\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2588 - accuracy: 0.9616 - val_loss: 0.3782 - val_accuracy: 0.9167\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2556 - accuracy: 0.9644 - val_loss: 0.3846 - val_accuracy: 0.9100\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2476 - accuracy: 0.9657 - val_loss: 0.3877 - val_accuracy: 0.9167\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.2508 - accuracy: 0.9648 - val_loss: 0.3529 - val_accuracy: 0.9133\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2491 - accuracy: 0.9644 - val_loss: 0.3744 - val_accuracy: 0.9100\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2524 - accuracy: 0.9606 - val_loss: 0.3902 - val_accuracy: 0.9200\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2461 - accuracy: 0.9662 - val_loss: 0.3895 - val_accuracy: 0.9133\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.2466 - accuracy: 0.9644 - val_loss: 0.3928 - val_accuracy: 0.9200\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2473 - accuracy: 0.9681 - val_loss: 0.3812 - val_accuracy: 0.9233\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2526 - accuracy: 0.9639 - val_loss: 0.3740 - val_accuracy: 0.9167\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2505 - accuracy: 0.9662 - val_loss: 0.3918 - val_accuracy: 0.9133\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2472 - accuracy: 0.9657 - val_loss: 0.3960 - val_accuracy: 0.9167\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2470 - accuracy: 0.9704 - val_loss: 0.3716 - val_accuracy: 0.9133\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2496 - accuracy: 0.9671 - val_loss: 0.3799 - val_accuracy: 0.9133\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2387 - accuracy: 0.9741 - val_loss: 0.3847 - val_accuracy: 0.9100\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2433 - accuracy: 0.9671 - val_loss: 0.3786 - val_accuracy: 0.9167\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2321 - accuracy: 0.9741 - val_loss: 0.3941 - val_accuracy: 0.9100\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2382 - accuracy: 0.9671 - val_loss: 0.3797 - val_accuracy: 0.9100\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2339 - accuracy: 0.9741 - val_loss: 0.3771 - val_accuracy: 0.9167\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2355 - accuracy: 0.9713 - val_loss: 0.3784 - val_accuracy: 0.9233\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2277 - accuracy: 0.9736 - val_loss: 0.3862 - val_accuracy: 0.9233\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2368 - accuracy: 0.9731 - val_loss: 0.3896 - val_accuracy: 0.9200\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2441 - accuracy: 0.9676 - val_loss: 0.3755 - val_accuracy: 0.9267\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2336 - accuracy: 0.9736 - val_loss: 0.3710 - val_accuracy: 0.9267\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2289 - accuracy: 0.9755 - val_loss: 0.3781 - val_accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2252 - accuracy: 0.9755 - val_loss: 0.3821 - val_accuracy: 0.9167\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2242 - accuracy: 0.9778 - val_loss: 0.3688 - val_accuracy: 0.9300\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2260 - accuracy: 0.9759 - val_loss: 0.3874 - val_accuracy: 0.9233\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2213 - accuracy: 0.9764 - val_loss: 0.3677 - val_accuracy: 0.9200\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2239 - accuracy: 0.9759 - val_loss: 0.3840 - val_accuracy: 0.9167\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2225 - accuracy: 0.9731 - val_loss: 0.3649 - val_accuracy: 0.9233\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2214 - accuracy: 0.9764 - val_loss: 0.3761 - val_accuracy: 0.9233\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2174 - accuracy: 0.9810 - val_loss: 0.3652 - val_accuracy: 0.9200\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2278 - accuracy: 0.9722 - val_loss: 0.3824 - val_accuracy: 0.9200\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2292 - accuracy: 0.9722 - val_loss: 0.3996 - val_accuracy: 0.9233\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2275 - accuracy: 0.9787 - val_loss: 0.3710 - val_accuracy: 0.9233\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2269 - accuracy: 0.9727 - val_loss: 0.4057 - val_accuracy: 0.9233\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2245 - accuracy: 0.9764 - val_loss: 0.3817 - val_accuracy: 0.9167\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2326 - accuracy: 0.9722 - val_loss: 0.3748 - val_accuracy: 0.9200\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2271 - accuracy: 0.9755 - val_loss: 0.3899 - val_accuracy: 0.9233\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2226 - accuracy: 0.9801 - val_loss: 0.3768 - val_accuracy: 0.9233\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2299 - accuracy: 0.9750 - val_loss: 0.3796 - val_accuracy: 0.9200\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2264 - accuracy: 0.9745 - val_loss: 0.3675 - val_accuracy: 0.9233\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2242 - accuracy: 0.9741 - val_loss: 0.3941 - val_accuracy: 0.9167\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2209 - accuracy: 0.9769 - val_loss: 0.3664 - val_accuracy: 0.9233\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2279 - accuracy: 0.9713 - val_loss: 0.3568 - val_accuracy: 0.9267\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2245 - accuracy: 0.9778 - val_loss: 0.3854 - val_accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2284 - accuracy: 0.9736 - val_loss: 0.3927 - val_accuracy: 0.9267\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2181 - accuracy: 0.9764 - val_loss: 0.3678 - val_accuracy: 0.9300\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2200 - accuracy: 0.9787 - val_loss: 0.3972 - val_accuracy: 0.9233\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2173 - accuracy: 0.9759 - val_loss: 0.3894 - val_accuracy: 0.9267\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2197 - accuracy: 0.9764 - val_loss: 0.3628 - val_accuracy: 0.9300\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2137 - accuracy: 0.9769 - val_loss: 0.3826 - val_accuracy: 0.9267\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2112 - accuracy: 0.9796 - val_loss: 0.3885 - val_accuracy: 0.9233\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2055 - accuracy: 0.9806 - val_loss: 0.3945 - val_accuracy: 0.9200\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2181 - accuracy: 0.9750 - val_loss: 0.4039 - val_accuracy: 0.9167\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2187 - accuracy: 0.9764 - val_loss: 0.3897 - val_accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2172 - accuracy: 0.9759 - val_loss: 0.4292 - val_accuracy: 0.9267\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2117 - accuracy: 0.9769 - val_loss: 0.4074 - val_accuracy: 0.9267\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2157 - accuracy: 0.9769 - val_loss: 0.3781 - val_accuracy: 0.9267\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2229 - accuracy: 0.9713 - val_loss: 0.3696 - val_accuracy: 0.9367\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2240 - accuracy: 0.9713 - val_loss: 0.3669 - val_accuracy: 0.9333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2065 - accuracy: 0.9806 - val_loss: 0.3900 - val_accuracy: 0.9333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2117 - accuracy: 0.9806 - val_loss: 0.3924 - val_accuracy: 0.9233\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2067 - accuracy: 0.9801 - val_loss: 0.3857 - val_accuracy: 0.9267\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2076 - accuracy: 0.9773 - val_loss: 0.3864 - val_accuracy: 0.9233\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2146 - accuracy: 0.9722 - val_loss: 0.3796 - val_accuracy: 0.9233\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2093 - accuracy: 0.9769 - val_loss: 0.3698 - val_accuracy: 0.9233\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2138 - accuracy: 0.9741 - val_loss: 0.3932 - val_accuracy: 0.9233\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2073 - accuracy: 0.9773 - val_loss: 0.4047 - val_accuracy: 0.9267\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2093 - accuracy: 0.9778 - val_loss: 0.3919 - val_accuracy: 0.9167\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2095 - accuracy: 0.9778 - val_loss: 0.3726 - val_accuracy: 0.9233\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2180 - accuracy: 0.9745 - val_loss: 0.4155 - val_accuracy: 0.9167\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2119 - accuracy: 0.9796 - val_loss: 0.4279 - val_accuracy: 0.9200\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2154 - accuracy: 0.9718 - val_loss: 0.4239 - val_accuracy: 0.9200\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2048 - accuracy: 0.9815 - val_loss: 0.3955 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2051 - accuracy: 0.9782 - val_loss: 0.4152 - val_accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2056 - accuracy: 0.9787 - val_loss: 0.4021 - val_accuracy: 0.9267\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2076 - accuracy: 0.9787 - val_loss: 0.4111 - val_accuracy: 0.9233\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2053 - accuracy: 0.9750 - val_loss: 0.4172 - val_accuracy: 0.9200\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1963 - accuracy: 0.9819 - val_loss: 0.4007 - val_accuracy: 0.9200\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1988 - accuracy: 0.9792 - val_loss: 0.3877 - val_accuracy: 0.9267\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1951 - accuracy: 0.9824 - val_loss: 0.4070 - val_accuracy: 0.9267\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1924 - accuracy: 0.9810 - val_loss: 0.4145 - val_accuracy: 0.9267\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2036 - accuracy: 0.9741 - val_loss: 0.3897 - val_accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2012 - accuracy: 0.9792 - val_loss: 0.4091 - val_accuracy: 0.9233\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1988 - accuracy: 0.9810 - val_loss: 0.4171 - val_accuracy: 0.9233\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1998 - accuracy: 0.9810 - val_loss: 0.4185 - val_accuracy: 0.9300\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1982 - accuracy: 0.9819 - val_loss: 0.4144 - val_accuracy: 0.9300\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1969 - accuracy: 0.9819 - val_loss: 0.4264 - val_accuracy: 0.9233\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2029 - accuracy: 0.9806 - val_loss: 0.3625 - val_accuracy: 0.9333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2058 - accuracy: 0.9759 - val_loss: 0.4004 - val_accuracy: 0.9267\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2035 - accuracy: 0.9745 - val_loss: 0.3868 - val_accuracy: 0.9233\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2028 - accuracy: 0.9745 - val_loss: 0.3922 - val_accuracy: 0.9267\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1988 - accuracy: 0.9782 - val_loss: 0.4017 - val_accuracy: 0.9333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1968 - accuracy: 0.9796 - val_loss: 0.3803 - val_accuracy: 0.9267\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1975 - accuracy: 0.9815 - val_loss: 0.4210 - val_accuracy: 0.9200\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2057 - accuracy: 0.9713 - val_loss: 0.3917 - val_accuracy: 0.9200\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2056 - accuracy: 0.9750 - val_loss: 0.3823 - val_accuracy: 0.9233\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1997 - accuracy: 0.9782 - val_loss: 0.4002 - val_accuracy: 0.9233\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2000 - accuracy: 0.9773 - val_loss: 0.4449 - val_accuracy: 0.9167\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2014 - accuracy: 0.9769 - val_loss: 0.4466 - val_accuracy: 0.9267\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1971 - accuracy: 0.9792 - val_loss: 0.4218 - val_accuracy: 0.9267\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1977 - accuracy: 0.9796 - val_loss: 0.4591 - val_accuracy: 0.9200\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1942 - accuracy: 0.9801 - val_loss: 0.4186 - val_accuracy: 0.9300\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1989 - accuracy: 0.9773 - val_loss: 0.4122 - val_accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1939 - accuracy: 0.9792 - val_loss: 0.3923 - val_accuracy: 0.9267\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1939 - accuracy: 0.9764 - val_loss: 0.3971 - val_accuracy: 0.9267\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1811 - accuracy: 0.9852 - val_loss: 0.4240 - val_accuracy: 0.9267\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1893 - accuracy: 0.9796 - val_loss: 0.4331 - val_accuracy: 0.9233\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1915 - accuracy: 0.9801 - val_loss: 0.4090 - val_accuracy: 0.9233\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1850 - accuracy: 0.9838 - val_loss: 0.4487 - val_accuracy: 0.9267\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1873 - accuracy: 0.9838 - val_loss: 0.4269 - val_accuracy: 0.9233\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1884 - accuracy: 0.9829 - val_loss: 0.4301 - val_accuracy: 0.9233\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1948 - accuracy: 0.9792 - val_loss: 0.4274 - val_accuracy: 0.9267\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1937 - accuracy: 0.9806 - val_loss: 0.4394 - val_accuracy: 0.9300\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1901 - accuracy: 0.9833 - val_loss: 0.4160 - val_accuracy: 0.9267\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1935 - accuracy: 0.9782 - val_loss: 0.4471 - val_accuracy: 0.9300\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1967 - accuracy: 0.9773 - val_loss: 0.4180 - val_accuracy: 0.9267\n",
      "540/540 [==============================] - 0s 285us/sample - loss: 0.3758 - accuracy: 0.9481\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 379us/sample - loss: 4.5028 - accuracy: 0.4731 - val_loss: 3.3416 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.6072 - accuracy: 0.6699 - val_loss: 3.1325 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.2992 - accuracy: 0.7519 - val_loss: 2.9462 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.9986 - accuracy: 0.7801 - val_loss: 2.7723 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.8279 - accuracy: 0.7843 - val_loss: 2.6064 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.6180 - accuracy: 0.7963 - val_loss: 2.4479 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.4339 - accuracy: 0.8102 - val_loss: 2.2946 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.2258 - accuracy: 0.8241 - val_loss: 2.1455 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.0811 - accuracy: 0.8366 - val_loss: 2.0018 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 2.0110 - accuracy: 0.82 - 0s 24us/sample - loss: 1.9415 - accuracy: 0.8384 - val_loss: 1.8670 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8214 - accuracy: 0.8444 - val_loss: 1.7450 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6849 - accuracy: 0.8449 - val_loss: 1.6333 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.5746 - accuracy: 0.8481 - val_loss: 1.5254 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.4766 - accuracy: 0.8472 - val_loss: 1.4273 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3855 - accuracy: 0.8495 - val_loss: 1.3389 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2880 - accuracy: 0.8481 - val_loss: 1.2596 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.2185 - accuracy: 0.8509 - val_loss: 1.1846 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.1458 - accuracy: 0.8500 - val_loss: 1.1155 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.0821 - accuracy: 0.8505 - val_loss: 1.0525 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0209 - accuracy: 0.8505 - val_loss: 0.9943 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9646 - accuracy: 0.8500 - val_loss: 0.9411 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9198 - accuracy: 0.8505 - val_loss: 0.8909 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8726 - accuracy: 0.8495 - val_loss: 0.8442 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8241 - accuracy: 0.8505 - val_loss: 0.8021 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7830 - accuracy: 0.8505 - val_loss: 0.7623 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7490 - accuracy: 0.8505 - val_loss: 0.7243 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7063 - accuracy: 0.8505 - val_loss: 0.6888 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6715 - accuracy: 0.8505 - val_loss: 0.6549 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6489 - accuracy: 0.8505 - val_loss: 0.6232 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.6282 - accuracy: 0.8505 - val_loss: 0.5947 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5925 - accuracy: 0.8505 - val_loss: 0.5688 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5742 - accuracy: 0.8505 - val_loss: 0.5430 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5430 - accuracy: 0.8505 - val_loss: 0.5217 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.5176 - accuracy: 0.8505 - val_loss: 0.5029 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5072 - accuracy: 0.8505 - val_loss: 0.4873 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4925 - accuracy: 0.8505 - val_loss: 0.4729 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4716 - accuracy: 0.8505 - val_loss: 0.4602 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4510 - accuracy: 0.8505 - val_loss: 0.4486 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4379 - accuracy: 0.8505 - val_loss: 0.4436 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4344 - accuracy: 0.8505 - val_loss: 0.4362 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4190 - accuracy: 0.8505 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4109 - accuracy: 0.8505 - val_loss: 0.4202 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3968 - accuracy: 0.8505 - val_loss: 0.4111 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3868 - accuracy: 0.8505 - val_loss: 0.4058 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3762 - accuracy: 0.8505 - val_loss: 0.4010 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3705 - accuracy: 0.8505 - val_loss: 0.3995 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3664 - accuracy: 0.8505 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3523 - accuracy: 0.8505 - val_loss: 0.3919 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3530 - accuracy: 0.8505 - val_loss: 0.3852 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3482 - accuracy: 0.8505 - val_loss: 0.3842 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3400 - accuracy: 0.8505 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3420 - accuracy: 0.8505 - val_loss: 0.3793 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3278 - accuracy: 0.8505 - val_loss: 0.3738 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3237 - accuracy: 0.8505 - val_loss: 0.3821 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3277 - accuracy: 0.9259 - val_loss: 0.3651 - val_accuracy: 0.9033\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3243 - accuracy: 0.9278 - val_loss: 0.3678 - val_accuracy: 0.9033\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3138 - accuracy: 0.9347 - val_loss: 0.3599 - val_accuracy: 0.9100\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3132 - accuracy: 0.9403 - val_loss: 0.3575 - val_accuracy: 0.9267\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3097 - accuracy: 0.9398 - val_loss: 0.3574 - val_accuracy: 0.9200\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3019 - accuracy: 0.9505 - val_loss: 0.3568 - val_accuracy: 0.9067\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2986 - accuracy: 0.9495 - val_loss: 0.3581 - val_accuracy: 0.9067\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3015 - accuracy: 0.9486 - val_loss: 0.3529 - val_accuracy: 0.9167\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2954 - accuracy: 0.9519 - val_loss: 0.3549 - val_accuracy: 0.9133\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2936 - accuracy: 0.9528 - val_loss: 0.3495 - val_accuracy: 0.9167\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2916 - accuracy: 0.9537 - val_loss: 0.3575 - val_accuracy: 0.9200\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2890 - accuracy: 0.9528 - val_loss: 0.3426 - val_accuracy: 0.9233\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2920 - accuracy: 0.9569 - val_loss: 0.3615 - val_accuracy: 0.9100\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2821 - accuracy: 0.9583 - val_loss: 0.3557 - val_accuracy: 0.9100\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2857 - accuracy: 0.9574 - val_loss: 0.3597 - val_accuracy: 0.9100\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2801 - accuracy: 0.9583 - val_loss: 0.3627 - val_accuracy: 0.9167\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2913 - accuracy: 0.9565 - val_loss: 0.3492 - val_accuracy: 0.9233\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2828 - accuracy: 0.9537 - val_loss: 0.3596 - val_accuracy: 0.9233\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2840 - accuracy: 0.9597 - val_loss: 0.3524 - val_accuracy: 0.9233\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2771 - accuracy: 0.9644 - val_loss: 0.3612 - val_accuracy: 0.9200\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2756 - accuracy: 0.9597 - val_loss: 0.3439 - val_accuracy: 0.9300\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2713 - accuracy: 0.9699 - val_loss: 0.3532 - val_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2683 - accuracy: 0.9648 - val_loss: 0.3551 - val_accuracy: 0.9200\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2683 - accuracy: 0.9639 - val_loss: 0.3357 - val_accuracy: 0.9300\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2682 - accuracy: 0.9657 - val_loss: 0.3418 - val_accuracy: 0.9300\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2647 - accuracy: 0.9676 - val_loss: 0.3476 - val_accuracy: 0.9300\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2747 - accuracy: 0.9625 - val_loss: 0.3592 - val_accuracy: 0.9300\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2670 - accuracy: 0.9690 - val_loss: 0.3434 - val_accuracy: 0.9233\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2706 - accuracy: 0.9681 - val_loss: 0.3440 - val_accuracy: 0.9267\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2708 - accuracy: 0.9667 - val_loss: 0.3358 - val_accuracy: 0.9333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2633 - accuracy: 0.9681 - val_loss: 0.3485 - val_accuracy: 0.9367\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2600 - accuracy: 0.9694 - val_loss: 0.3418 - val_accuracy: 0.9367\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2637 - accuracy: 0.9690 - val_loss: 0.3462 - val_accuracy: 0.9433\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2588 - accuracy: 0.9731 - val_loss: 0.3444 - val_accuracy: 0.9400\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2527 - accuracy: 0.9759 - val_loss: 0.3588 - val_accuracy: 0.9400\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2523 - accuracy: 0.9782 - val_loss: 0.3614 - val_accuracy: 0.9400\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2552 - accuracy: 0.9750 - val_loss: 0.3599 - val_accuracy: 0.9400\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2498 - accuracy: 0.9727 - val_loss: 0.3474 - val_accuracy: 0.9367\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2476 - accuracy: 0.9759 - val_loss: 0.3503 - val_accuracy: 0.9367\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2438 - accuracy: 0.9713 - val_loss: 0.3329 - val_accuracy: 0.9333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2458 - accuracy: 0.9736 - val_loss: 0.3388 - val_accuracy: 0.9367\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2454 - accuracy: 0.9704 - val_loss: 0.3399 - val_accuracy: 0.9300\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2444 - accuracy: 0.9759 - val_loss: 0.3479 - val_accuracy: 0.9300\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2499 - accuracy: 0.9718 - val_loss: 0.3632 - val_accuracy: 0.9300\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2522 - accuracy: 0.9657 - val_loss: 0.3333 - val_accuracy: 0.9467\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2528 - accuracy: 0.9708 - val_loss: 0.3615 - val_accuracy: 0.9400\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2432 - accuracy: 0.9778 - val_loss: 0.3543 - val_accuracy: 0.9400\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2413 - accuracy: 0.9750 - val_loss: 0.3612 - val_accuracy: 0.9400\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2391 - accuracy: 0.9787 - val_loss: 0.3590 - val_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2472 - accuracy: 0.9722 - val_loss: 0.3671 - val_accuracy: 0.9267\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2355 - accuracy: 0.9810 - val_loss: 0.3612 - val_accuracy: 0.9267\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2329 - accuracy: 0.9782 - val_loss: 0.3660 - val_accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2305 - accuracy: 0.9787 - val_loss: 0.3591 - val_accuracy: 0.9267\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2385 - accuracy: 0.9773 - val_loss: 0.3646 - val_accuracy: 0.9333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2366 - accuracy: 0.9745 - val_loss: 0.3604 - val_accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2381 - accuracy: 0.9796 - val_loss: 0.3488 - val_accuracy: 0.9367\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2342 - accuracy: 0.9750 - val_loss: 0.3530 - val_accuracy: 0.9400\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2359 - accuracy: 0.9769 - val_loss: 0.3566 - val_accuracy: 0.9300\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2340 - accuracy: 0.9782 - val_loss: 0.3443 - val_accuracy: 0.9333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2373 - accuracy: 0.9769 - val_loss: 0.3601 - val_accuracy: 0.9400\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2473 - accuracy: 0.9727 - val_loss: 0.3248 - val_accuracy: 0.9400\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2378 - accuracy: 0.9718 - val_loss: 0.3539 - val_accuracy: 0.9333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2395 - accuracy: 0.9787 - val_loss: 0.3594 - val_accuracy: 0.9367\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2310 - accuracy: 0.9810 - val_loss: 0.3511 - val_accuracy: 0.9267\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2250 - accuracy: 0.9829 - val_loss: 0.3637 - val_accuracy: 0.9400\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2236 - accuracy: 0.9792 - val_loss: 0.3673 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2274 - accuracy: 0.9736 - val_loss: 0.3339 - val_accuracy: 0.9333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2213 - accuracy: 0.9792 - val_loss: 0.3507 - val_accuracy: 0.9367\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2250 - accuracy: 0.9787 - val_loss: 0.3748 - val_accuracy: 0.9333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2229 - accuracy: 0.9819 - val_loss: 0.3672 - val_accuracy: 0.9300\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2173 - accuracy: 0.9815 - val_loss: 0.3461 - val_accuracy: 0.9333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2279 - accuracy: 0.9759 - val_loss: 0.3637 - val_accuracy: 0.9367\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2264 - accuracy: 0.9778 - val_loss: 0.3516 - val_accuracy: 0.9333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2251 - accuracy: 0.9806 - val_loss: 0.3678 - val_accuracy: 0.9300\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2311 - accuracy: 0.9764 - val_loss: 0.3453 - val_accuracy: 0.9433\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2324 - accuracy: 0.9718 - val_loss: 0.3568 - val_accuracy: 0.9433\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2298 - accuracy: 0.9764 - val_loss: 0.3671 - val_accuracy: 0.9367\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2191 - accuracy: 0.9806 - val_loss: 0.3726 - val_accuracy: 0.9433\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2199 - accuracy: 0.9806 - val_loss: 0.3648 - val_accuracy: 0.9467\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2287 - accuracy: 0.9764 - val_loss: 0.3435 - val_accuracy: 0.9400\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2254 - accuracy: 0.9764 - val_loss: 0.3761 - val_accuracy: 0.9367\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2287 - accuracy: 0.9769 - val_loss: 0.3722 - val_accuracy: 0.9400\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2206 - accuracy: 0.9792 - val_loss: 0.3628 - val_accuracy: 0.9433\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2258 - accuracy: 0.9787 - val_loss: 0.3509 - val_accuracy: 0.9467\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2234 - accuracy: 0.9755 - val_loss: 0.3553 - val_accuracy: 0.9433\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2144 - accuracy: 0.9815 - val_loss: 0.3556 - val_accuracy: 0.9367\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2156 - accuracy: 0.9806 - val_loss: 0.3680 - val_accuracy: 0.9400\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2172 - accuracy: 0.9759 - val_loss: 0.3512 - val_accuracy: 0.9400\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2211 - accuracy: 0.9759 - val_loss: 0.3652 - val_accuracy: 0.9400\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2192 - accuracy: 0.9778 - val_loss: 0.3860 - val_accuracy: 0.9367\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2183 - accuracy: 0.9787 - val_loss: 0.3956 - val_accuracy: 0.9300\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2092 - accuracy: 0.9806 - val_loss: 0.3864 - val_accuracy: 0.9367\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2132 - accuracy: 0.9796 - val_loss: 0.3734 - val_accuracy: 0.9367\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2128 - accuracy: 0.9815 - val_loss: 0.3723 - val_accuracy: 0.9400\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2101 - accuracy: 0.9806 - val_loss: 0.3559 - val_accuracy: 0.9333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2131 - accuracy: 0.9764 - val_loss: 0.3436 - val_accuracy: 0.9400\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2103 - accuracy: 0.9796 - val_loss: 0.3552 - val_accuracy: 0.9433\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2159 - accuracy: 0.9731 - val_loss: 0.3476 - val_accuracy: 0.9467\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2131 - accuracy: 0.9801 - val_loss: 0.3476 - val_accuracy: 0.9467\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2063 - accuracy: 0.9843 - val_loss: 0.3724 - val_accuracy: 0.9400\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2098 - accuracy: 0.9810 - val_loss: 0.3406 - val_accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2083 - accuracy: 0.9852 - val_loss: 0.3508 - val_accuracy: 0.9333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2125 - accuracy: 0.9819 - val_loss: 0.3657 - val_accuracy: 0.9400\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2128 - accuracy: 0.9806 - val_loss: 0.3549 - val_accuracy: 0.9400\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2096 - accuracy: 0.9838 - val_loss: 0.3453 - val_accuracy: 0.9333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2103 - accuracy: 0.9833 - val_loss: 0.3333 - val_accuracy: 0.9400\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2154 - accuracy: 0.9759 - val_loss: 0.3619 - val_accuracy: 0.9400\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2086 - accuracy: 0.9801 - val_loss: 0.3350 - val_accuracy: 0.9467\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2128 - accuracy: 0.9782 - val_loss: 0.3310 - val_accuracy: 0.9433\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2064 - accuracy: 0.9810 - val_loss: 0.3453 - val_accuracy: 0.9433\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2102 - accuracy: 0.9782 - val_loss: 0.3551 - val_accuracy: 0.9500\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2090 - accuracy: 0.9759 - val_loss: 0.3703 - val_accuracy: 0.9467\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2016 - accuracy: 0.9806 - val_loss: 0.3708 - val_accuracy: 0.9433\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2045 - accuracy: 0.9801 - val_loss: 0.3542 - val_accuracy: 0.9400\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2023 - accuracy: 0.9801 - val_loss: 0.3544 - val_accuracy: 0.9400\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2024 - accuracy: 0.9829 - val_loss: 0.3365 - val_accuracy: 0.9467\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2045 - accuracy: 0.9806 - val_loss: 0.3299 - val_accuracy: 0.9433\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2100 - accuracy: 0.9782 - val_loss: 0.3562 - val_accuracy: 0.9400\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2042 - accuracy: 0.9819 - val_loss: 0.3370 - val_accuracy: 0.9400\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1981 - accuracy: 0.9829 - val_loss: 0.3432 - val_accuracy: 0.9367\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2115 - accuracy: 0.9764 - val_loss: 0.3571 - val_accuracy: 0.9367\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2087 - accuracy: 0.9764 - val_loss: 0.3515 - val_accuracy: 0.9400\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2058 - accuracy: 0.9806 - val_loss: 0.3353 - val_accuracy: 0.9367\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2053 - accuracy: 0.9806 - val_loss: 0.3358 - val_accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2045 - accuracy: 0.9796 - val_loss: 0.3540 - val_accuracy: 0.9400\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2029 - accuracy: 0.9824 - val_loss: 0.3522 - val_accuracy: 0.9367\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1982 - accuracy: 0.9801 - val_loss: 0.3555 - val_accuracy: 0.9333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1982 - accuracy: 0.9796 - val_loss: 0.3648 - val_accuracy: 0.9333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2014 - accuracy: 0.9782 - val_loss: 0.3679 - val_accuracy: 0.9300\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1998 - accuracy: 0.9796 - val_loss: 0.3899 - val_accuracy: 0.9367\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2007 - accuracy: 0.9801 - val_loss: 0.3570 - val_accuracy: 0.9367\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2018 - accuracy: 0.9792 - val_loss: 0.3375 - val_accuracy: 0.9433\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2020 - accuracy: 0.9750 - val_loss: 0.3527 - val_accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1899 - accuracy: 0.9870 - val_loss: 0.3605 - val_accuracy: 0.9367\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2021 - accuracy: 0.9787 - val_loss: 0.3747 - val_accuracy: 0.9333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2059 - accuracy: 0.9773 - val_loss: 0.3711 - val_accuracy: 0.9367\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2057 - accuracy: 0.9778 - val_loss: 0.3728 - val_accuracy: 0.9400\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1996 - accuracy: 0.9819 - val_loss: 0.3983 - val_accuracy: 0.9300\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2047 - accuracy: 0.9806 - val_loss: 0.3726 - val_accuracy: 0.9433\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1936 - accuracy: 0.9819 - val_loss: 0.3640 - val_accuracy: 0.9400\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2017 - accuracy: 0.9745 - val_loss: 0.3636 - val_accuracy: 0.9500\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1948 - accuracy: 0.9829 - val_loss: 0.3748 - val_accuracy: 0.9433\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1946 - accuracy: 0.9819 - val_loss: 0.3849 - val_accuracy: 0.9433\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1896 - accuracy: 0.9856 - val_loss: 0.3569 - val_accuracy: 0.9400\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1948 - accuracy: 0.9801 - val_loss: 0.3333 - val_accuracy: 0.9367\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1965 - accuracy: 0.9801 - val_loss: 0.3426 - val_accuracy: 0.9433\n",
      "540/540 [==============================] - 0s 287us/sample - loss: 0.3177 - accuracy: 0.9611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 383us/sample - loss: 4.6055 - accuracy: 0.4255 - val_loss: 3.4829 - val_accuracy: 0.7233\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 3.6163 - accuracy: 0.6463 - val_loss: 3.1843 - val_accuracy: 0.8367\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 3.2769 - accuracy: 0.7315 - val_loss: 2.9713 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.0242 - accuracy: 0.7681 - val_loss: 2.7800 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.8293 - accuracy: 0.7852 - val_loss: 2.5989 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.5832 - accuracy: 0.8056 - val_loss: 2.4286 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.3999 - accuracy: 0.8144 - val_loss: 2.2635 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.2360 - accuracy: 0.8231 - val_loss: 2.1077 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.0701 - accuracy: 0.8329 - val_loss: 1.9606 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.9193 - accuracy: 0.8421 - val_loss: 1.8245 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.7848 - accuracy: 0.8481 - val_loss: 1.6986 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.6502 - accuracy: 0.8523 - val_loss: 1.5833 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.5422 - accuracy: 0.8537 - val_loss: 1.4766 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4369 - accuracy: 0.8556 - val_loss: 1.3795 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3569 - accuracy: 0.8542 - val_loss: 1.2925 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2523 - accuracy: 0.8574 - val_loss: 1.2137 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1717 - accuracy: 0.8565 - val_loss: 1.1395 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0970 - accuracy: 0.8583 - val_loss: 1.0705 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0299 - accuracy: 0.8579 - val_loss: 1.0080 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9765 - accuracy: 0.8583 - val_loss: 0.9509 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.9218 - accuracy: 0.8579 - val_loss: 0.9001 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8639 - accuracy: 0.8583 - val_loss: 0.8510 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8223 - accuracy: 0.8583 - val_loss: 0.8056 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.7865 - accuracy: 0.8583 - val_loss: 0.7636 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7459 - accuracy: 0.8583 - val_loss: 0.7243 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7124 - accuracy: 0.8583 - val_loss: 0.6897 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6753 - accuracy: 0.8583 - val_loss: 0.6560 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6408 - accuracy: 0.8583 - val_loss: 0.6263 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6128 - accuracy: 0.8583 - val_loss: 0.5966 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5841 - accuracy: 0.8583 - val_loss: 0.5736 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5696 - accuracy: 0.8583 - val_loss: 0.5498 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5459 - accuracy: 0.8583 - val_loss: 0.5266 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5228 - accuracy: 0.8583 - val_loss: 0.5103 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4909 - accuracy: 0.8583 - val_loss: 0.4975 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4780 - accuracy: 0.8583 - val_loss: 0.4799 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4636 - accuracy: 0.8583 - val_loss: 0.4676 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4488 - accuracy: 0.8583 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4399 - accuracy: 0.8583 - val_loss: 0.4431 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4152 - accuracy: 0.8583 - val_loss: 0.4397 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4141 - accuracy: 0.8583 - val_loss: 0.4238 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3943 - accuracy: 0.8583 - val_loss: 0.4194 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3849 - accuracy: 0.8583 - val_loss: 0.4210 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3761 - accuracy: 0.8583 - val_loss: 0.4203 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3707 - accuracy: 0.8583 - val_loss: 0.4084 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3628 - accuracy: 0.8583 - val_loss: 0.4053 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3588 - accuracy: 0.8583 - val_loss: 0.3952 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3486 - accuracy: 0.8583 - val_loss: 0.4014 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3435 - accuracy: 0.8583 - val_loss: 0.3896 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3397 - accuracy: 0.8583 - val_loss: 0.3954 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3372 - accuracy: 0.8583 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3229 - accuracy: 0.8583 - val_loss: 0.3787 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3244 - accuracy: 0.8583 - val_loss: 0.3850 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3168 - accuracy: 0.8583 - val_loss: 0.3799 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3165 - accuracy: 0.8583 - val_loss: 0.3866 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3104 - accuracy: 0.8792 - val_loss: 0.3900 - val_accuracy: 0.9000\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3119 - accuracy: 0.9412 - val_loss: 0.3734 - val_accuracy: 0.9033\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3058 - accuracy: 0.9491 - val_loss: 0.3841 - val_accuracy: 0.9033\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3046 - accuracy: 0.9394 - val_loss: 0.3772 - val_accuracy: 0.8900\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2963 - accuracy: 0.9509 - val_loss: 0.3886 - val_accuracy: 0.8933\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2953 - accuracy: 0.9477 - val_loss: 0.3759 - val_accuracy: 0.8933\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2972 - accuracy: 0.9481 - val_loss: 0.3665 - val_accuracy: 0.9100\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2910 - accuracy: 0.9546 - val_loss: 0.3712 - val_accuracy: 0.9067\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2914 - accuracy: 0.9565 - val_loss: 0.3609 - val_accuracy: 0.9233\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2879 - accuracy: 0.9537 - val_loss: 0.3725 - val_accuracy: 0.9100\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2825 - accuracy: 0.9620 - val_loss: 0.3715 - val_accuracy: 0.9167\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2809 - accuracy: 0.9560 - val_loss: 0.3609 - val_accuracy: 0.9133\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2810 - accuracy: 0.9620 - val_loss: 0.3731 - val_accuracy: 0.9133\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2771 - accuracy: 0.9625 - val_loss: 0.3599 - val_accuracy: 0.9200\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2743 - accuracy: 0.9588 - val_loss: 0.3736 - val_accuracy: 0.9100\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2790 - accuracy: 0.9625 - val_loss: 0.3610 - val_accuracy: 0.9167\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2787 - accuracy: 0.9681 - val_loss: 0.3731 - val_accuracy: 0.9000\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2766 - accuracy: 0.9616 - val_loss: 0.3714 - val_accuracy: 0.9200\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2670 - accuracy: 0.9657 - val_loss: 0.3748 - val_accuracy: 0.9167\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2682 - accuracy: 0.9648 - val_loss: 0.3590 - val_accuracy: 0.9167\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2675 - accuracy: 0.9681 - val_loss: 0.3666 - val_accuracy: 0.9100\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2606 - accuracy: 0.9667 - val_loss: 0.3631 - val_accuracy: 0.9200\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2561 - accuracy: 0.9694 - val_loss: 0.3667 - val_accuracy: 0.9133\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2570 - accuracy: 0.9745 - val_loss: 0.3503 - val_accuracy: 0.9100\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2556 - accuracy: 0.9708 - val_loss: 0.3584 - val_accuracy: 0.9133\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2554 - accuracy: 0.9731 - val_loss: 0.3657 - val_accuracy: 0.9100\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2511 - accuracy: 0.9699 - val_loss: 0.3543 - val_accuracy: 0.9100\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2552 - accuracy: 0.9736 - val_loss: 0.3520 - val_accuracy: 0.9233\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2531 - accuracy: 0.9718 - val_loss: 0.3479 - val_accuracy: 0.9233\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2574 - accuracy: 0.9731 - val_loss: 0.3504 - val_accuracy: 0.9167\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2467 - accuracy: 0.9722 - val_loss: 0.3475 - val_accuracy: 0.9167\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2499 - accuracy: 0.9694 - val_loss: 0.3522 - val_accuracy: 0.9100\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2520 - accuracy: 0.9704 - val_loss: 0.3371 - val_accuracy: 0.9300\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2524 - accuracy: 0.9708 - val_loss: 0.3392 - val_accuracy: 0.9267\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2482 - accuracy: 0.9764 - val_loss: 0.3554 - val_accuracy: 0.9133\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2440 - accuracy: 0.9731 - val_loss: 0.3456 - val_accuracy: 0.9267\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2447 - accuracy: 0.9750 - val_loss: 0.3635 - val_accuracy: 0.9233\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2444 - accuracy: 0.9745 - val_loss: 0.3789 - val_accuracy: 0.9133\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2421 - accuracy: 0.9773 - val_loss: 0.3577 - val_accuracy: 0.9133\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2362 - accuracy: 0.9736 - val_loss: 0.3415 - val_accuracy: 0.9233\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2431 - accuracy: 0.9750 - val_loss: 0.3467 - val_accuracy: 0.9200\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2420 - accuracy: 0.9745 - val_loss: 0.3495 - val_accuracy: 0.9133\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2348 - accuracy: 0.9787 - val_loss: 0.3661 - val_accuracy: 0.9100\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2363 - accuracy: 0.9755 - val_loss: 0.3597 - val_accuracy: 0.9033\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2375 - accuracy: 0.9736 - val_loss: 0.3466 - val_accuracy: 0.9233\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2305 - accuracy: 0.9824 - val_loss: 0.3699 - val_accuracy: 0.9100\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2355 - accuracy: 0.9731 - val_loss: 0.3591 - val_accuracy: 0.9200\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2392 - accuracy: 0.9736 - val_loss: 0.3310 - val_accuracy: 0.9267\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2394 - accuracy: 0.9755 - val_loss: 0.3568 - val_accuracy: 0.9233\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2345 - accuracy: 0.9787 - val_loss: 0.3625 - val_accuracy: 0.9233\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2356 - accuracy: 0.9745 - val_loss: 0.3548 - val_accuracy: 0.9233\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2412 - accuracy: 0.9769 - val_loss: 0.3776 - val_accuracy: 0.9233\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2298 - accuracy: 0.9792 - val_loss: 0.3356 - val_accuracy: 0.9233\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2256 - accuracy: 0.9843 - val_loss: 0.3617 - val_accuracy: 0.9233\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2261 - accuracy: 0.9801 - val_loss: 0.3566 - val_accuracy: 0.9200\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2321 - accuracy: 0.9741 - val_loss: 0.3529 - val_accuracy: 0.9233\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2279 - accuracy: 0.9792 - val_loss: 0.3654 - val_accuracy: 0.9167\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2265 - accuracy: 0.9769 - val_loss: 0.3511 - val_accuracy: 0.9233\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2329 - accuracy: 0.9745 - val_loss: 0.3480 - val_accuracy: 0.9167\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2277 - accuracy: 0.9773 - val_loss: 0.3383 - val_accuracy: 0.9233\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2235 - accuracy: 0.9745 - val_loss: 0.3319 - val_accuracy: 0.9300\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.99 - 0s 22us/sample - loss: 0.2200 - accuracy: 0.9806 - val_loss: 0.3379 - val_accuracy: 0.9233\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2167 - accuracy: 0.9829 - val_loss: 0.3651 - val_accuracy: 0.9167\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2164 - accuracy: 0.9801 - val_loss: 0.3742 - val_accuracy: 0.9233\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2179 - accuracy: 0.9750 - val_loss: 0.3443 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2201 - accuracy: 0.9801 - val_loss: 0.3404 - val_accuracy: 0.9267\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2219 - accuracy: 0.9806 - val_loss: 0.3503 - val_accuracy: 0.9233\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2191 - accuracy: 0.9764 - val_loss: 0.3506 - val_accuracy: 0.9233\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2198 - accuracy: 0.9792 - val_loss: 0.3471 - val_accuracy: 0.9133\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2250 - accuracy: 0.9727 - val_loss: 0.3502 - val_accuracy: 0.9200\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2200 - accuracy: 0.9810 - val_loss: 0.3669 - val_accuracy: 0.9200\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2155 - accuracy: 0.9792 - val_loss: 0.3702 - val_accuracy: 0.9167\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2286 - accuracy: 0.9722 - val_loss: 0.3434 - val_accuracy: 0.9233\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2136 - accuracy: 0.9824 - val_loss: 0.3590 - val_accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2269 - accuracy: 0.9759 - val_loss: 0.3507 - val_accuracy: 0.9167\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2171 - accuracy: 0.9806 - val_loss: 0.3704 - val_accuracy: 0.9133\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2200 - accuracy: 0.9810 - val_loss: 0.3481 - val_accuracy: 0.9200\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2105 - accuracy: 0.9810 - val_loss: 0.3671 - val_accuracy: 0.9167\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2124 - accuracy: 0.9750 - val_loss: 0.3684 - val_accuracy: 0.9167\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2058 - accuracy: 0.9824 - val_loss: 0.3973 - val_accuracy: 0.9200\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2151 - accuracy: 0.9801 - val_loss: 0.3475 - val_accuracy: 0.9267\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2141 - accuracy: 0.9782 - val_loss: 0.3556 - val_accuracy: 0.9267\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1993 - accuracy: 0.9866 - val_loss: 0.3828 - val_accuracy: 0.9267\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2132 - accuracy: 0.9787 - val_loss: 0.3583 - val_accuracy: 0.9300\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2090 - accuracy: 0.9773 - val_loss: 0.3588 - val_accuracy: 0.9267\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2108 - accuracy: 0.9852 - val_loss: 0.3597 - val_accuracy: 0.9233\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2103 - accuracy: 0.9782 - val_loss: 0.3820 - val_accuracy: 0.9100\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2200 - accuracy: 0.9750 - val_loss: 0.3483 - val_accuracy: 0.9200\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2108 - accuracy: 0.9801 - val_loss: 0.3886 - val_accuracy: 0.9200\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2067 - accuracy: 0.9810 - val_loss: 0.3678 - val_accuracy: 0.9200\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2107 - accuracy: 0.9815 - val_loss: 0.3697 - val_accuracy: 0.9200\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2059 - accuracy: 0.9806 - val_loss: 0.3814 - val_accuracy: 0.9200\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2059 - accuracy: 0.9833 - val_loss: 0.3691 - val_accuracy: 0.9267\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2065 - accuracy: 0.9782 - val_loss: 0.3842 - val_accuracy: 0.9233\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2075 - accuracy: 0.9773 - val_loss: 0.3594 - val_accuracy: 0.9167\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2136 - accuracy: 0.9782 - val_loss: 0.3930 - val_accuracy: 0.9233\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2117 - accuracy: 0.9769 - val_loss: 0.3923 - val_accuracy: 0.9200\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1976 - accuracy: 0.9856 - val_loss: 0.3792 - val_accuracy: 0.9233\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2168 - accuracy: 0.9750 - val_loss: 0.3231 - val_accuracy: 0.9267\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2017 - accuracy: 0.9833 - val_loss: 0.3568 - val_accuracy: 0.9267\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2062 - accuracy: 0.9787 - val_loss: 0.3558 - val_accuracy: 0.9300\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2030 - accuracy: 0.9792 - val_loss: 0.3421 - val_accuracy: 0.9300\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2024 - accuracy: 0.9833 - val_loss: 0.3518 - val_accuracy: 0.9233\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2073 - accuracy: 0.9782 - val_loss: 0.3358 - val_accuracy: 0.9300\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2070 - accuracy: 0.9787 - val_loss: 0.3565 - val_accuracy: 0.9267\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2048 - accuracy: 0.9810 - val_loss: 0.3276 - val_accuracy: 0.9267\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2027 - accuracy: 0.9778 - val_loss: 0.3397 - val_accuracy: 0.9267\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2055 - accuracy: 0.9792 - val_loss: 0.3549 - val_accuracy: 0.9267\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2051 - accuracy: 0.9769 - val_loss: 0.3860 - val_accuracy: 0.9267\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2092 - accuracy: 0.9824 - val_loss: 0.3513 - val_accuracy: 0.9333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2050 - accuracy: 0.9778 - val_loss: 0.3804 - val_accuracy: 0.9300\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2024 - accuracy: 0.9769 - val_loss: 0.3768 - val_accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2039 - accuracy: 0.9810 - val_loss: 0.3745 - val_accuracy: 0.9300\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2066 - accuracy: 0.9810 - val_loss: 0.3707 - val_accuracy: 0.9300\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2000 - accuracy: 0.9815 - val_loss: 0.4048 - val_accuracy: 0.9267\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2015 - accuracy: 0.9796 - val_loss: 0.3801 - val_accuracy: 0.9233\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2034 - accuracy: 0.9764 - val_loss: 0.3841 - val_accuracy: 0.9200\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1945 - accuracy: 0.9833 - val_loss: 0.3745 - val_accuracy: 0.9233\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1944 - accuracy: 0.9829 - val_loss: 0.3880 - val_accuracy: 0.9233\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1947 - accuracy: 0.9843 - val_loss: 0.3969 - val_accuracy: 0.9233\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1993 - accuracy: 0.9792 - val_loss: 0.3789 - val_accuracy: 0.9200\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1922 - accuracy: 0.9856 - val_loss: 0.4031 - val_accuracy: 0.9233\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1943 - accuracy: 0.9810 - val_loss: 0.3903 - val_accuracy: 0.9200\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1930 - accuracy: 0.9815 - val_loss: 0.3910 - val_accuracy: 0.9233\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1969 - accuracy: 0.9787 - val_loss: 0.3873 - val_accuracy: 0.9233\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1962 - accuracy: 0.9796 - val_loss: 0.3802 - val_accuracy: 0.9267\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1940 - accuracy: 0.9838 - val_loss: 0.3757 - val_accuracy: 0.9267\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1919 - accuracy: 0.9843 - val_loss: 0.3865 - val_accuracy: 0.9333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2070 - accuracy: 0.9782 - val_loss: 0.3439 - val_accuracy: 0.9233\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1989 - accuracy: 0.9801 - val_loss: 0.3913 - val_accuracy: 0.9233\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1955 - accuracy: 0.9861 - val_loss: 0.3709 - val_accuracy: 0.9233\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2003 - accuracy: 0.9778 - val_loss: 0.3849 - val_accuracy: 0.9233\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1917 - accuracy: 0.9815 - val_loss: 0.3666 - val_accuracy: 0.9267\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1924 - accuracy: 0.9819 - val_loss: 0.4016 - val_accuracy: 0.9233\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1872 - accuracy: 0.9866 - val_loss: 0.3936 - val_accuracy: 0.9200\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1998 - accuracy: 0.9792 - val_loss: 0.3723 - val_accuracy: 0.9167\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1898 - accuracy: 0.9852 - val_loss: 0.4027 - val_accuracy: 0.9200\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1932 - accuracy: 0.9833 - val_loss: 0.4259 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1949 - accuracy: 0.9792 - val_loss: 0.4183 - val_accuracy: 0.9200\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1989 - accuracy: 0.9773 - val_loss: 0.3748 - val_accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1924 - accuracy: 0.9801 - val_loss: 0.3806 - val_accuracy: 0.9233\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1997 - accuracy: 0.9773 - val_loss: 0.4026 - val_accuracy: 0.9233\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1933 - accuracy: 0.9796 - val_loss: 0.4262 - val_accuracy: 0.9267\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1951 - accuracy: 0.9810 - val_loss: 0.4072 - val_accuracy: 0.9300\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1963 - accuracy: 0.9824 - val_loss: 0.4105 - val_accuracy: 0.9233\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1906 - accuracy: 0.9843 - val_loss: 0.3866 - val_accuracy: 0.9233\n",
      "540/540 [==============================] - 0s 268us/sample - loss: 0.4270 - accuracy: 0.9352\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 495us/sample - loss: 4.0938 - accuracy: 0.6222 - val_loss: 3.2464 - val_accuracy: 0.8367\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 28us/sample - loss: 3.4290 - accuracy: 0.7616 - val_loss: 3.0403 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.1792 - accuracy: 0.7750 - val_loss: 2.8460 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.9512 - accuracy: 0.7829 - val_loss: 2.6688 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.6938 - accuracy: 0.7958 - val_loss: 2.4947 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.4823 - accuracy: 0.8028 - val_loss: 2.3274 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.2812 - accuracy: 0.8250 - val_loss: 2.1648 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.1147 - accuracy: 0.8255 - val_loss: 2.0108 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.9438 - accuracy: 0.8366 - val_loss: 1.8693 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8159 - accuracy: 0.8394 - val_loss: 1.7338 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.6710 - accuracy: 0.8454 - val_loss: 1.6088 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.5515 - accuracy: 0.8435 - val_loss: 1.4962 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.4584 - accuracy: 0.8440 - val_loss: 1.3941 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3549 - accuracy: 0.8454 - val_loss: 1.3011 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2550 - accuracy: 0.8458 - val_loss: 1.2127 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.1822 - accuracy: 0.8472 - val_loss: 1.1329 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.0980 - accuracy: 0.8481 - val_loss: 1.0612 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0385 - accuracy: 0.8472 - val_loss: 0.9964 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9775 - accuracy: 0.8477 - val_loss: 0.9374 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9229 - accuracy: 0.8477 - val_loss: 0.8829 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8594 - accuracy: 0.8477 - val_loss: 0.8320 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8156 - accuracy: 0.8477 - val_loss: 0.7860 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7776 - accuracy: 0.8477 - val_loss: 0.7441 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7323 - accuracy: 0.8477 - val_loss: 0.7043 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6921 - accuracy: 0.8477 - val_loss: 0.6691 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6600 - accuracy: 0.8477 - val_loss: 0.6377 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6186 - accuracy: 0.8477 - val_loss: 0.6088 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6019 - accuracy: 0.8477 - val_loss: 0.5834 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5664 - accuracy: 0.8477 - val_loss: 0.5631 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5471 - accuracy: 0.8477 - val_loss: 0.5439 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5185 - accuracy: 0.8477 - val_loss: 0.5289 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.82 - 0s 22us/sample - loss: 0.5030 - accuracy: 0.8477 - val_loss: 0.5081 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4764 - accuracy: 0.8477 - val_loss: 0.4954 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4609 - accuracy: 0.8477 - val_loss: 0.4841 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4464 - accuracy: 0.8477 - val_loss: 0.4726 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4313 - accuracy: 0.8477 - val_loss: 0.4632 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4262 - accuracy: 0.8477 - val_loss: 0.4472 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4069 - accuracy: 0.8477 - val_loss: 0.4452 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3961 - accuracy: 0.8477 - val_loss: 0.4385 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3861 - accuracy: 0.8477 - val_loss: 0.4293 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3791 - accuracy: 0.8477 - val_loss: 0.4248 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3656 - accuracy: 0.8477 - val_loss: 0.4207 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3628 - accuracy: 0.8477 - val_loss: 0.4138 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3521 - accuracy: 0.8644 - val_loss: 0.4131 - val_accuracy: 0.8967\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3436 - accuracy: 0.9287 - val_loss: 0.4124 - val_accuracy: 0.8800\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3443 - accuracy: 0.9218 - val_loss: 0.4148 - val_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3346 - accuracy: 0.9403 - val_loss: 0.4064 - val_accuracy: 0.8933\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3295 - accuracy: 0.9468 - val_loss: 0.4023 - val_accuracy: 0.8967\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3272 - accuracy: 0.9500 - val_loss: 0.3969 - val_accuracy: 0.8967\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3230 - accuracy: 0.9407 - val_loss: 0.3841 - val_accuracy: 0.8933\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3256 - accuracy: 0.9463 - val_loss: 0.3840 - val_accuracy: 0.8967\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3145 - accuracy: 0.9472 - val_loss: 0.3819 - val_accuracy: 0.8933\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3081 - accuracy: 0.9509 - val_loss: 0.3874 - val_accuracy: 0.8933\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2989 - accuracy: 0.9565 - val_loss: 0.3870 - val_accuracy: 0.9000\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3029 - accuracy: 0.9514 - val_loss: 0.3845 - val_accuracy: 0.9033\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2950 - accuracy: 0.9588 - val_loss: 0.3847 - val_accuracy: 0.9033\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2941 - accuracy: 0.9556 - val_loss: 0.3772 - val_accuracy: 0.9133\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2936 - accuracy: 0.9560 - val_loss: 0.3720 - val_accuracy: 0.9200\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2886 - accuracy: 0.9639 - val_loss: 0.3791 - val_accuracy: 0.9167\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2858 - accuracy: 0.9634 - val_loss: 0.3791 - val_accuracy: 0.9200\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2830 - accuracy: 0.9644 - val_loss: 0.3802 - val_accuracy: 0.9033\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2814 - accuracy: 0.9616 - val_loss: 0.3666 - val_accuracy: 0.9067\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2782 - accuracy: 0.9606 - val_loss: 0.3648 - val_accuracy: 0.9167\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2789 - accuracy: 0.9662 - val_loss: 0.3760 - val_accuracy: 0.9100\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2789 - accuracy: 0.9630 - val_loss: 0.3771 - val_accuracy: 0.9133\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2697 - accuracy: 0.9685 - val_loss: 0.3784 - val_accuracy: 0.9067\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2706 - accuracy: 0.9634 - val_loss: 0.3800 - val_accuracy: 0.9133\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2647 - accuracy: 0.9708 - val_loss: 0.3661 - val_accuracy: 0.9167\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2667 - accuracy: 0.9667 - val_loss: 0.3676 - val_accuracy: 0.9133\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2599 - accuracy: 0.9713 - val_loss: 0.3940 - val_accuracy: 0.9033\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2649 - accuracy: 0.9676 - val_loss: 0.3754 - val_accuracy: 0.9200\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2657 - accuracy: 0.9662 - val_loss: 0.4000 - val_accuracy: 0.9067\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2582 - accuracy: 0.9685 - val_loss: 0.3935 - val_accuracy: 0.9167\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2640 - accuracy: 0.9690 - val_loss: 0.3838 - val_accuracy: 0.9167\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2597 - accuracy: 0.9690 - val_loss: 0.3778 - val_accuracy: 0.9200\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2548 - accuracy: 0.9713 - val_loss: 0.3770 - val_accuracy: 0.9133\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2550 - accuracy: 0.9731 - val_loss: 0.3783 - val_accuracy: 0.9167\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2584 - accuracy: 0.9694 - val_loss: 0.3736 - val_accuracy: 0.9200\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2578 - accuracy: 0.9713 - val_loss: 0.3752 - val_accuracy: 0.9100\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2559 - accuracy: 0.9727 - val_loss: 0.3891 - val_accuracy: 0.9000\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2538 - accuracy: 0.9722 - val_loss: 0.3884 - val_accuracy: 0.9133\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2464 - accuracy: 0.9769 - val_loss: 0.3890 - val_accuracy: 0.9033\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2581 - accuracy: 0.9685 - val_loss: 0.3700 - val_accuracy: 0.9100\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2490 - accuracy: 0.9736 - val_loss: 0.3909 - val_accuracy: 0.9100\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2403 - accuracy: 0.9736 - val_loss: 0.3723 - val_accuracy: 0.9200\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2427 - accuracy: 0.9745 - val_loss: 0.3813 - val_accuracy: 0.9200\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2444 - accuracy: 0.9727 - val_loss: 0.3849 - val_accuracy: 0.9133\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2389 - accuracy: 0.9759 - val_loss: 0.3902 - val_accuracy: 0.9100\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2420 - accuracy: 0.9727 - val_loss: 0.3899 - val_accuracy: 0.9167\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2441 - accuracy: 0.9741 - val_loss: 0.3946 - val_accuracy: 0.9067\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2432 - accuracy: 0.9736 - val_loss: 0.3741 - val_accuracy: 0.9133\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2385 - accuracy: 0.9759 - val_loss: 0.3662 - val_accuracy: 0.9300\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2348 - accuracy: 0.9787 - val_loss: 0.3931 - val_accuracy: 0.9200\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2375 - accuracy: 0.9773 - val_loss: 0.4103 - val_accuracy: 0.9067\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2369 - accuracy: 0.9713 - val_loss: 0.3965 - val_accuracy: 0.9167\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2398 - accuracy: 0.9704 - val_loss: 0.3805 - val_accuracy: 0.9167\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2308 - accuracy: 0.9769 - val_loss: 0.3983 - val_accuracy: 0.9167\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2327 - accuracy: 0.9773 - val_loss: 0.3954 - val_accuracy: 0.9133\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2317 - accuracy: 0.9759 - val_loss: 0.3904 - val_accuracy: 0.9167\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2302 - accuracy: 0.9806 - val_loss: 0.4335 - val_accuracy: 0.9100\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2272 - accuracy: 0.9787 - val_loss: 0.3893 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2344 - accuracy: 0.9727 - val_loss: 0.3914 - val_accuracy: 0.9133\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2256 - accuracy: 0.9787 - val_loss: 0.3921 - val_accuracy: 0.9167\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2273 - accuracy: 0.9787 - val_loss: 0.3971 - val_accuracy: 0.9200\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2232 - accuracy: 0.9792 - val_loss: 0.3981 - val_accuracy: 0.9200\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2304 - accuracy: 0.9750 - val_loss: 0.4157 - val_accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2249 - accuracy: 0.9787 - val_loss: 0.4058 - val_accuracy: 0.9233\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2275 - accuracy: 0.9792 - val_loss: 0.3944 - val_accuracy: 0.9067\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2311 - accuracy: 0.9764 - val_loss: 0.3870 - val_accuracy: 0.9267\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2293 - accuracy: 0.9773 - val_loss: 0.4137 - val_accuracy: 0.9100\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2278 - accuracy: 0.9782 - val_loss: 0.3994 - val_accuracy: 0.9100\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2295 - accuracy: 0.9741 - val_loss: 0.4056 - val_accuracy: 0.9200\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2248 - accuracy: 0.9769 - val_loss: 0.3938 - val_accuracy: 0.9233\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2185 - accuracy: 0.9796 - val_loss: 0.4045 - val_accuracy: 0.9200\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2167 - accuracy: 0.9819 - val_loss: 0.4133 - val_accuracy: 0.9167\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2212 - accuracy: 0.9769 - val_loss: 0.3641 - val_accuracy: 0.9300\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2231 - accuracy: 0.9769 - val_loss: 0.3941 - val_accuracy: 0.9267\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2220 - accuracy: 0.9810 - val_loss: 0.3750 - val_accuracy: 0.9233\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2215 - accuracy: 0.9745 - val_loss: 0.3862 - val_accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2207 - accuracy: 0.9755 - val_loss: 0.4015 - val_accuracy: 0.9167\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2202 - accuracy: 0.9769 - val_loss: 0.3930 - val_accuracy: 0.9267\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2272 - accuracy: 0.9769 - val_loss: 0.4071 - val_accuracy: 0.9200\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2208 - accuracy: 0.9755 - val_loss: 0.4033 - val_accuracy: 0.9200\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2192 - accuracy: 0.9769 - val_loss: 0.4104 - val_accuracy: 0.9167\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2173 - accuracy: 0.9792 - val_loss: 0.4048 - val_accuracy: 0.9233\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2132 - accuracy: 0.9806 - val_loss: 0.3906 - val_accuracy: 0.9300\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2131 - accuracy: 0.9806 - val_loss: 0.4334 - val_accuracy: 0.9267\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2152 - accuracy: 0.9792 - val_loss: 0.4207 - val_accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2092 - accuracy: 0.9801 - val_loss: 0.3973 - val_accuracy: 0.9267\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2155 - accuracy: 0.9792 - val_loss: 0.4284 - val_accuracy: 0.9167\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2146 - accuracy: 0.9792 - val_loss: 0.4129 - val_accuracy: 0.9267\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2160 - accuracy: 0.9773 - val_loss: 0.4443 - val_accuracy: 0.9200\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2045 - accuracy: 0.9838 - val_loss: 0.4095 - val_accuracy: 0.9167\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2068 - accuracy: 0.9819 - val_loss: 0.4034 - val_accuracy: 0.9233\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2143 - accuracy: 0.9759 - val_loss: 0.4242 - val_accuracy: 0.9233\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2077 - accuracy: 0.9787 - val_loss: 0.4266 - val_accuracy: 0.9233\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2052 - accuracy: 0.9829 - val_loss: 0.4306 - val_accuracy: 0.9167\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2088 - accuracy: 0.9787 - val_loss: 0.4386 - val_accuracy: 0.9200\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2129 - accuracy: 0.9782 - val_loss: 0.4216 - val_accuracy: 0.9200\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2088 - accuracy: 0.9792 - val_loss: 0.4347 - val_accuracy: 0.9233\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2098 - accuracy: 0.9782 - val_loss: 0.4173 - val_accuracy: 0.9233\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2066 - accuracy: 0.9773 - val_loss: 0.4152 - val_accuracy: 0.9267\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2135 - accuracy: 0.9750 - val_loss: 0.4168 - val_accuracy: 0.9167\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2026 - accuracy: 0.9833 - val_loss: 0.4314 - val_accuracy: 0.9233\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.97 - 0s 23us/sample - loss: 0.2045 - accuracy: 0.9815 - val_loss: 0.4191 - val_accuracy: 0.9300\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2013 - accuracy: 0.9843 - val_loss: 0.4278 - val_accuracy: 0.9200\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2064 - accuracy: 0.9787 - val_loss: 0.4103 - val_accuracy: 0.9267\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2040 - accuracy: 0.9801 - val_loss: 0.4064 - val_accuracy: 0.9233\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2067 - accuracy: 0.9796 - val_loss: 0.4335 - val_accuracy: 0.9200\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2059 - accuracy: 0.9782 - val_loss: 0.4207 - val_accuracy: 0.9233\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2105 - accuracy: 0.9764 - val_loss: 0.4563 - val_accuracy: 0.9200\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2014 - accuracy: 0.9815 - val_loss: 0.4472 - val_accuracy: 0.9167\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1956 - accuracy: 0.9856 - val_loss: 0.4424 - val_accuracy: 0.9267\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2046 - accuracy: 0.9810 - val_loss: 0.4405 - val_accuracy: 0.9233\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1989 - accuracy: 0.9829 - val_loss: 0.4183 - val_accuracy: 0.9233\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2059 - accuracy: 0.9741 - val_loss: 0.4286 - val_accuracy: 0.9300\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2080 - accuracy: 0.9755 - val_loss: 0.4212 - val_accuracy: 0.9267\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2012 - accuracy: 0.9792 - val_loss: 0.4457 - val_accuracy: 0.9233\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2007 - accuracy: 0.9843 - val_loss: 0.4248 - val_accuracy: 0.9300\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2010 - accuracy: 0.9778 - val_loss: 0.3980 - val_accuracy: 0.9333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2036 - accuracy: 0.9815 - val_loss: 0.4049 - val_accuracy: 0.9333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2007 - accuracy: 0.9801 - val_loss: 0.4180 - val_accuracy: 0.9333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2073 - accuracy: 0.9769 - val_loss: 0.4293 - val_accuracy: 0.9233\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2033 - accuracy: 0.9810 - val_loss: 0.4243 - val_accuracy: 0.9333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2033 - accuracy: 0.9778 - val_loss: 0.4317 - val_accuracy: 0.9267\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1957 - accuracy: 0.9806 - val_loss: 0.4505 - val_accuracy: 0.9233\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.97 - 0s 22us/sample - loss: 0.2002 - accuracy: 0.9852 - val_loss: 0.4496 - val_accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1965 - accuracy: 0.9815 - val_loss: 0.4248 - val_accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1983 - accuracy: 0.9792 - val_loss: 0.4293 - val_accuracy: 0.9267\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1986 - accuracy: 0.9801 - val_loss: 0.4167 - val_accuracy: 0.9267\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1943 - accuracy: 0.9819 - val_loss: 0.4270 - val_accuracy: 0.9333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1922 - accuracy: 0.9824 - val_loss: 0.4433 - val_accuracy: 0.9300\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1989 - accuracy: 0.9796 - val_loss: 0.4378 - val_accuracy: 0.9267\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1917 - accuracy: 0.9824 - val_loss: 0.4404 - val_accuracy: 0.9233\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1999 - accuracy: 0.9759 - val_loss: 0.4640 - val_accuracy: 0.9267\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1947 - accuracy: 0.9806 - val_loss: 0.4341 - val_accuracy: 0.9233\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1932 - accuracy: 0.9824 - val_loss: 0.4651 - val_accuracy: 0.9200\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1989 - accuracy: 0.9801 - val_loss: 0.4556 - val_accuracy: 0.9233\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2035 - accuracy: 0.9773 - val_loss: 0.4652 - val_accuracy: 0.9200\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1928 - accuracy: 0.9810 - val_loss: 0.4465 - val_accuracy: 0.9200\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1984 - accuracy: 0.9773 - val_loss: 0.4787 - val_accuracy: 0.9167\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1945 - accuracy: 0.9819 - val_loss: 0.4374 - val_accuracy: 0.9167\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1912 - accuracy: 0.9847 - val_loss: 0.4384 - val_accuracy: 0.9167\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1933 - accuracy: 0.9815 - val_loss: 0.4857 - val_accuracy: 0.9233\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.96 - 0s 23us/sample - loss: 0.1956 - accuracy: 0.9787 - val_loss: 0.4415 - val_accuracy: 0.9200\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1936 - accuracy: 0.9815 - val_loss: 0.4502 - val_accuracy: 0.9167\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1898 - accuracy: 0.9829 - val_loss: 0.4326 - val_accuracy: 0.9233\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1910 - accuracy: 0.9833 - val_loss: 0.4589 - val_accuracy: 0.9200\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.1924 - accuracy: 0.9819 - val_loss: 0.4843 - val_accuracy: 0.9133\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1928 - accuracy: 0.9810 - val_loss: 0.4546 - val_accuracy: 0.9233\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1996 - accuracy: 0.9792 - val_loss: 0.4729 - val_accuracy: 0.9200\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1965 - accuracy: 0.9796 - val_loss: 0.4725 - val_accuracy: 0.9267\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1904 - accuracy: 0.9824 - val_loss: 0.4842 - val_accuracy: 0.9300\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1853 - accuracy: 0.9829 - val_loss: 0.4746 - val_accuracy: 0.9233\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1949 - accuracy: 0.9792 - val_loss: 0.4497 - val_accuracy: 0.9300\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1894 - accuracy: 0.9829 - val_loss: 0.4458 - val_accuracy: 0.9300\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1933 - accuracy: 0.9810 - val_loss: 0.4472 - val_accuracy: 0.9267\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1925 - accuracy: 0.9778 - val_loss: 0.4555 - val_accuracy: 0.9200\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1856 - accuracy: 0.9838 - val_loss: 0.4582 - val_accuracy: 0.9167\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1924 - accuracy: 0.9801 - val_loss: 0.5127 - val_accuracy: 0.9167\n",
      "540/540 [==============================] - 0s 284us/sample - loss: 0.3969 - accuracy: 0.9463\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 382us/sample - loss: 4.0006 - accuracy: 0.5273 - val_loss: 3.3068 - val_accuracy: 0.8433\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.4406 - accuracy: 0.6963 - val_loss: 3.0531 - val_accuracy: 0.8367\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.0872 - accuracy: 0.7690 - val_loss: 2.8383 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.8429 - accuracy: 0.7731 - val_loss: 2.6390 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.5949 - accuracy: 0.7954 - val_loss: 2.4478 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.3898 - accuracy: 0.8148 - val_loss: 2.2673 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.2332 - accuracy: 0.8208 - val_loss: 2.0987 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.0420 - accuracy: 0.8227 - val_loss: 1.9374 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8801 - accuracy: 0.8306 - val_loss: 1.7862 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.7264 - accuracy: 0.8352 - val_loss: 1.6519 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.5989 - accuracy: 0.8403 - val_loss: 1.5283 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4816 - accuracy: 0.8412 - val_loss: 1.4176 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.3612 - accuracy: 0.8421 - val_loss: 1.3140 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2721 - accuracy: 0.8403 - val_loss: 1.2215 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1863 - accuracy: 0.8426 - val_loss: 1.1422 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.1230 - accuracy: 0.8426 - val_loss: 1.0694 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.0402 - accuracy: 0.8431 - val_loss: 1.0023 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.9758 - accuracy: 0.8417 - val_loss: 0.9412 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9286 - accuracy: 0.8431 - val_loss: 0.8870 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8733 - accuracy: 0.8431 - val_loss: 0.8365 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8212 - accuracy: 0.8431 - val_loss: 0.7898 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7795 - accuracy: 0.8426 - val_loss: 0.7459 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7385 - accuracy: 0.8431 - val_loss: 0.7069 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7059 - accuracy: 0.8431 - val_loss: 0.6692 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6768 - accuracy: 0.8431 - val_loss: 0.6347 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6368 - accuracy: 0.8431 - val_loss: 0.6019 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6007 - accuracy: 0.8431 - val_loss: 0.5706 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5747 - accuracy: 0.8431 - val_loss: 0.5406 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5462 - accuracy: 0.8431 - val_loss: 0.5161 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5345 - accuracy: 0.8431 - val_loss: 0.4942 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5124 - accuracy: 0.8431 - val_loss: 0.4756 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4854 - accuracy: 0.8431 - val_loss: 0.4613 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4684 - accuracy: 0.8431 - val_loss: 0.4473 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4500 - accuracy: 0.8431 - val_loss: 0.4274 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4221 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4209 - accuracy: 0.8431 - val_loss: 0.4128 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4085 - accuracy: 0.8431 - val_loss: 0.4033 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4058 - accuracy: 0.8431 - val_loss: 0.3986 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3931 - accuracy: 0.8431 - val_loss: 0.3962 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.3811 - accuracy: 0.8431 - val_loss: 0.3983 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3758 - accuracy: 0.8431 - val_loss: 0.3972 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3677 - accuracy: 0.8431 - val_loss: 0.3884 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3639 - accuracy: 0.8431 - val_loss: 0.3921 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3531 - accuracy: 0.8431 - val_loss: 0.3873 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3481 - accuracy: 0.8431 - val_loss: 0.3747 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3381 - accuracy: 0.8431 - val_loss: 0.3724 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3363 - accuracy: 0.8431 - val_loss: 0.3713 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3330 - accuracy: 0.8431 - val_loss: 0.3600 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3307 - accuracy: 0.8431 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3242 - accuracy: 0.8431 - val_loss: 0.3599 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3196 - accuracy: 0.8977 - val_loss: 0.3603 - val_accuracy: 0.9100\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.3158 - accuracy: 0.9412 - val_loss: 0.3557 - val_accuracy: 0.9033\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3089 - accuracy: 0.9394 - val_loss: 0.3479 - val_accuracy: 0.9200\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3077 - accuracy: 0.9486 - val_loss: 0.3458 - val_accuracy: 0.9300\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3093 - accuracy: 0.9454 - val_loss: 0.3462 - val_accuracy: 0.9167\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.3066 - accuracy: 0.9384 - val_loss: 0.3391 - val_accuracy: 0.9333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3086 - accuracy: 0.9500 - val_loss: 0.3552 - val_accuracy: 0.9300\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.3048 - accuracy: 0.9468 - val_loss: 0.3522 - val_accuracy: 0.9267\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2955 - accuracy: 0.9551 - val_loss: 0.3520 - val_accuracy: 0.9200\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.94 - 0s 22us/sample - loss: 0.2928 - accuracy: 0.9491 - val_loss: 0.3473 - val_accuracy: 0.9300\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2912 - accuracy: 0.9551 - val_loss: 0.3564 - val_accuracy: 0.9233\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2912 - accuracy: 0.9542 - val_loss: 0.3590 - val_accuracy: 0.9133\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2939 - accuracy: 0.9509 - val_loss: 0.3180 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2911 - accuracy: 0.9528 - val_loss: 0.3332 - val_accuracy: 0.9300\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2848 - accuracy: 0.9569 - val_loss: 0.3385 - val_accuracy: 0.9300\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2826 - accuracy: 0.9560 - val_loss: 0.3446 - val_accuracy: 0.9300\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2874 - accuracy: 0.9523 - val_loss: 0.3398 - val_accuracy: 0.9367\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2820 - accuracy: 0.9644 - val_loss: 0.3542 - val_accuracy: 0.9233\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2815 - accuracy: 0.9588 - val_loss: 0.3470 - val_accuracy: 0.9267\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2806 - accuracy: 0.9625 - val_loss: 0.3453 - val_accuracy: 0.9267\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2816 - accuracy: 0.9620 - val_loss: 0.3577 - val_accuracy: 0.9200\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2736 - accuracy: 0.9667 - val_loss: 0.3495 - val_accuracy: 0.9233\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.96 - 0s 23us/sample - loss: 0.2826 - accuracy: 0.9574 - val_loss: 0.3345 - val_accuracy: 0.9133\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2747 - accuracy: 0.9685 - val_loss: 0.3507 - val_accuracy: 0.9200\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2743 - accuracy: 0.9625 - val_loss: 0.3472 - val_accuracy: 0.9200\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2714 - accuracy: 0.9653 - val_loss: 0.3474 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2643 - accuracy: 0.9731 - val_loss: 0.3519 - val_accuracy: 0.9267\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2682 - accuracy: 0.9653 - val_loss: 0.3382 - val_accuracy: 0.9367\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2584 - accuracy: 0.9685 - val_loss: 0.3573 - val_accuracy: 0.9333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2585 - accuracy: 0.9727 - val_loss: 0.3475 - val_accuracy: 0.9333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2620 - accuracy: 0.9685 - val_loss: 0.3434 - val_accuracy: 0.9233\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2701 - accuracy: 0.9634 - val_loss: 0.3242 - val_accuracy: 0.9333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2599 - accuracy: 0.9676 - val_loss: 0.3511 - val_accuracy: 0.9233\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2564 - accuracy: 0.9690 - val_loss: 0.3430 - val_accuracy: 0.9300\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2646 - accuracy: 0.9667 - val_loss: 0.3403 - val_accuracy: 0.9367\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2571 - accuracy: 0.9676 - val_loss: 0.3527 - val_accuracy: 0.9300\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2686 - accuracy: 0.9685 - val_loss: 0.3524 - val_accuracy: 0.9267\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2618 - accuracy: 0.9694 - val_loss: 0.3729 - val_accuracy: 0.9100\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2532 - accuracy: 0.9694 - val_loss: 0.3736 - val_accuracy: 0.9100\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2510 - accuracy: 0.9727 - val_loss: 0.3494 - val_accuracy: 0.9300\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2518 - accuracy: 0.9704 - val_loss: 0.3441 - val_accuracy: 0.9300\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.2590 - accuracy: 0.9648 - val_loss: 0.3442 - val_accuracy: 0.9400\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2506 - accuracy: 0.9685 - val_loss: 0.3723 - val_accuracy: 0.9267\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2478 - accuracy: 0.9745 - val_loss: 0.3359 - val_accuracy: 0.9367\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2445 - accuracy: 0.9750 - val_loss: 0.3620 - val_accuracy: 0.9267\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2524 - accuracy: 0.9704 - val_loss: 0.3308 - val_accuracy: 0.9433\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2491 - accuracy: 0.9727 - val_loss: 0.3533 - val_accuracy: 0.9367\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2456 - accuracy: 0.9699 - val_loss: 0.3458 - val_accuracy: 0.9400\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2393 - accuracy: 0.9764 - val_loss: 0.3615 - val_accuracy: 0.9433\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2395 - accuracy: 0.9718 - val_loss: 0.3517 - val_accuracy: 0.9433\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2345 - accuracy: 0.9782 - val_loss: 0.3629 - val_accuracy: 0.9367\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2332 - accuracy: 0.9769 - val_loss: 0.3419 - val_accuracy: 0.9433\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2400 - accuracy: 0.9745 - val_loss: 0.3444 - val_accuracy: 0.9433\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2360 - accuracy: 0.9806 - val_loss: 0.3465 - val_accuracy: 0.9400\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2306 - accuracy: 0.9796 - val_loss: 0.3417 - val_accuracy: 0.9433\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2271 - accuracy: 0.9829 - val_loss: 0.3575 - val_accuracy: 0.9433\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2264 - accuracy: 0.9829 - val_loss: 0.3751 - val_accuracy: 0.9333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2266 - accuracy: 0.9769 - val_loss: 0.3379 - val_accuracy: 0.9400\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.2338 - accuracy: 0.9745 - val_loss: 0.3425 - val_accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2320 - accuracy: 0.9755 - val_loss: 0.3386 - val_accuracy: 0.9333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2309 - accuracy: 0.9769 - val_loss: 0.3339 - val_accuracy: 0.9367\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2321 - accuracy: 0.9759 - val_loss: 0.3425 - val_accuracy: 0.9367\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2346 - accuracy: 0.9773 - val_loss: 0.3550 - val_accuracy: 0.9400\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2341 - accuracy: 0.9782 - val_loss: 0.3598 - val_accuracy: 0.9367\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2362 - accuracy: 0.9787 - val_loss: 0.3729 - val_accuracy: 0.9333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2314 - accuracy: 0.9778 - val_loss: 0.3569 - val_accuracy: 0.9367\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2229 - accuracy: 0.9764 - val_loss: 0.3666 - val_accuracy: 0.9400\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2251 - accuracy: 0.9787 - val_loss: 0.3711 - val_accuracy: 0.9433\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2260 - accuracy: 0.9782 - val_loss: 0.3644 - val_accuracy: 0.9433\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2248 - accuracy: 0.9792 - val_loss: 0.3527 - val_accuracy: 0.9333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2195 - accuracy: 0.9796 - val_loss: 0.3377 - val_accuracy: 0.9400\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2223 - accuracy: 0.9796 - val_loss: 0.3582 - val_accuracy: 0.9333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2284 - accuracy: 0.9699 - val_loss: 0.3542 - val_accuracy: 0.9433\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2277 - accuracy: 0.9755 - val_loss: 0.3579 - val_accuracy: 0.9400\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2227 - accuracy: 0.9782 - val_loss: 0.3360 - val_accuracy: 0.9500\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2246 - accuracy: 0.9787 - val_loss: 0.3433 - val_accuracy: 0.9467\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2211 - accuracy: 0.9815 - val_loss: 0.3696 - val_accuracy: 0.9433\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2178 - accuracy: 0.9792 - val_loss: 0.3360 - val_accuracy: 0.9467\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2140 - accuracy: 0.9824 - val_loss: 0.3332 - val_accuracy: 0.9433\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2273 - accuracy: 0.9731 - val_loss: 0.3332 - val_accuracy: 0.9467\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.2195 - accuracy: 0.9769 - val_loss: 0.3583 - val_accuracy: 0.9433\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2165 - accuracy: 0.9806 - val_loss: 0.3233 - val_accuracy: 0.9467\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2164 - accuracy: 0.9787 - val_loss: 0.3417 - val_accuracy: 0.9467\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2111 - accuracy: 0.9838 - val_loss: 0.3386 - val_accuracy: 0.9467\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2073 - accuracy: 0.9819 - val_loss: 0.3518 - val_accuracy: 0.9500\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2077 - accuracy: 0.9806 - val_loss: 0.3573 - val_accuracy: 0.9500\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2108 - accuracy: 0.9815 - val_loss: 0.3478 - val_accuracy: 0.9433\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2144 - accuracy: 0.9759 - val_loss: 0.3442 - val_accuracy: 0.9500\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2262 - accuracy: 0.9731 - val_loss: 0.3163 - val_accuracy: 0.9467\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2184 - accuracy: 0.9796 - val_loss: 0.3381 - val_accuracy: 0.9400\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2218 - accuracy: 0.9750 - val_loss: 0.3466 - val_accuracy: 0.9467\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2138 - accuracy: 0.9792 - val_loss: 0.3386 - val_accuracy: 0.9533\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2110 - accuracy: 0.9778 - val_loss: 0.3510 - val_accuracy: 0.9500\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2111 - accuracy: 0.9824 - val_loss: 0.3592 - val_accuracy: 0.9367\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2068 - accuracy: 0.9806 - val_loss: 0.3408 - val_accuracy: 0.9467\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1988 - accuracy: 0.9847 - val_loss: 0.3694 - val_accuracy: 0.9467\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2065 - accuracy: 0.9764 - val_loss: 0.3541 - val_accuracy: 0.9500\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2088 - accuracy: 0.9806 - val_loss: 0.3711 - val_accuracy: 0.9467\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2013 - accuracy: 0.9861 - val_loss: 0.3729 - val_accuracy: 0.9400\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2003 - accuracy: 0.9824 - val_loss: 0.3619 - val_accuracy: 0.9433\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2132 - accuracy: 0.9764 - val_loss: 0.3367 - val_accuracy: 0.9533\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2074 - accuracy: 0.9815 - val_loss: 0.3503 - val_accuracy: 0.9500\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2171 - accuracy: 0.9769 - val_loss: 0.3369 - val_accuracy: 0.9533\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2109 - accuracy: 0.9801 - val_loss: 0.3746 - val_accuracy: 0.9467\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2028 - accuracy: 0.9833 - val_loss: 0.3708 - val_accuracy: 0.9533\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2089 - accuracy: 0.9833 - val_loss: 0.3674 - val_accuracy: 0.9567\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2103 - accuracy: 0.9764 - val_loss: 0.3536 - val_accuracy: 0.9500\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2060 - accuracy: 0.9769 - val_loss: 0.3676 - val_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1984 - accuracy: 0.9856 - val_loss: 0.3985 - val_accuracy: 0.9467\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2121 - accuracy: 0.9782 - val_loss: 0.3711 - val_accuracy: 0.9467\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1986 - accuracy: 0.9838 - val_loss: 0.3931 - val_accuracy: 0.9500\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2013 - accuracy: 0.9829 - val_loss: 0.3780 - val_accuracy: 0.9500\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2029 - accuracy: 0.9782 - val_loss: 0.3528 - val_accuracy: 0.9533\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2047 - accuracy: 0.9792 - val_loss: 0.3576 - val_accuracy: 0.9467\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2107 - accuracy: 0.9755 - val_loss: 0.3407 - val_accuracy: 0.9467\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2077 - accuracy: 0.9782 - val_loss: 0.3402 - val_accuracy: 0.9533\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.2070 - accuracy: 0.9815 - val_loss: 0.3500 - val_accuracy: 0.9500\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2063 - accuracy: 0.9769 - val_loss: 0.3758 - val_accuracy: 0.9500\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2060 - accuracy: 0.9782 - val_loss: 0.3464 - val_accuracy: 0.9500\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2081 - accuracy: 0.9778 - val_loss: 0.3589 - val_accuracy: 0.9500\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2023 - accuracy: 0.9792 - val_loss: 0.3660 - val_accuracy: 0.9433\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1988 - accuracy: 0.9829 - val_loss: 0.3534 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2038 - accuracy: 0.9782 - val_loss: 0.3631 - val_accuracy: 0.9467\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1930 - accuracy: 0.9856 - val_loss: 0.3678 - val_accuracy: 0.9533\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2007 - accuracy: 0.9829 - val_loss: 0.4061 - val_accuracy: 0.9433\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2016 - accuracy: 0.9796 - val_loss: 0.3767 - val_accuracy: 0.9433\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2091 - accuracy: 0.9750 - val_loss: 0.3735 - val_accuracy: 0.9500\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2029 - accuracy: 0.9792 - val_loss: 0.3760 - val_accuracy: 0.9433\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2033 - accuracy: 0.9787 - val_loss: 0.3727 - val_accuracy: 0.9467\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2066 - accuracy: 0.9736 - val_loss: 0.3642 - val_accuracy: 0.9467\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1931 - accuracy: 0.9843 - val_loss: 0.3640 - val_accuracy: 0.9533\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2064 - accuracy: 0.9759 - val_loss: 0.3822 - val_accuracy: 0.9500\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1989 - accuracy: 0.9829 - val_loss: 0.4496 - val_accuracy: 0.9500\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2077 - accuracy: 0.9764 - val_loss: 0.3660 - val_accuracy: 0.9500\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2000 - accuracy: 0.9833 - val_loss: 0.3695 - val_accuracy: 0.9467\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1998 - accuracy: 0.9815 - val_loss: 0.3462 - val_accuracy: 0.9533\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2023 - accuracy: 0.9759 - val_loss: 0.3661 - val_accuracy: 0.9533\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1987 - accuracy: 0.9782 - val_loss: 0.3592 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.1906 - accuracy: 0.9870 - val_loss: 0.3450 - val_accuracy: 0.9467\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2019 - accuracy: 0.9773 - val_loss: 0.3374 - val_accuracy: 0.9500\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.2069 - accuracy: 0.9745 - val_loss: 0.3495 - val_accuracy: 0.9433\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1999 - accuracy: 0.9796 - val_loss: 0.3626 - val_accuracy: 0.9433\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1964 - accuracy: 0.9810 - val_loss: 0.3772 - val_accuracy: 0.9433\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1935 - accuracy: 0.9810 - val_loss: 0.3523 - val_accuracy: 0.9467\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.2023 - accuracy: 0.9759 - val_loss: 0.3559 - val_accuracy: 0.9500\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.1973 - accuracy: 0.9801 - val_loss: 0.3600 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1953 - accuracy: 0.9806 - val_loss: 0.3882 - val_accuracy: 0.9500\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1907 - accuracy: 0.9829 - val_loss: 0.3858 - val_accuracy: 0.9433\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1905 - accuracy: 0.9852 - val_loss: 0.3951 - val_accuracy: 0.9433\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.1869 - accuracy: 0.9829 - val_loss: 0.3942 - val_accuracy: 0.9400\n",
      "540/540 [==============================] - 0s 263us/sample - loss: 0.2864 - accuracy: 0.9611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 388us/sample - loss: 14.8888 - accuracy: 0.5662 - val_loss: 13.4154 - val_accuracy: 0.7200\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 12.3522 - accuracy: 0.7153 - val_loss: 11.1755 - val_accuracy: 0.8167\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 10.3004 - accuracy: 0.8014 - val_loss: 9.3597 - val_accuracy: 0.8267\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 8.6502 - accuracy: 0.8347 - val_loss: 7.8869 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 7.3142 - accuracy: 0.8421 - val_loss: 6.6897 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 6.2165 - accuracy: 0.8509 - val_loss: 5.7129 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.3151 - accuracy: 0.8519 - val_loss: 4.9122 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.5795 - accuracy: 0.8523 - val_loss: 4.2516 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.9664 - accuracy: 0.8523 - val_loss: 3.7017 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.4569 - accuracy: 0.8523 - val_loss: 3.2404 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.0241 - accuracy: 0.8523 - val_loss: 2.8508 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.6623 - accuracy: 0.8523 - val_loss: 2.5187 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.3506 - accuracy: 0.8523 - val_loss: 2.2343 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0877 - accuracy: 0.8523 - val_loss: 1.9891 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8572 - accuracy: 0.8523 - val_loss: 1.7776 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6613 - accuracy: 0.8523 - val_loss: 1.5947 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.4867 - accuracy: 0.8523 - val_loss: 1.4365 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.3425 - accuracy: 0.8523 - val_loss: 1.3000 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 1.2134 - accuracy: 0.8523 - val_loss: 1.1809 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 1.1056 - accuracy: 0.8523 - val_loss: 1.0780 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.0084 - accuracy: 0.8523 - val_loss: 0.9897 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.9225 - accuracy: 0.8523 - val_loss: 0.9133 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8538 - accuracy: 0.8523 - val_loss: 0.8482 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 16us/sample - loss: 0.7915 - accuracy: 0.8523 - val_loss: 0.7919 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.7399 - accuracy: 0.8523 - val_loss: 0.7432 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.6943 - accuracy: 0.8523 - val_loss: 0.7009 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.6548 - accuracy: 0.8523 - val_loss: 0.6640 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.6200 - accuracy: 0.8523 - val_loss: 0.6322 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.5909 - accuracy: 0.8523 - val_loss: 0.6049 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5646 - accuracy: 0.8523 - val_loss: 0.5811 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5453 - accuracy: 0.8523 - val_loss: 0.5604 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5220 - accuracy: 0.8523 - val_loss: 0.5429 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5082 - accuracy: 0.8523 - val_loss: 0.5283 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4928 - accuracy: 0.8523 - val_loss: 0.5156 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4777 - accuracy: 0.8523 - val_loss: 0.5046 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4723 - accuracy: 0.8523 - val_loss: 0.4952 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4647 - accuracy: 0.8523 - val_loss: 0.4877 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4548 - accuracy: 0.8523 - val_loss: 0.4813 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4507 - accuracy: 0.8523 - val_loss: 0.4760 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4451 - accuracy: 0.8523 - val_loss: 0.4714 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4410 - accuracy: 0.8523 - val_loss: 0.4679 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4393 - accuracy: 0.8523 - val_loss: 0.4647 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4323 - accuracy: 0.8523 - val_loss: 0.4619 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4329 - accuracy: 0.8523 - val_loss: 0.4604 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4294 - accuracy: 0.8523 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4285 - accuracy: 0.8523 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4284 - accuracy: 0.8523 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4257 - accuracy: 0.8523 - val_loss: 0.4551 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4288 - accuracy: 0.8523 - val_loss: 0.4544 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4251 - accuracy: 0.8523 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4253 - accuracy: 0.8523 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4241 - accuracy: 0.8523 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4258 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4238 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4260 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4180 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4237 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4235 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4247 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4258 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4244 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4261 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4239 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4186 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4236 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4181 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4181 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.79 - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4239 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4236 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4190 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.80 - 0s 19us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4244 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4234 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4227 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4190 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 257us/sample - loss: 0.4357 - accuracy: 0.8426\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 507us/sample - loss: 15.0250 - accuracy: 0.7458 - val_loss: 13.5523 - val_accuracy: 0.8400\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 12.5046 - accuracy: 0.8148 - val_loss: 11.3089 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 10.4425 - accuracy: 0.8380 - val_loss: 9.4879 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 8.7901 - accuracy: 0.8463 - val_loss: 8.0124 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 7.4376 - accuracy: 0.8486 - val_loss: 6.8138 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 6.3412 - accuracy: 0.8509 - val_loss: 5.8323 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.4374 - accuracy: 0.8505 - val_loss: 5.0253 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 4.6958 - accuracy: 0.8505 - val_loss: 4.3561 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.0718 - accuracy: 0.8505 - val_loss: 3.7976 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 3.5558 - accuracy: 0.8505 - val_loss: 3.3280 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 3.1197 - accuracy: 0.8505 - val_loss: 2.9296 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.7494 - accuracy: 0.8505 - val_loss: 2.5895 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 2.4263 - accuracy: 0.8505 - val_loss: 2.2978 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.1542 - accuracy: 0.8505 - val_loss: 2.0461 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 1.9196 - accuracy: 0.8505 - val_loss: 1.8278 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.7123 - accuracy: 0.8505 - val_loss: 1.6388 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.5380 - accuracy: 0.8505 - val_loss: 1.4739 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.3810 - accuracy: 0.8505 - val_loss: 1.3309 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.2479 - accuracy: 0.8505 - val_loss: 1.2059 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1298 - accuracy: 0.8505 - val_loss: 1.0976 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.0263 - accuracy: 0.8505 - val_loss: 1.0037 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.9403 - accuracy: 0.8505 - val_loss: 0.9223 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8655 - accuracy: 0.8505 - val_loss: 0.8521 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7954 - accuracy: 0.8505 - val_loss: 0.7911 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7430 - accuracy: 0.8505 - val_loss: 0.7390 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6906 - accuracy: 0.8505 - val_loss: 0.6939 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6496 - accuracy: 0.8505 - val_loss: 0.6556 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6141 - accuracy: 0.8505 - val_loss: 0.6229 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5857 - accuracy: 0.8505 - val_loss: 0.5949 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5565 - accuracy: 0.8505 - val_loss: 0.5714 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5349 - accuracy: 0.8505 - val_loss: 0.5513 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5205 - accuracy: 0.8505 - val_loss: 0.5344 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5001 - accuracy: 0.8505 - val_loss: 0.5203 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4873 - accuracy: 0.8505 - val_loss: 0.5082 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4756 - accuracy: 0.8505 - val_loss: 0.4981 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4665 - accuracy: 0.8505 - val_loss: 0.4901 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4652 - accuracy: 0.8505 - val_loss: 0.4829 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4526 - accuracy: 0.8505 - val_loss: 0.4771 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4503 - accuracy: 0.8505 - val_loss: 0.4726 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4421 - accuracy: 0.8505 - val_loss: 0.4685 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4388 - accuracy: 0.8505 - val_loss: 0.4653 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4362 - accuracy: 0.8505 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4339 - accuracy: 0.8505 - val_loss: 0.4605 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4330 - accuracy: 0.8505 - val_loss: 0.4586 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4332 - accuracy: 0.8505 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4301 - accuracy: 0.8505 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4289 - accuracy: 0.8505 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4287 - accuracy: 0.8505 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4297 - accuracy: 0.8505 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4277 - accuracy: 0.8505 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4270 - accuracy: 0.8505 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4259 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4266 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4298 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4263 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4263 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4262 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4272 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4272 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4261 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4270 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4229 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4268 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4196 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4265 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4210 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4219 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4219 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4219 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4220 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4226 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4213 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4259 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4220 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4273 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4229 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4226 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4260 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4208 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 287us/sample - loss: 0.4228 - accuracy: 0.8500\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 377us/sample - loss: 15.0636 - accuracy: 0.7917 - val_loss: 13.6954 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 12.6225 - accuracy: 0.8181 - val_loss: 11.4923 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 10.6107 - accuracy: 0.8389 - val_loss: 9.6906 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 8.9742 - accuracy: 0.8532 - val_loss: 8.2252 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 7.6346 - accuracy: 0.8574 - val_loss: 7.0245 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 6.5294 - accuracy: 0.8574 - val_loss: 6.0369 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.6234 - accuracy: 0.8583 - val_loss: 5.2187 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 4.8653 - accuracy: 0.8579 - val_loss: 4.5374 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.2352 - accuracy: 0.8583 - val_loss: 3.9669 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.7065 - accuracy: 0.8583 - val_loss: 3.4837 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 3.2544 - accuracy: 0.8583 - val_loss: 3.0722 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.8731 - accuracy: 0.8583 - val_loss: 2.7188 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 2.5391 - accuracy: 0.8583 - val_loss: 2.4134 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.2572 - accuracy: 0.8583 - val_loss: 2.1484 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0067 - accuracy: 0.8583 - val_loss: 1.9186 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.7906 - accuracy: 0.8583 - val_loss: 1.7191 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6022 - accuracy: 0.8583 - val_loss: 1.5457 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.4376 - accuracy: 0.8583 - val_loss: 1.3949 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.2935 - accuracy: 0.8583 - val_loss: 1.2636 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.1722 - accuracy: 0.8583 - val_loss: 1.1496 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0631 - accuracy: 0.8583 - val_loss: 1.0501 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.9680 - accuracy: 0.8583 - val_loss: 0.9640 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8906 - accuracy: 0.8583 - val_loss: 0.8889 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8220 - accuracy: 0.8583 - val_loss: 0.8238 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7585 - accuracy: 0.8583 - val_loss: 0.7675 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7050 - accuracy: 0.8583 - val_loss: 0.7191 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6608 - accuracy: 0.8583 - val_loss: 0.6772 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.6240 - accuracy: 0.8583 - val_loss: 0.6415 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5885 - accuracy: 0.8583 - val_loss: 0.6109 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5608 - accuracy: 0.8583 - val_loss: 0.5850 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5344 - accuracy: 0.8583 - val_loss: 0.5633 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5145 - accuracy: 0.8583 - val_loss: 0.5446 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4956 - accuracy: 0.8583 - val_loss: 0.5293 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4841 - accuracy: 0.8583 - val_loss: 0.5158 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4725 - accuracy: 0.8583 - val_loss: 0.5050 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4589 - accuracy: 0.8583 - val_loss: 0.4957 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4500 - accuracy: 0.8583 - val_loss: 0.4878 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4445 - accuracy: 0.8583 - val_loss: 0.4815 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4387 - accuracy: 0.8583 - val_loss: 0.4764 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4315 - accuracy: 0.8583 - val_loss: 0.4721 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4291 - accuracy: 0.8583 - val_loss: 0.4684 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4266 - accuracy: 0.8583 - val_loss: 0.4651 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4211 - accuracy: 0.8583 - val_loss: 0.4635 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4226 - accuracy: 0.8583 - val_loss: 0.4613 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4185 - accuracy: 0.8583 - val_loss: 0.4595 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4203 - accuracy: 0.8583 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4166 - accuracy: 0.8583 - val_loss: 0.4572 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4158 - accuracy: 0.8583 - val_loss: 0.4562 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4165 - accuracy: 0.8583 - val_loss: 0.4556 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4135 - accuracy: 0.8583 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4129 - accuracy: 0.8583 - val_loss: 0.4553 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4148 - accuracy: 0.8583 - val_loss: 0.4542 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4142 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4118 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4110 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4070 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4127 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4127 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4129 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4116 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4069 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4081 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4077 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4086 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4082 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4070 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4115 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4073 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4073 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4081 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 263us/sample - loss: 0.4794 - accuracy: 0.8185\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 383us/sample - loss: 14.9772 - accuracy: 0.7079 - val_loss: 13.5534 - val_accuracy: 0.8300\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 12.4370 - accuracy: 0.8056 - val_loss: 11.2793 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 10.3755 - accuracy: 0.8324 - val_loss: 9.4359 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 8.7051 - accuracy: 0.8454 - val_loss: 7.9431 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 7.3467 - accuracy: 0.8481 - val_loss: 6.7256 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 6.2426 - accuracy: 0.8477 - val_loss: 5.7284 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 5.3276 - accuracy: 0.8477 - val_loss: 4.9126 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 4.5820 - accuracy: 0.8477 - val_loss: 4.2439 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.9612 - accuracy: 0.8477 - val_loss: 3.6911 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 3.4473 - accuracy: 0.8477 - val_loss: 3.2288 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.0211 - accuracy: 0.8477 - val_loss: 2.8385 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.6589 - accuracy: 0.8477 - val_loss: 2.5070 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.3544 - accuracy: 0.8477 - val_loss: 2.2228 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0861 - accuracy: 0.8477 - val_loss: 1.9790 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8563 - accuracy: 0.8477 - val_loss: 1.7698 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.6601 - accuracy: 0.8477 - val_loss: 1.5886 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4955 - accuracy: 0.8477 - val_loss: 1.4321 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3467 - accuracy: 0.8477 - val_loss: 1.2973 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2212 - accuracy: 0.8477 - val_loss: 1.1789 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1099 - accuracy: 0.8477 - val_loss: 1.0771 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0128 - accuracy: 0.8477 - val_loss: 0.9892 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.9344 - accuracy: 0.8477 - val_loss: 0.9122 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8613 - accuracy: 0.8477 - val_loss: 0.8458 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7976 - accuracy: 0.8477 - val_loss: 0.7885 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7444 - accuracy: 0.8477 - val_loss: 0.7388 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6965 - accuracy: 0.8477 - val_loss: 0.6957 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6584 - accuracy: 0.8477 - val_loss: 0.6583 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6208 - accuracy: 0.8477 - val_loss: 0.6262 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5913 - accuracy: 0.8477 - val_loss: 0.5984 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5667 - accuracy: 0.8477 - val_loss: 0.5741 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5451 - accuracy: 0.8477 - val_loss: 0.5539 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5283 - accuracy: 0.8477 - val_loss: 0.5366 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5088 - accuracy: 0.8477 - val_loss: 0.5222 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4964 - accuracy: 0.8477 - val_loss: 0.5096 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4868 - accuracy: 0.8477 - val_loss: 0.4992 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4727 - accuracy: 0.8477 - val_loss: 0.4906 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4659 - accuracy: 0.8477 - val_loss: 0.4836 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.85 - 0s 19us/sample - loss: 0.4588 - accuracy: 0.8477 - val_loss: 0.4776 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4527 - accuracy: 0.8477 - val_loss: 0.4729 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4524 - accuracy: 0.8477 - val_loss: 0.4688 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4454 - accuracy: 0.8477 - val_loss: 0.4652 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4449 - accuracy: 0.8477 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4404 - accuracy: 0.8477 - val_loss: 0.4605 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4361 - accuracy: 0.8477 - val_loss: 0.4586 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4391 - accuracy: 0.8477 - val_loss: 0.4571 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4377 - accuracy: 0.8477 - val_loss: 0.4557 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4348 - accuracy: 0.8477 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4336 - accuracy: 0.8477 - val_loss: 0.4543 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4361 - accuracy: 0.8477 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4313 - accuracy: 0.8477 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4319 - accuracy: 0.8477 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4354 - accuracy: 0.8477 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4343 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4338 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4324 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4338 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4326 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4261 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.84 - 0s 20us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.82 - 0s 19us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4311 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4319 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4316 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4315 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4308 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4318 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4298 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.85 - 0s 18us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4326 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4311 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4287 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4269 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4328 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4305 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4269 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4255 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.88 - 0s 18us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4538 - accuracy: 0.83 - 0s 18us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4262 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4266 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4262 - accuracy: 0.8477 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4315 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4311 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.89 - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4298 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4265 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4253 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4267 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 270us/sample - loss: 0.4038 - accuracy: 0.8611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 505us/sample - loss: 14.5987 - accuracy: 0.5204 - val_loss: 13.1263 - val_accuracy: 0.7733\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 12.0911 - accuracy: 0.6833 - val_loss: 10.9235 - val_accuracy: 0.8300\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 10.0889 - accuracy: 0.7782 - val_loss: 9.1551 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 8.4805 - accuracy: 0.8287 - val_loss: 7.7336 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 7.1832 - accuracy: 0.8370 - val_loss: 6.5813 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 6.1328 - accuracy: 0.8426 - val_loss: 5.6400 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.2645 - accuracy: 0.8431 - val_loss: 4.8651 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.5543 - accuracy: 0.8431 - val_loss: 4.2210 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 3.9597 - accuracy: 0.8431 - val_loss: 3.6819 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.4562 - accuracy: 0.8431 - val_loss: 3.2276 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.0384 - accuracy: 0.8431 - val_loss: 2.8420 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.6764 - accuracy: 0.8431 - val_loss: 2.5126 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.3686 - accuracy: 0.8431 - val_loss: 2.2298 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.1086 - accuracy: 0.8431 - val_loss: 1.9857 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.8750 - accuracy: 0.8431 - val_loss: 1.7744 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.6773 - accuracy: 0.8431 - val_loss: 1.5911 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.5033 - accuracy: 0.8431 - val_loss: 1.4321 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3564 - accuracy: 0.8431 - val_loss: 1.2942 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2254 - accuracy: 0.8431 - val_loss: 1.1743 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.1118 - accuracy: 0.8431 - val_loss: 1.0703 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0137 - accuracy: 0.8431 - val_loss: 0.9801 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9312 - accuracy: 0.8431 - val_loss: 0.9021 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.8561 - accuracy: 0.8431 - val_loss: 0.8347 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7957 - accuracy: 0.8431 - val_loss: 0.7766 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7419 - accuracy: 0.8431 - val_loss: 0.7266 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6961 - accuracy: 0.8431 - val_loss: 0.6837 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6546 - accuracy: 0.8431 - val_loss: 0.6470 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6194 - accuracy: 0.8431 - val_loss: 0.6157 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5909 - accuracy: 0.8431 - val_loss: 0.5890 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5677 - accuracy: 0.8431 - val_loss: 0.5664 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5459 - accuracy: 0.8431 - val_loss: 0.5471 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5276 - accuracy: 0.8431 - val_loss: 0.5309 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.5119 - accuracy: 0.8431 - val_loss: 0.5173 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4993 - accuracy: 0.8431 - val_loss: 0.5057 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4897 - accuracy: 0.8431 - val_loss: 0.4961 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4802 - accuracy: 0.8431 - val_loss: 0.4881 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4706 - accuracy: 0.8431 - val_loss: 0.4814 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4670 - accuracy: 0.8431 - val_loss: 0.4758 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4634 - accuracy: 0.8431 - val_loss: 0.4711 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4584 - accuracy: 0.8431 - val_loss: 0.4673 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4560 - accuracy: 0.8431 - val_loss: 0.4641 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4517 - accuracy: 0.8431 - val_loss: 0.4616 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4460 - accuracy: 0.8431 - val_loss: 0.4595 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4468 - accuracy: 0.8431 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4457 - accuracy: 0.8431 - val_loss: 0.4564 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4434 - accuracy: 0.8431 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4446 - accuracy: 0.8431 - val_loss: 0.4543 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4428 - accuracy: 0.8431 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4416 - accuracy: 0.8431 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4397 - accuracy: 0.8431 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4390 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4386 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4390 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4391 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4404 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4386 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4394 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4401 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4407 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4394 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4391 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4371 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4393 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4386 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4400 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4398 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4347 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4396 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.85 - 0s 19us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4394 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4389 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4383 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.81 - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.80 - 0s 18us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4393 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.84 - 0s 18us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4386 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4371 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 276us/sample - loss: 0.3737 - accuracy: 0.8796\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 425us/sample - loss: 27.9517 - accuracy: 0.6722 - val_loss: 24.7657 - val_accuracy: 0.8200\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 22.3805 - accuracy: 0.8190 - val_loss: 19.8313 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 17.9098 - accuracy: 0.8523 - val_loss: 15.8834 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 14.3585 - accuracy: 0.8481 - val_loss: 12.7514 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 11.5335 - accuracy: 0.8532 - val_loss: 10.2679 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 9.3007 - accuracy: 0.8523 - val_loss: 8.2979 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 7.5204 - accuracy: 0.8523 - val_loss: 6.7322 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 6.1065 - accuracy: 0.8523 - val_loss: 5.4855 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 4.9787 - accuracy: 0.8523 - val_loss: 4.4900 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.0763 - accuracy: 0.8523 - val_loss: 3.6922 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.3555 - accuracy: 0.8523 - val_loss: 3.0510 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.7733 - accuracy: 0.8523 - val_loss: 2.5352 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.3050 - accuracy: 0.8523 - val_loss: 2.1191 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.9293 - accuracy: 0.8523 - val_loss: 1.7831 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6223 - accuracy: 0.8523 - val_loss: 1.5114 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3760 - accuracy: 0.8523 - val_loss: 1.2929 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1802 - accuracy: 0.8523 - val_loss: 1.1166 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0179 - accuracy: 0.8523 - val_loss: 0.9752 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8921 - accuracy: 0.8523 - val_loss: 0.8622 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7922 - accuracy: 0.8523 - val_loss: 0.7722 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7061 - accuracy: 0.8523 - val_loss: 0.7007 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6418 - accuracy: 0.8523 - val_loss: 0.6442 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5915 - accuracy: 0.8523 - val_loss: 0.5998 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5518 - accuracy: 0.8523 - val_loss: 0.5655 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5245 - accuracy: 0.8523 - val_loss: 0.5383 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4968 - accuracy: 0.8523 - val_loss: 0.5173 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4799 - accuracy: 0.8523 - val_loss: 0.5014 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4646 - accuracy: 0.8523 - val_loss: 0.4890 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4545 - accuracy: 0.8523 - val_loss: 0.4794 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4464 - accuracy: 0.8523 - val_loss: 0.4727 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4391 - accuracy: 0.8523 - val_loss: 0.4672 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4340 - accuracy: 0.8523 - val_loss: 0.4633 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4328 - accuracy: 0.8523 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4282 - accuracy: 0.8523 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4250 - accuracy: 0.8523 - val_loss: 0.4561 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4238 - accuracy: 0.8523 - val_loss: 0.4554 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4540 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4248 - accuracy: 0.8523 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4235 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4184 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4179 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4227 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4186 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4187 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4181 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4166 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4194 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4229 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4189 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4193 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.82 - 0s 21us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4197 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4188 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.85 - 0s 21us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4194 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4175 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4197 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.83 - 0s 21us/sample - loss: 0.4184 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4178 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4184 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4201 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4190 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4197 - accuracy: 0.8523 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4193 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4188 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 29us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 28us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4189 - accuracy: 0.8523 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4193 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4182 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 28us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 28us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 29us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4193 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 28us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4185 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4182 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4187 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4176 - accuracy: 0.8523 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4189 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4185 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 296us/sample - loss: 0.4357 - accuracy: 0.8426\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 376us/sample - loss: 27.8341 - accuracy: 0.7079 - val_loss: 24.6343 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 28us/sample - loss: 22.2562 - accuracy: 0.8171 - val_loss: 19.7002 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 17.7891 - accuracy: 0.8407 - val_loss: 15.7692 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 14.2477 - accuracy: 0.8472 - val_loss: 12.6572 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 11.4521 - accuracy: 0.8505 - val_loss: 10.1903 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 9.2250 - accuracy: 0.8505 - val_loss: 8.2342 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 7.4649 - accuracy: 0.8505 - val_loss: 6.6821 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 6.0635 - accuracy: 0.8505 - val_loss: 5.4463 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 4.9490 - accuracy: 0.8505 - val_loss: 4.4601 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.0525 - accuracy: 0.8505 - val_loss: 3.6711 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.3393 - accuracy: 0.8505 - val_loss: 3.0369 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.7630 - accuracy: 0.8505 - val_loss: 2.5261 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.3011 - accuracy: 0.8505 - val_loss: 2.1138 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.9306 - accuracy: 0.8505 - val_loss: 1.7805 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6232 - accuracy: 0.8505 - val_loss: 1.5116 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3783 - accuracy: 0.8505 - val_loss: 1.2944 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1839 - accuracy: 0.8505 - val_loss: 1.1193 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0242 - accuracy: 0.8505 - val_loss: 0.9782 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8955 - accuracy: 0.8505 - val_loss: 0.8651 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7941 - accuracy: 0.8505 - val_loss: 0.7754 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7150 - accuracy: 0.8505 - val_loss: 0.7033 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6471 - accuracy: 0.8505 - val_loss: 0.6468 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5994 - accuracy: 0.8505 - val_loss: 0.6020 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5560 - accuracy: 0.8505 - val_loss: 0.5669 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.5260 - accuracy: 0.8505 - val_loss: 0.5399 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4995 - accuracy: 0.8505 - val_loss: 0.5186 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4823 - accuracy: 0.8505 - val_loss: 0.5019 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4677 - accuracy: 0.8505 - val_loss: 0.4895 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4571 - accuracy: 0.8505 - val_loss: 0.4803 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4494 - accuracy: 0.8505 - val_loss: 0.4728 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4427 - accuracy: 0.8505 - val_loss: 0.4668 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4389 - accuracy: 0.8505 - val_loss: 0.4633 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4333 - accuracy: 0.8505 - val_loss: 0.4603 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4319 - accuracy: 0.8505 - val_loss: 0.4576 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8505 - val_loss: 0.4559 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4284 - accuracy: 0.8505 - val_loss: 0.4549 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4287 - accuracy: 0.8505 - val_loss: 0.4537 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4275 - accuracy: 0.8505 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4273 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4214 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4258 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4258 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4260 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4218 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4220 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4229 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4216 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4212 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4219 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.87 - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4221 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4220 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4216 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.88 - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4260 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4221 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4260 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4229 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4229 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4214 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4205 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4216 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4221 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4250 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4219 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4213 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 270us/sample - loss: 0.4228 - accuracy: 0.8500\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 528us/sample - loss: 27.8875 - accuracy: 0.4458 - val_loss: 24.6324 - val_accuracy: 0.7700\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 22.2459 - accuracy: 0.7356 - val_loss: 19.6943 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 17.7759 - accuracy: 0.8310 - val_loss: 15.7559 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 14.2240 - accuracy: 0.8574 - val_loss: 12.6360 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 11.4211 - accuracy: 0.8574 - val_loss: 10.1622 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 9.1923 - accuracy: 0.8583 - val_loss: 8.1986 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 7.4206 - accuracy: 0.8583 - val_loss: 6.6375 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 6.0103 - accuracy: 0.8583 - val_loss: 5.3957 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 4.8861 - accuracy: 0.8583 - val_loss: 4.4080 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.9929 - accuracy: 0.8583 - val_loss: 3.6212 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.2805 - accuracy: 0.8583 - val_loss: 2.9923 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.7104 - accuracy: 0.8583 - val_loss: 2.4881 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.2534 - accuracy: 0.8583 - val_loss: 2.0829 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.8846 - accuracy: 0.8583 - val_loss: 1.7560 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.5876 - accuracy: 0.8583 - val_loss: 1.4921 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.3485 - accuracy: 0.8583 - val_loss: 1.2798 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1528 - accuracy: 0.8583 - val_loss: 1.1085 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.0021 - accuracy: 0.8583 - val_loss: 0.9708 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8751 - accuracy: 0.8583 - val_loss: 0.8605 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7760 - accuracy: 0.8583 - val_loss: 0.7724 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.6967 - accuracy: 0.8583 - val_loss: 0.7022 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6355 - accuracy: 0.8583 - val_loss: 0.6467 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.5824 - accuracy: 0.8583 - val_loss: 0.6035 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5437 - accuracy: 0.8583 - val_loss: 0.5684 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5146 - accuracy: 0.8583 - val_loss: 0.5414 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4878 - accuracy: 0.8583 - val_loss: 0.5210 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4702 - accuracy: 0.8583 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4565 - accuracy: 0.8583 - val_loss: 0.4921 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4457 - accuracy: 0.8583 - val_loss: 0.4825 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4394 - accuracy: 0.8583 - val_loss: 0.4747 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4310 - accuracy: 0.8583 - val_loss: 0.4696 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4249 - accuracy: 0.8583 - val_loss: 0.4651 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4203 - accuracy: 0.8583 - val_loss: 0.4621 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4168 - accuracy: 0.8583 - val_loss: 0.4597 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4170 - accuracy: 0.8583 - val_loss: 0.4579 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4149 - accuracy: 0.8583 - val_loss: 0.4567 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4123 - accuracy: 0.8583 - val_loss: 0.4550 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4145 - accuracy: 0.8583 - val_loss: 0.4548 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4544 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4118 - accuracy: 0.8583 - val_loss: 0.4537 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4143 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4079 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4115 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4080 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4116 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4123 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4082 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4070 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4116 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4076 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4138 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4081 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4074 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4115 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4115 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4086 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4125 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.85 - 0s 21us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4075 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4537 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.79 - 0s 22us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.87 - 0s 22us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4082 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4080 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4081 - accuracy: 0.8583 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 269us/sample - loss: 0.4795 - accuracy: 0.8185\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 369us/sample - loss: 28.1058 - accuracy: 0.7861 - val_loss: 24.9358 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 28us/sample - loss: 22.5490 - accuracy: 0.8306 - val_loss: 19.9744 - val_accuracy: 0.8367\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 18.0659 - accuracy: 0.8407 - val_loss: 16.0060 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 14.4772 - accuracy: 0.8440 - val_loss: 12.8553 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 11.6372 - accuracy: 0.8458 - val_loss: 10.3587 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 9.3937 - accuracy: 0.8477 - val_loss: 8.3781 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 7.6012 - accuracy: 0.8477 - val_loss: 6.8014 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 6.1747 - accuracy: 0.8477 - val_loss: 5.5430 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 5.0345 - accuracy: 0.8477 - val_loss: 4.5370 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 4.1252 - accuracy: 0.8477 - val_loss: 3.7302 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.3933 - accuracy: 0.8477 - val_loss: 3.0819 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.8080 - accuracy: 0.8477 - val_loss: 2.5591 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.3326 - accuracy: 0.8477 - val_loss: 2.1380 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.9533 - accuracy: 0.8477 - val_loss: 1.7999 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.6448 - accuracy: 0.8477 - val_loss: 1.5273 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4013 - accuracy: 0.8477 - val_loss: 1.3080 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.2005 - accuracy: 0.8477 - val_loss: 1.1309 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 1.0421 - accuracy: 0.8477 - val_loss: 0.9880 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9120 - accuracy: 0.8477 - val_loss: 0.8739 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8087 - accuracy: 0.8477 - val_loss: 0.7816 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7246 - accuracy: 0.8477 - val_loss: 0.7084 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6582 - accuracy: 0.8477 - val_loss: 0.6503 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6071 - accuracy: 0.8477 - val_loss: 0.6045 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5639 - accuracy: 0.8477 - val_loss: 0.5696 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5325 - accuracy: 0.8477 - val_loss: 0.5407 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5072 - accuracy: 0.8477 - val_loss: 0.5192 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4877 - accuracy: 0.8477 - val_loss: 0.5023 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4747 - accuracy: 0.8477 - val_loss: 0.4897 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4638 - accuracy: 0.8477 - val_loss: 0.4798 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4537 - accuracy: 0.8477 - val_loss: 0.4724 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4478 - accuracy: 0.8477 - val_loss: 0.4667 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4427 - accuracy: 0.8477 - val_loss: 0.4629 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4387 - accuracy: 0.8477 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4361 - accuracy: 0.8477 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4362 - accuracy: 0.8477 - val_loss: 0.4553 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4348 - accuracy: 0.8477 - val_loss: 0.4544 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4320 - accuracy: 0.8477 - val_loss: 0.4538 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4273 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4300 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4298 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4318 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4263 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4320 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4287 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4265 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4263 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4263 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4267 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4262 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4265 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4273 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.88 - 0s 22us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4265 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4267 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.87 - 0s 21us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4273 - accuracy: 0.8477 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4273 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4269 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4305 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4273 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4305 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4266 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4265 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.85 - 0s 22us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4268 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 260us/sample - loss: 0.4037 - accuracy: 0.8611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 374us/sample - loss: 28.2345 - accuracy: 0.7435 - val_loss: 25.0087 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 22.5954 - accuracy: 0.8319 - val_loss: 20.0100 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 18.0803 - accuracy: 0.8375 - val_loss: 16.0227 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 14.4859 - accuracy: 0.8431 - val_loss: 12.8609 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 11.6411 - accuracy: 0.8435 - val_loss: 10.3529 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 9.3821 - accuracy: 0.8431 - val_loss: 8.3598 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 7.5859 - accuracy: 0.8431 - val_loss: 6.7740 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 6.1533 - accuracy: 0.8431 - val_loss: 5.5091 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 5.0098 - accuracy: 0.8431 - val_loss: 4.4991 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 4.0966 - accuracy: 0.8431 - val_loss: 3.6917 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.3669 - accuracy: 0.8431 - val_loss: 3.0446 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.7815 - accuracy: 0.8431 - val_loss: 2.5254 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.3131 - accuracy: 0.8431 - val_loss: 2.1077 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.9290 - accuracy: 0.8431 - val_loss: 1.7716 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6282 - accuracy: 0.8431 - val_loss: 1.5006 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.3809 - accuracy: 0.8431 - val_loss: 1.2827 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.1837 - accuracy: 0.8431 - val_loss: 1.1076 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.0264 - accuracy: 0.8431 - val_loss: 0.9673 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.8996 - accuracy: 0.8431 - val_loss: 0.8554 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7970 - accuracy: 0.8431 - val_loss: 0.7662 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7196 - accuracy: 0.8431 - val_loss: 0.6954 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6552 - accuracy: 0.8431 - val_loss: 0.6399 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6044 - accuracy: 0.8431 - val_loss: 0.5963 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5652 - accuracy: 0.8431 - val_loss: 0.5619 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5346 - accuracy: 0.8431 - val_loss: 0.5354 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.5106 - accuracy: 0.8431 - val_loss: 0.5149 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4938 - accuracy: 0.8431 - val_loss: 0.4992 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4784 - accuracy: 0.8431 - val_loss: 0.4871 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4698 - accuracy: 0.8431 - val_loss: 0.4780 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4589 - accuracy: 0.8431 - val_loss: 0.4707 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4533 - accuracy: 0.8431 - val_loss: 0.4658 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4499 - accuracy: 0.8431 - val_loss: 0.4616 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4467 - accuracy: 0.8431 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4455 - accuracy: 0.8431 - val_loss: 0.4566 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4427 - accuracy: 0.8431 - val_loss: 0.4549 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4538 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4413 - accuracy: 0.8431 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4383 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4383 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4341 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4396 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4371 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.85 - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4344 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.85 - 0s 21us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4336 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4341 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4348 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4336 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4327 - accuracy: 0.8431 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 266us/sample - loss: 0.3736 - accuracy: 0.8796\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 377us/sample - loss: 15.4245 - accuracy: 0.6602 - val_loss: 13.8139 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 12.9664 - accuracy: 0.6968 - val_loss: 11.6956 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 10.9611 - accuracy: 0.7579 - val_loss: 9.9298 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 9.2879 - accuracy: 0.7907 - val_loss: 8.4710 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 7.9144 - accuracy: 0.8106 - val_loss: 7.2653 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 6.7977 - accuracy: 0.8324 - val_loss: 6.2597 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.8584 - accuracy: 0.8412 - val_loss: 5.4186 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 5.0825 - accuracy: 0.8440 - val_loss: 4.7117 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 4.4234 - accuracy: 0.8491 - val_loss: 4.1160 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 3.8652 - accuracy: 0.8514 - val_loss: 3.6118 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.3979 - accuracy: 0.8523 - val_loss: 3.1823 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.9942 - accuracy: 0.8523 - val_loss: 2.8149 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.6514 - accuracy: 0.8523 - val_loss: 2.4990 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.3549 - accuracy: 0.8523 - val_loss: 2.2255 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0974 - accuracy: 0.8523 - val_loss: 1.9885 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.8680 - accuracy: 0.8523 - val_loss: 1.7824 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.6755 - accuracy: 0.8523 - val_loss: 1.6026 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.5062 - accuracy: 0.8523 - val_loss: 1.4456 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3561 - accuracy: 0.8523 - val_loss: 1.3086 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2244 - accuracy: 0.8523 - val_loss: 1.1891 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1158 - accuracy: 0.8523 - val_loss: 1.0849 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0166 - accuracy: 0.8523 - val_loss: 0.9943 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.9357 - accuracy: 0.8523 - val_loss: 0.9158 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8582 - accuracy: 0.8523 - val_loss: 0.8479 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8000 - accuracy: 0.8523 - val_loss: 0.7889 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7450 - accuracy: 0.8523 - val_loss: 0.7379 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6952 - accuracy: 0.8523 - val_loss: 0.6940 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6505 - accuracy: 0.8523 - val_loss: 0.6566 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6184 - accuracy: 0.8523 - val_loss: 0.6245 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5926 - accuracy: 0.8523 - val_loss: 0.5968 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5625 - accuracy: 0.8523 - val_loss: 0.5735 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5410 - accuracy: 0.8523 - val_loss: 0.5535 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5242 - accuracy: 0.8523 - val_loss: 0.5367 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5063 - accuracy: 0.8523 - val_loss: 0.5224 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4927 - accuracy: 0.8523 - val_loss: 0.5105 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4831 - accuracy: 0.8523 - val_loss: 0.5003 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4743 - accuracy: 0.8523 - val_loss: 0.4917 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4634 - accuracy: 0.8523 - val_loss: 0.4846 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4572 - accuracy: 0.8523 - val_loss: 0.4788 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4552 - accuracy: 0.8523 - val_loss: 0.4739 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4485 - accuracy: 0.8523 - val_loss: 0.4698 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4478 - accuracy: 0.8523 - val_loss: 0.4663 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4429 - accuracy: 0.8523 - val_loss: 0.4636 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4298 - accuracy: 0.8523 - val_loss: 0.4614 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4398 - accuracy: 0.8523 - val_loss: 0.4595 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4332 - accuracy: 0.8523 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8523 - val_loss: 0.4566 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4350 - accuracy: 0.8523 - val_loss: 0.4554 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4340 - accuracy: 0.8523 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4317 - accuracy: 0.8523 - val_loss: 0.4538 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4305 - accuracy: 0.8523 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4280 - accuracy: 0.8523 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4306 - accuracy: 0.8523 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4267 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4298 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4303 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4292 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4297 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4303 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4271 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4268 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4280 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4274 - accuracy: 0.8523 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4287 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4234 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4248 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4253 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4247 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4269 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4244 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4263 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4284 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4256 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4255 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4255 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4246 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4233 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4284 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4274 - accuracy: 0.8523 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4267 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4245 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4246 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4235 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4248 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4244 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4265 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4234 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4257 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4187 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4236 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.89 - 0s 19us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4194 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4238 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.83 - 0s 18us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.84 - 0s 19us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4239 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4199 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4253 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.83 - 0s 19us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4194 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 17us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4169 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4206 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4187 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4181 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4189 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 62us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4187 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4183 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4185 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4193 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4197 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4190 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 269us/sample - loss: 0.4356 - accuracy: 0.8426\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 376us/sample - loss: 16.7500 - accuracy: 0.3653 - val_loss: 14.4449 - val_accuracy: 0.2533\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 14.0564 - accuracy: 0.4875 - val_loss: 12.3601 - val_accuracy: 0.5433\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 11.8537 - accuracy: 0.5773 - val_loss: 10.6351 - val_accuracy: 0.7767\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 10.1279 - accuracy: 0.6458 - val_loss: 9.1765 - val_accuracy: 0.8233\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 8.7024 - accuracy: 0.7093 - val_loss: 7.9353 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 7.4872 - accuracy: 0.7593 - val_loss: 6.8808 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 6.5039 - accuracy: 0.7819 - val_loss: 5.9816 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 5.6416 - accuracy: 0.8051 - val_loss: 5.2156 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.9191 - accuracy: 0.8241 - val_loss: 4.5650 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 4.3089 - accuracy: 0.8389 - val_loss: 4.0089 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 3.7907 - accuracy: 0.8463 - val_loss: 3.5356 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.3465 - accuracy: 0.8435 - val_loss: 3.1311 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.9611 - accuracy: 0.8491 - val_loss: 2.7831 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.6382 - accuracy: 0.8477 - val_loss: 2.4841 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.3575 - accuracy: 0.8500 - val_loss: 2.2254 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 2.1097 - accuracy: 0.8509 - val_loss: 2.0011 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.9003 - accuracy: 0.8505 - val_loss: 1.8064 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.7125 - accuracy: 0.8505 - val_loss: 1.6362 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.5603 - accuracy: 0.8505 - val_loss: 1.4875 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.4177 - accuracy: 0.8505 - val_loss: 1.3573 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2893 - accuracy: 0.8505 - val_loss: 1.2430 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.1881 - accuracy: 0.8509 - val_loss: 1.1431 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0957 - accuracy: 0.8505 - val_loss: 1.0554 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0037 - accuracy: 0.8505 - val_loss: 0.9783 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9353 - accuracy: 0.8505 - val_loss: 0.9109 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8778 - accuracy: 0.8505 - val_loss: 0.8518 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8110 - accuracy: 0.8505 - val_loss: 0.8000 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.7659 - accuracy: 0.8505 - val_loss: 0.7546 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.7182 - accuracy: 0.8505 - val_loss: 0.7150 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6890 - accuracy: 0.8505 - val_loss: 0.6804 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6525 - accuracy: 0.8505 - val_loss: 0.6503 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6246 - accuracy: 0.8505 - val_loss: 0.6240 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5995 - accuracy: 0.8505 - val_loss: 0.6011 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5783 - accuracy: 0.8505 - val_loss: 0.5812 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5614 - accuracy: 0.8505 - val_loss: 0.5639 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5450 - accuracy: 0.8505 - val_loss: 0.5489 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5290 - accuracy: 0.8505 - val_loss: 0.5359 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5082 - accuracy: 0.8505 - val_loss: 0.5246 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5076 - accuracy: 0.8505 - val_loss: 0.5148 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4979 - accuracy: 0.8505 - val_loss: 0.5063 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4865 - accuracy: 0.8505 - val_loss: 0.4990 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4781 - accuracy: 0.8505 - val_loss: 0.4927 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4747 - accuracy: 0.8505 - val_loss: 0.4871 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4712 - accuracy: 0.8505 - val_loss: 0.4824 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4660 - accuracy: 0.8505 - val_loss: 0.4783 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4609 - accuracy: 0.8505 - val_loss: 0.4747 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4556 - accuracy: 0.8505 - val_loss: 0.4716 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4517 - accuracy: 0.8505 - val_loss: 0.4689 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4519 - accuracy: 0.8505 - val_loss: 0.4666 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4480 - accuracy: 0.8505 - val_loss: 0.4646 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4507 - accuracy: 0.8505 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4401 - accuracy: 0.8505 - val_loss: 0.4613 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4502 - accuracy: 0.8505 - val_loss: 0.4600 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4412 - accuracy: 0.8505 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4417 - accuracy: 0.8505 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4403 - accuracy: 0.8505 - val_loss: 0.4570 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4375 - accuracy: 0.8505 - val_loss: 0.4561 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4470 - accuracy: 0.8505 - val_loss: 0.4554 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4401 - accuracy: 0.8505 - val_loss: 0.4548 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4337 - accuracy: 0.8505 - val_loss: 0.4544 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4337 - accuracy: 0.8505 - val_loss: 0.4540 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4328 - accuracy: 0.8505 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4314 - accuracy: 0.8505 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4323 - accuracy: 0.8505 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4311 - accuracy: 0.8505 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4304 - accuracy: 0.8505 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4335 - accuracy: 0.8505 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4339 - accuracy: 0.8505 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4296 - accuracy: 0.8505 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4356 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4322 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4314 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4332 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4384 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4306 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4286 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4333 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4330 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4320 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4316 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4355 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4278 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4287 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4309 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4298 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4300 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.88 - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4309 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4270 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4269 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4297 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4299 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4269 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4299 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4309 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.80 - 0s 18us/sample - loss: 0.4337 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4302 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4281 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4277 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4326 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4266 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4306 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4277 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4283 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4310 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4324 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.78 - 0s 19us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4266 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4278 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4272 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4277 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5510 - accuracy: 0.77 - 0s 18us/sample - loss: 0.4274 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4283 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4287 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4285 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4273 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.88 - 0s 18us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4284 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4263 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4301 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4266 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4258 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4276 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8505 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4293 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4250 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4250 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4221 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4218 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4288 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4229 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.89 - 0s 18us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4277 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4212 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4221 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4218 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4233 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4210 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 295us/sample - loss: 0.4227 - accuracy: 0.8500\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 381us/sample - loss: 15.3167 - accuracy: 0.7574 - val_loss: 13.8574 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 12.8709 - accuracy: 0.8028 - val_loss: 11.7242 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 10.8718 - accuracy: 0.8282 - val_loss: 9.9357 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 9.2331 - accuracy: 0.8366 - val_loss: 8.4515 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 7.8774 - accuracy: 0.8472 - val_loss: 7.2236 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 6.7223 - accuracy: 0.8523 - val_loss: 6.2056 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.7864 - accuracy: 0.8565 - val_loss: 5.3584 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 5.0108 - accuracy: 0.8579 - val_loss: 4.6507 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 4.3481 - accuracy: 0.8579 - val_loss: 4.0593 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.8040 - accuracy: 0.8583 - val_loss: 3.5604 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.3398 - accuracy: 0.8583 - val_loss: 3.1372 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 2.9433 - accuracy: 0.8583 - val_loss: 2.7761 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 2.6081 - accuracy: 0.8583 - val_loss: 2.4654 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 2.3090 - accuracy: 0.8583 - val_loss: 2.1975 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 2.0575 - accuracy: 0.8583 - val_loss: 1.9650 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.8381 - accuracy: 0.8583 - val_loss: 1.7628 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.6458 - accuracy: 0.8583 - val_loss: 1.5865 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.4792 - accuracy: 0.8583 - val_loss: 1.4327 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3397 - accuracy: 0.8583 - val_loss: 1.2984 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2092 - accuracy: 0.8583 - val_loss: 1.1809 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1047 - accuracy: 0.8583 - val_loss: 1.0787 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.0048 - accuracy: 0.8583 - val_loss: 0.9897 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9201 - accuracy: 0.8583 - val_loss: 0.9123 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8469 - accuracy: 0.8583 - val_loss: 0.8448 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.9176 - accuracy: 0.80 - 0s 20us/sample - loss: 0.7881 - accuracy: 0.8583 - val_loss: 0.7868 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7314 - accuracy: 0.8583 - val_loss: 0.7366 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6844 - accuracy: 0.8583 - val_loss: 0.6934 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6426 - accuracy: 0.8583 - val_loss: 0.6560 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6064 - accuracy: 0.8583 - val_loss: 0.6244 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5743 - accuracy: 0.8583 - val_loss: 0.5974 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5571 - accuracy: 0.8583 - val_loss: 0.5739 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5350 - accuracy: 0.8583 - val_loss: 0.5539 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5088 - accuracy: 0.8583 - val_loss: 0.5370 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4980 - accuracy: 0.8583 - val_loss: 0.5233 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4848 - accuracy: 0.8583 - val_loss: 0.5112 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4738 - accuracy: 0.8583 - val_loss: 0.5011 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4619 - accuracy: 0.8583 - val_loss: 0.4926 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4526 - accuracy: 0.8583 - val_loss: 0.4854 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4415 - accuracy: 0.8583 - val_loss: 0.4797 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4426 - accuracy: 0.8583 - val_loss: 0.4752 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4323 - accuracy: 0.8583 - val_loss: 0.4707 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8583 - val_loss: 0.4673 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4312 - accuracy: 0.8583 - val_loss: 0.4646 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8583 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4257 - accuracy: 0.8583 - val_loss: 0.4602 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4293 - accuracy: 0.8583 - val_loss: 0.4583 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8583 - val_loss: 0.4569 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4215 - accuracy: 0.8583 - val_loss: 0.4561 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4216 - accuracy: 0.8583 - val_loss: 0.4553 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4197 - accuracy: 0.8583 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4181 - accuracy: 0.8583 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4151 - accuracy: 0.8583 - val_loss: 0.4538 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4204 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4201 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4163 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4179 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4153 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4170 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4190 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4153 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4162 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4188 - accuracy: 0.8583 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4166 - accuracy: 0.8583 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4110 - accuracy: 0.8583 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4178 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4190 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4517 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4181 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4190 - accuracy: 0.8583 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4142 - accuracy: 0.8583 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4129 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4137 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4149 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4133 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4181 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4129 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4154 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4145 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4177 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4134 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4127 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4148 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4180 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4141 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4127 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4148 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4134 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.85 - 0s 19us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4139 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4159 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4145 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4146 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.86 - 0s 18us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4120 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4079 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4116 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4144 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4120 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4076 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4129 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4120 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4127 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.83 - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4122 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4116 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4110 - accuracy: 0.8583 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.79 - 0s 18us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4110 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.82 - 0s 18us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.88 - 0s 18us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4090 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4080 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4078 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4096 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.85 - 0s 18us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 275us/sample - loss: 0.4783 - accuracy: 0.8185\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 390us/sample - loss: 15.2086 - accuracy: 0.6236 - val_loss: 13.5167 - val_accuracy: 0.8133\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 12.7583 - accuracy: 0.6745 - val_loss: 11.4747 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 10.7610 - accuracy: 0.7306 - val_loss: 9.7637 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 9.1174 - accuracy: 0.7574 - val_loss: 8.3363 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 7.7764 - accuracy: 0.7875 - val_loss: 7.1478 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 6.6816 - accuracy: 0.8088 - val_loss: 6.1547 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 5.7598 - accuracy: 0.8282 - val_loss: 5.3221 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 4.9924 - accuracy: 0.8380 - val_loss: 4.6228 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 4.3431 - accuracy: 0.8444 - val_loss: 4.0325 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.7960 - accuracy: 0.8444 - val_loss: 3.5338 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.3256 - accuracy: 0.8477 - val_loss: 3.1108 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.9305 - accuracy: 0.8477 - val_loss: 2.7507 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.5889 - accuracy: 0.8477 - val_loss: 2.4414 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.3075 - accuracy: 0.8477 - val_loss: 2.1753 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0541 - accuracy: 0.8477 - val_loss: 1.9446 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8377 - accuracy: 0.8477 - val_loss: 1.7445 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 1.6476 - accuracy: 0.8477 - val_loss: 1.5703 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 1.4867 - accuracy: 0.8477 - val_loss: 1.4183 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3468 - accuracy: 0.8477 - val_loss: 1.2857 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.2103 - accuracy: 0.8477 - val_loss: 1.1703 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.1077 - accuracy: 0.8477 - val_loss: 1.0697 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0153 - accuracy: 0.8477 - val_loss: 0.9822 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.9308 - accuracy: 0.8477 - val_loss: 0.9062 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8671 - accuracy: 0.8477 - val_loss: 0.8402 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8011 - accuracy: 0.8477 - val_loss: 0.7832 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7463 - accuracy: 0.8477 - val_loss: 0.7339 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7075 - accuracy: 0.8477 - val_loss: 0.6914 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6591 - accuracy: 0.8477 - val_loss: 0.6549 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.6303 - accuracy: 0.8477 - val_loss: 0.6235 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.5995 - accuracy: 0.8477 - val_loss: 0.5967 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.5727 - accuracy: 0.8477 - val_loss: 0.5738 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5510 - accuracy: 0.8477 - val_loss: 0.5542 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5338 - accuracy: 0.8477 - val_loss: 0.5376 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5238 - accuracy: 0.8477 - val_loss: 0.5235 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5062 - accuracy: 0.8477 - val_loss: 0.5115 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4948 - accuracy: 0.8477 - val_loss: 0.5014 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4882 - accuracy: 0.8477 - val_loss: 0.4929 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4770 - accuracy: 0.8477 - val_loss: 0.4857 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4679 - accuracy: 0.8477 - val_loss: 0.4797 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4659 - accuracy: 0.8477 - val_loss: 0.4747 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4640 - accuracy: 0.8477 - val_loss: 0.4705 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4568 - accuracy: 0.8477 - val_loss: 0.4670 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4518 - accuracy: 0.8477 - val_loss: 0.4641 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4512 - accuracy: 0.8477 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4415 - accuracy: 0.8477 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4424 - accuracy: 0.8477 - val_loss: 0.4582 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4488 - accuracy: 0.8477 - val_loss: 0.4567 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4389 - accuracy: 0.8477 - val_loss: 0.4556 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4415 - accuracy: 0.8477 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4399 - accuracy: 0.8477 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4320 - accuracy: 0.8477 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4394 - accuracy: 0.8477 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8477 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4340 - accuracy: 0.8477 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4384 - accuracy: 0.8477 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4351 - accuracy: 0.8477 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4395 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4391 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4359 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4344 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4351 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4390 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4372 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4329 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4311 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4333 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4339 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4345 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4319 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4350 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4300 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4323 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4340 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4334 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4329 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4333 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4330 - accuracy: 0.8477 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4348 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4335 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4328 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4269 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4341 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4333 - accuracy: 0.8477 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4350 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4337 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4340 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4323 - accuracy: 0.8477 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4315 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4315 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4321 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4319 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4321 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4344 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4308 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4333 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4335 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4324 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4315 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.87 - 0s 19us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4322 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4315 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4302 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4300 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4268 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4260 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4305 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4255 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4268 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.84 - 0s 18us/sample - loss: 0.4265 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4262 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4272 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4293 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4262 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4279 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4291 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4281 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4269 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 279us/sample - loss: 0.4040 - accuracy: 0.8611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 524us/sample - loss: 15.4615 - accuracy: 0.7343 - val_loss: 13.9191 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 12.9820 - accuracy: 0.7648 - val_loss: 11.7712 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 10.9630 - accuracy: 0.8005 - val_loss: 9.9770 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 9.2755 - accuracy: 0.8102 - val_loss: 8.4923 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 7.8823 - accuracy: 0.8250 - val_loss: 7.2638 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 6.7529 - accuracy: 0.8352 - val_loss: 6.2397 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.8235 - accuracy: 0.8380 - val_loss: 5.3836 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 5.0325 - accuracy: 0.8412 - val_loss: 4.6654 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 4.3716 - accuracy: 0.8421 - val_loss: 4.0628 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.8102 - accuracy: 0.8431 - val_loss: 3.5561 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 3.3455 - accuracy: 0.8431 - val_loss: 3.1278 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 2.9525 - accuracy: 0.8431 - val_loss: 2.7635 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.6046 - accuracy: 0.8431 - val_loss: 2.4511 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.3194 - accuracy: 0.8431 - val_loss: 2.1818 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 2.0709 - accuracy: 0.8431 - val_loss: 1.9489 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.8493 - accuracy: 0.8431 - val_loss: 1.7465 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.6609 - accuracy: 0.8431 - val_loss: 1.5705 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 1.4956 - accuracy: 0.8431 - val_loss: 1.4172 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.3492 - accuracy: 0.8431 - val_loss: 1.2837 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.2282 - accuracy: 0.8431 - val_loss: 1.1673 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.1130 - accuracy: 0.8431 - val_loss: 1.0660 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 1.0214 - accuracy: 0.8431 - val_loss: 0.9781 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.9434 - accuracy: 0.8431 - val_loss: 0.9017 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.8735 - accuracy: 0.8431 - val_loss: 0.8356 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.8012 - accuracy: 0.8431 - val_loss: 0.7784 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7463 - accuracy: 0.8431 - val_loss: 0.7291 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.7005 - accuracy: 0.8431 - val_loss: 0.6867 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6585 - accuracy: 0.8431 - val_loss: 0.6502 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.6277 - accuracy: 0.8431 - val_loss: 0.6190 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.6067 - accuracy: 0.8431 - val_loss: 0.5923 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5752 - accuracy: 0.8431 - val_loss: 0.5696 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5519 - accuracy: 0.8431 - val_loss: 0.5503 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5304 - accuracy: 0.8431 - val_loss: 0.5339 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5205 - accuracy: 0.8431 - val_loss: 0.5200 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5077 - accuracy: 0.8431 - val_loss: 0.5083 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.5006 - accuracy: 0.8431 - val_loss: 0.4985 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4912 - accuracy: 0.8431 - val_loss: 0.4902 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4820 - accuracy: 0.8431 - val_loss: 0.4832 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4718 - accuracy: 0.8431 - val_loss: 0.4775 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.81 - 0s 19us/sample - loss: 0.4672 - accuracy: 0.8431 - val_loss: 0.4726 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4664 - accuracy: 0.8431 - val_loss: 0.4686 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4614 - accuracy: 0.8431 - val_loss: 0.4653 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4557 - accuracy: 0.8431 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4520 - accuracy: 0.8431 - val_loss: 0.4603 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4500 - accuracy: 0.8431 - val_loss: 0.4585 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4522 - accuracy: 0.8431 - val_loss: 0.4570 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4474 - accuracy: 0.8431 - val_loss: 0.4557 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4432 - accuracy: 0.8431 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4475 - accuracy: 0.8431 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4483 - accuracy: 0.8431 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4442 - accuracy: 0.8431 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4462 - accuracy: 0.8431 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4436 - accuracy: 0.8431 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4424 - accuracy: 0.8431 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4402 - accuracy: 0.8431 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4435 - accuracy: 0.8431 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4415 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4442 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4391 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4405 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4405 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4398 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4425 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4415 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4440 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4404 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4407 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4412 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4393 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4425 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4389 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4389 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4398 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4399 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4386 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4396 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4402 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4320 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4397 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4391 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4403 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4383 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4335 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4404 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4348 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4344 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4347 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4342 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4343 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4347 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4337 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4347 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4347 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 18us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4340 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 280us/sample - loss: 0.3737 - accuracy: 0.8796\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 372us/sample - loss: 29.3679 - accuracy: 0.4333 - val_loss: 25.6742 - val_accuracy: 0.5433\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 26us/sample - loss: 23.6838 - accuracy: 0.5940 - val_loss: 20.9868 - val_accuracy: 0.8300\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 19.1982 - accuracy: 0.7074 - val_loss: 17.1087 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 15.6079 - accuracy: 0.7370 - val_loss: 13.9469 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 12.7168 - accuracy: 0.7810 - val_loss: 11.3808 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 10.3674 - accuracy: 0.8167 - val_loss: 9.3019 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 8.4882 - accuracy: 0.8329 - val_loss: 7.6184 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 6.9503 - accuracy: 0.8477 - val_loss: 6.2565 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 5.7134 - accuracy: 0.8505 - val_loss: 5.1551 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 4.7157 - accuracy: 0.8519 - val_loss: 4.2651 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.9018 - accuracy: 0.8523 - val_loss: 3.5442 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 3.2425 - accuracy: 0.8523 - val_loss: 2.9600 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.7110 - accuracy: 0.8523 - val_loss: 2.4855 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.2782 - accuracy: 0.8523 - val_loss: 2.0995 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.9246 - accuracy: 0.8523 - val_loss: 1.7852 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.6386 - accuracy: 0.8523 - val_loss: 1.5291 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.4072 - accuracy: 0.8523 - val_loss: 1.3204 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.2190 - accuracy: 0.8523 - val_loss: 1.1507 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0594 - accuracy: 0.8523 - val_loss: 1.0129 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.9349 - accuracy: 0.8523 - val_loss: 0.9012 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8359 - accuracy: 0.8523 - val_loss: 0.8107 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7540 - accuracy: 0.8523 - val_loss: 0.7377 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6867 - accuracy: 0.8523 - val_loss: 0.6792 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.6317 - accuracy: 0.8523 - val_loss: 0.6320 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.5926 - accuracy: 0.8523 - val_loss: 0.5943 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5569 - accuracy: 0.8523 - val_loss: 0.5644 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5332 - accuracy: 0.8523 - val_loss: 0.5404 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5098 - accuracy: 0.8523 - val_loss: 0.5214 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4936 - accuracy: 0.8523 - val_loss: 0.5064 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4783 - accuracy: 0.8523 - val_loss: 0.4945 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4614 - accuracy: 0.8523 - val_loss: 0.4854 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4601 - accuracy: 0.8523 - val_loss: 0.4780 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4502 - accuracy: 0.8523 - val_loss: 0.4724 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4462 - accuracy: 0.8523 - val_loss: 0.4678 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4414 - accuracy: 0.8523 - val_loss: 0.4644 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4321 - accuracy: 0.8523 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4371 - accuracy: 0.8523 - val_loss: 0.4595 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4326 - accuracy: 0.8523 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4336 - accuracy: 0.8523 - val_loss: 0.4564 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4317 - accuracy: 0.8523 - val_loss: 0.4553 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4272 - accuracy: 0.8523 - val_loss: 0.4546 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4542 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4340 - accuracy: 0.8523 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4267 - accuracy: 0.8523 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4322 - accuracy: 0.8523 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4256 - accuracy: 0.8523 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4265 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4275 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4260 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4286 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4280 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4249 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4249 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4288 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4245 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4296 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.83 - 0s 23us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4273 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4322 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4280 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4266 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4275 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4253 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4274 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4258 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4264 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4238 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4269 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4244 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4235 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4273 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4265 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4246 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4229 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4268 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4185 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4257 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4242 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4262 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4231 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4253 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4255 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8523 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4222 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4225 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4229 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4234 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4191 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4213 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4243 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4239 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4233 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4188 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4229 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4230 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4245 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4207 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4227 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4185 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4234 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4228 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4235 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4196 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4217 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4240 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4188 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4221 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4185 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4224 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4195 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4229 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4203 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8523 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4215 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.86 - 0s 21us/sample - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4205 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4208 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4220 - accuracy: 0.8523 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4193 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4226 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4174 - accuracy: 0.8523 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4210 - accuracy: 0.8523 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4216 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 289us/sample - loss: 0.4355 - accuracy: 0.8426\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 391us/sample - loss: 28.5251 - accuracy: 0.6722 - val_loss: 25.1761 - val_accuracy: 0.8367\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 23.0824 - accuracy: 0.7255 - val_loss: 20.4145 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 18.5676 - accuracy: 0.7778 - val_loss: 16.5156 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 15.0052 - accuracy: 0.8213 - val_loss: 13.3582 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 12.1406 - accuracy: 0.8389 - val_loss: 10.8210 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 9.8464 - accuracy: 0.8449 - val_loss: 8.7831 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 7.9949 - accuracy: 0.8495 - val_loss: 7.1504 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 6.5153 - accuracy: 0.8505 - val_loss: 5.8406 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 5.3290 - accuracy: 0.8505 - val_loss: 4.7899 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 4.3791 - accuracy: 0.8505 - val_loss: 3.9444 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.6003 - accuracy: 0.8505 - val_loss: 3.2637 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 2.9846 - accuracy: 0.8505 - val_loss: 2.7140 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.4798 - accuracy: 0.8505 - val_loss: 2.2691 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.0743 - accuracy: 0.8505 - val_loss: 1.9088 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.7513 - accuracy: 0.8505 - val_loss: 1.6169 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4779 - accuracy: 0.8505 - val_loss: 1.3807 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2670 - accuracy: 0.8505 - val_loss: 1.1898 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0970 - accuracy: 0.8505 - val_loss: 1.0357 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9570 - accuracy: 0.8505 - val_loss: 0.9118 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8430 - accuracy: 0.8505 - val_loss: 0.8128 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.7484 - accuracy: 0.8505 - val_loss: 0.7338 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6809 - accuracy: 0.8505 - val_loss: 0.6712 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6226 - accuracy: 0.8505 - val_loss: 0.6217 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5817 - accuracy: 0.8505 - val_loss: 0.5828 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5415 - accuracy: 0.8505 - val_loss: 0.5520 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5196 - accuracy: 0.8505 - val_loss: 0.5283 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4974 - accuracy: 0.8505 - val_loss: 0.5098 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4829 - accuracy: 0.8505 - val_loss: 0.4955 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4673 - accuracy: 0.8505 - val_loss: 0.4845 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4556 - accuracy: 0.8505 - val_loss: 0.4763 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4516 - accuracy: 0.8505 - val_loss: 0.4699 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4463 - accuracy: 0.8505 - val_loss: 0.4651 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4385 - accuracy: 0.8505 - val_loss: 0.4617 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4350 - accuracy: 0.8505 - val_loss: 0.4590 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4380 - accuracy: 0.8505 - val_loss: 0.4568 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4322 - accuracy: 0.8505 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4330 - accuracy: 0.8505 - val_loss: 0.4542 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4305 - accuracy: 0.8505 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4274 - accuracy: 0.8505 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4307 - accuracy: 0.8505 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4321 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4308 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4321 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4277 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4301 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4302 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4304 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4257 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4270 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4273 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.86 - 0s 21us/sample - loss: 0.4265 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4271 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4313 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4317 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4293 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4276 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4259 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4303 - accuracy: 0.8505 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4275 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4293 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4283 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4294 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4261 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4269 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4280 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4250 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4262 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4284 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.85 - 0s 21us/sample - loss: 0.4258 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4287 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4273 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4220 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4256 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4234 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4231 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4250 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4262 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4261 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4282 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4265 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4269 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4260 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4280 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4269 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4225 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4250 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4266 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4275 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4264 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4260 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.79 - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4261 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4213 - accuracy: 0.8505 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4214 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4239 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4251 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4245 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4248 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4254 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4247 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4240 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4223 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4255 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4226 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4242 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4244 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4228 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4227 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4222 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4253 - accuracy: 0.8505 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4235 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4224 - accuracy: 0.8505 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 278us/sample - loss: 0.4228 - accuracy: 0.8500\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 527us/sample - loss: 28.7977 - accuracy: 0.6032 - val_loss: 25.3712 - val_accuracy: 0.7767\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 23.2117 - accuracy: 0.7292 - val_loss: 20.6096 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 18.7527 - accuracy: 0.7556 - val_loss: 16.7024 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 15.1973 - accuracy: 0.7829 - val_loss: 13.5373 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 12.2878 - accuracy: 0.8301 - val_loss: 10.9838 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 9.9677 - accuracy: 0.8509 - val_loss: 8.9273 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 8.1162 - accuracy: 0.8560 - val_loss: 7.2700 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 6.6079 - accuracy: 0.8579 - val_loss: 5.9362 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 5.3972 - accuracy: 0.8588 - val_loss: 4.8660 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 4.4280 - accuracy: 0.8583 - val_loss: 4.0066 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.6432 - accuracy: 0.8583 - val_loss: 3.3153 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.0107 - accuracy: 0.8583 - val_loss: 2.7584 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.5130 - accuracy: 0.8583 - val_loss: 2.3079 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.0950 - accuracy: 0.8583 - val_loss: 1.9436 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.7643 - accuracy: 0.8583 - val_loss: 1.6486 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.4970 - accuracy: 0.8583 - val_loss: 1.4096 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.2786 - accuracy: 0.8583 - val_loss: 1.2161 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1017 - accuracy: 0.8583 - val_loss: 1.0602 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9650 - accuracy: 0.8583 - val_loss: 0.9343 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.8497 - accuracy: 0.8583 - val_loss: 0.8329 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7613 - accuracy: 0.8583 - val_loss: 0.7518 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6897 - accuracy: 0.8583 - val_loss: 0.6870 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.6261 - accuracy: 0.8583 - val_loss: 0.6357 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.5862 - accuracy: 0.8583 - val_loss: 0.5950 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5429 - accuracy: 0.8583 - val_loss: 0.5629 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5154 - accuracy: 0.8583 - val_loss: 0.5379 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4908 - accuracy: 0.8583 - val_loss: 0.5184 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4714 - accuracy: 0.8583 - val_loss: 0.5031 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4588 - accuracy: 0.8583 - val_loss: 0.4915 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4511 - accuracy: 0.8583 - val_loss: 0.4819 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4397 - accuracy: 0.8583 - val_loss: 0.4750 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4357 - accuracy: 0.8583 - val_loss: 0.4696 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4344 - accuracy: 0.8583 - val_loss: 0.4654 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4257 - accuracy: 0.8583 - val_loss: 0.4620 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4262 - accuracy: 0.8583 - val_loss: 0.4595 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4233 - accuracy: 0.8583 - val_loss: 0.4577 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4205 - accuracy: 0.8583 - val_loss: 0.4565 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4177 - accuracy: 0.8583 - val_loss: 0.4555 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4171 - accuracy: 0.8583 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4197 - accuracy: 0.8583 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4179 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4160 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4158 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4133 - accuracy: 0.8583 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4142 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4153 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4169 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4172 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4143 - accuracy: 0.8583 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4146 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4116 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4120 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4151 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4127 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4171 - accuracy: 0.8583 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4134 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4128 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4146 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4154 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4139 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4153 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4163 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4077 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4174 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4162 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4152 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4118 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4133 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4079 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4134 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4135 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4126 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4153 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4140 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4138 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4142 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.88 - 0s 21us/sample - loss: 0.4142 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4122 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4130 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4122 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4131 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4132 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4122 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4123 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4120 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4119 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4118 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4083 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4125 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4111 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4113 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4120 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4115 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4109 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4122 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4114 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4088 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4110 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4115 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4087 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4049 - accuracy: 0.8583 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4084 - accuracy: 0.8583 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4099 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4082 - accuracy: 0.8583 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4137 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4107 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4112 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4094 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4105 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4086 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4098 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4100 - accuracy: 0.8583 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4101 - accuracy: 0.8583 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4092 - accuracy: 0.8583 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4102 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.81 - 0s 21us/sample - loss: 0.4106 - accuracy: 0.8583 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4103 - accuracy: 0.8583 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 279us/sample - loss: 0.4790 - accuracy: 0.8185\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 379us/sample - loss: 28.3780 - accuracy: 0.5037 - val_loss: 24.8984 - val_accuracy: 0.8233\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 22.8772 - accuracy: 0.6606 - val_loss: 20.2354 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 18.4475 - accuracy: 0.7338 - val_loss: 16.3945 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 14.9233 - accuracy: 0.7759 - val_loss: 13.2796 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 12.0806 - accuracy: 0.8051 - val_loss: 10.7689 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 9.7929 - accuracy: 0.8361 - val_loss: 8.7483 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 7.9629 - accuracy: 0.8403 - val_loss: 7.1229 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 6.4948 - accuracy: 0.8449 - val_loss: 5.8175 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 5.3024 - accuracy: 0.8468 - val_loss: 4.7700 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 4.3564 - accuracy: 0.8477 - val_loss: 3.9287 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.5892 - accuracy: 0.8477 - val_loss: 3.2504 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.9759 - accuracy: 0.8477 - val_loss: 2.7040 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.4794 - accuracy: 0.8477 - val_loss: 2.2628 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.0787 - accuracy: 0.8477 - val_loss: 1.9063 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.7580 - accuracy: 0.8477 - val_loss: 1.6179 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.4878 - accuracy: 0.8477 - val_loss: 1.3846 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.2808 - accuracy: 0.8477 - val_loss: 1.1961 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.1097 - accuracy: 0.8477 - val_loss: 1.0440 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.9693 - accuracy: 0.8477 - val_loss: 0.9216 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8609 - accuracy: 0.8477 - val_loss: 0.8232 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7741 - accuracy: 0.8477 - val_loss: 0.7445 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.7059 - accuracy: 0.8477 - val_loss: 0.6815 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6403 - accuracy: 0.8477 - val_loss: 0.6315 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.6026 - accuracy: 0.8477 - val_loss: 0.5919 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5601 - accuracy: 0.8477 - val_loss: 0.5605 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5301 - accuracy: 0.8477 - val_loss: 0.5359 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.5094 - accuracy: 0.8477 - val_loss: 0.5166 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4931 - accuracy: 0.8477 - val_loss: 0.5015 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4825 - accuracy: 0.8477 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4659 - accuracy: 0.8477 - val_loss: 0.4807 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4641 - accuracy: 0.8477 - val_loss: 0.4737 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4523 - accuracy: 0.8477 - val_loss: 0.4683 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4524 - accuracy: 0.8477 - val_loss: 0.4641 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4468 - accuracy: 0.8477 - val_loss: 0.4609 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4481 - accuracy: 0.8477 - val_loss: 0.4584 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4399 - accuracy: 0.8477 - val_loss: 0.4566 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4418 - accuracy: 0.8477 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4369 - accuracy: 0.8477 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 19us/sample - loss: 0.4372 - accuracy: 0.8477 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4337 - accuracy: 0.8477 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4355 - accuracy: 0.8477 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 27us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4385 - accuracy: 0.8477 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4331 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4337 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4353 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4342 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4342 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4287 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4338 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4354 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4313 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.85 - 0s 24us/sample - loss: 0.4326 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4317 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4357 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4365 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4276 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4318 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4345 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.85 - 0s 22us/sample - loss: 0.4330 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4354 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4336 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4372 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4327 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4335 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4329 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4359 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4342 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4316 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4340 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4324 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4323 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4278 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4334 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4343 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4339 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4313 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4317 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4318 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4308 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4347 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4336 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4321 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4322 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4348 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4270 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4303 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4274 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4347 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4299 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4323 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4308 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4287 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4335 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4295 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4313 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4323 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4319 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4311 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4321 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4321 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4267 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4300 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4268 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4312 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.82 - 0s 21us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4314 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4306 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4298 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4317 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4298 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4286 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.83 - 0s 22us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4264 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4304 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4297 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4269 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4285 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4305 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4288 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4325 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4309 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4307 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4277 - accuracy: 0.8477 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4275 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4296 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4280 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4292 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.82 - 0s 22us/sample - loss: 0.4305 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4310 - accuracy: 0.8477 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4282 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4283 - accuracy: 0.8477 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4290 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4273 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4294 - accuracy: 0.8477 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4287 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4271 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 284us/sample - loss: 0.4041 - accuracy: 0.8611\n",
      "Train on 2160 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2160/2160 [==============================] - 1s 383us/sample - loss: 28.5156 - accuracy: 0.7130 - val_loss: 25.2463 - val_accuracy: 0.8300\n",
      "Epoch 2/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 23.1584 - accuracy: 0.7463 - val_loss: 20.5486 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 18.7791 - accuracy: 0.7681 - val_loss: 16.6832 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 15.1693 - accuracy: 0.8023 - val_loss: 13.5463 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 12.3143 - accuracy: 0.8231 - val_loss: 11.0120 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 10.0162 - accuracy: 0.8347 - val_loss: 8.9646 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 8.1626 - accuracy: 0.8431 - val_loss: 7.3155 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 7.3110 - accuracy: 0.84 - 0s 22us/sample - loss: 6.6748 - accuracy: 0.8426 - val_loss: 5.9898 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 5.4705 - accuracy: 0.8431 - val_loss: 4.9234 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 4.5063 - accuracy: 0.8431 - val_loss: 4.0640 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 3.7178 - accuracy: 0.8431 - val_loss: 3.3702 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 3.0917 - accuracy: 0.8431 - val_loss: 2.8089 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 2.5798 - accuracy: 0.8431 - val_loss: 2.3534 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 2.1719 - accuracy: 0.8431 - val_loss: 1.9833 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.8273 - accuracy: 0.8431 - val_loss: 1.6823 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 1.5550 - accuracy: 0.8431 - val_loss: 1.4380 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.3334 - accuracy: 0.8431 - val_loss: 1.2399 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 1.2468 - accuracy: 0.83 - 0s 23us/sample - loss: 1.1575 - accuracy: 0.8431 - val_loss: 1.0794 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 1.0087 - accuracy: 0.8431 - val_loss: 0.9499 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.8930 - accuracy: 0.8431 - val_loss: 0.8455 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7960 - accuracy: 0.8431 - val_loss: 0.7619 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.7190 - accuracy: 0.8431 - val_loss: 0.6949 - val_accuracy: 0.8333\n",
      "Epoch 23/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.6598 - accuracy: 0.8431 - val_loss: 0.6417 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.6121 - accuracy: 0.8431 - val_loss: 0.5994 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5777 - accuracy: 0.8431 - val_loss: 0.5661 - val_accuracy: 0.8333\n",
      "Epoch 26/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5381 - accuracy: 0.8431 - val_loss: 0.5398 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.84 - 0s 23us/sample - loss: 0.5179 - accuracy: 0.8431 - val_loss: 0.5194 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.5009 - accuracy: 0.8431 - val_loss: 0.5033 - val_accuracy: 0.8333\n",
      "Epoch 29/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4850 - accuracy: 0.8431 - val_loss: 0.4909 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2160/2160 [==============================] - 0s 24us/sample - loss: 0.4735 - accuracy: 0.8431 - val_loss: 0.4812 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4648 - accuracy: 0.8431 - val_loss: 0.4739 - val_accuracy: 0.8333\n",
      "Epoch 32/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4625 - accuracy: 0.8431 - val_loss: 0.4681 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4531 - accuracy: 0.8431 - val_loss: 0.4640 - val_accuracy: 0.8333\n",
      "Epoch 34/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4528 - accuracy: 0.8431 - val_loss: 0.4606 - val_accuracy: 0.8333\n",
      "Epoch 35/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4494 - accuracy: 0.8431 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
      "Epoch 36/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4509 - accuracy: 0.8431 - val_loss: 0.4561 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4437 - accuracy: 0.8431 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4442 - accuracy: 0.8431 - val_loss: 0.4537 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4423 - accuracy: 0.8431 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4438 - accuracy: 0.8431 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4415 - accuracy: 0.8431 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4412 - accuracy: 0.8431 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4390 - accuracy: 0.8431 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4418 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4399 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4400 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4410 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4444 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4421 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4396 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4414 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "2160/2160 [==============================] - 0s 23us/sample - loss: 0.4410 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4424 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4394 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4398 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4401 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4416 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4419 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4344 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4348 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4396 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4430 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4388 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4374 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4403 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4382 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4390 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4344 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4390 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4393 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4387 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4371 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4362 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4393 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4402 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4385 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4373 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4395 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4376 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4397 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4396 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4389 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4390 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4393 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4379 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4338 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4389 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.80 - 0s 21us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4377 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4403 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.81 - 0s 20us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4341 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4383 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4368 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4392 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4381 - accuracy: 0.8431 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4375 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4371 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4347 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.86 - 0s 21us/sample - loss: 0.4353 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4352 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4364 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4372 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4378 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4366 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4369 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4342 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4337 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "2160/2160 [==============================] - ETA: 0s - loss: 0.4106 - accuracy: 0.85 - 0s 22us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "2160/2160 [==============================] - 0s 25us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4346 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4351 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4354 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4349 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4383 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4345 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4336 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4338 - accuracy: 0.8431 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4361 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4357 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4363 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4370 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4365 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4367 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4359 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4348 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4371 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "2160/2160 [==============================] - 0s 20us/sample - loss: 0.4358 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4322 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4360 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4356 - accuracy: 0.8431 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "2160/2160 [==============================] - 0s 21us/sample - loss: 0.4380 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "2160/2160 [==============================] - 0s 22us/sample - loss: 0.4355 - accuracy: 0.8431 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "540/540 [==============================] - 0s 260us/sample - loss: 0.3741 - accuracy: 0.8796\n",
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2700/2700 [==============================] - 1s 297us/sample - loss: 3.4106 - accuracy: 0.7559 - val_loss: 3.0129 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 2.8274 - accuracy: 0.8344 - val_loss: 2.5588 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 2.3942 - accuracy: 0.8456 - val_loss: 2.1714 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 2.0226 - accuracy: 0.8500 - val_loss: 1.8362 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 1.7225 - accuracy: 0.8500 - val_loss: 1.5597 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 1.4620 - accuracy: 0.8507 - val_loss: 1.3299 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 1.2491 - accuracy: 0.8493 - val_loss: 1.1391 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 1.0694 - accuracy: 0.8556 - val_loss: 0.9768 - val_accuracy: 0.8400\n",
      "Epoch 9/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.9265 - accuracy: 0.8589 - val_loss: 0.8431 - val_accuracy: 0.8467\n",
      "Epoch 10/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.8056 - accuracy: 0.8641 - val_loss: 0.7359 - val_accuracy: 0.8733\n",
      "Epoch 11/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.7108 - accuracy: 0.8822 - val_loss: 0.6481 - val_accuracy: 0.9133\n",
      "Epoch 12/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.6276 - accuracy: 0.8981 - val_loss: 0.5823 - val_accuracy: 0.9133\n",
      "Epoch 13/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.5583 - accuracy: 0.9096 - val_loss: 0.5266 - val_accuracy: 0.9233\n",
      "Epoch 14/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.5030 - accuracy: 0.9211 - val_loss: 0.4806 - val_accuracy: 0.9300\n",
      "Epoch 15/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.4647 - accuracy: 0.9300 - val_loss: 0.4494 - val_accuracy: 0.9300\n",
      "Epoch 16/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.4270 - accuracy: 0.9367 - val_loss: 0.4199 - val_accuracy: 0.9400\n",
      "Epoch 17/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3932 - accuracy: 0.9474 - val_loss: 0.3975 - val_accuracy: 0.9367\n",
      "Epoch 18/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.3626 - accuracy: 0.9470 - val_loss: 0.3736 - val_accuracy: 0.9400\n",
      "Epoch 19/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.3400 - accuracy: 0.9511 - val_loss: 0.3735 - val_accuracy: 0.9267\n",
      "Epoch 20/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.3186 - accuracy: 0.9607 - val_loss: 0.3453 - val_accuracy: 0.9400\n",
      "Epoch 21/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3047 - accuracy: 0.9611 - val_loss: 0.3396 - val_accuracy: 0.9367\n",
      "Epoch 22/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.2883 - accuracy: 0.9600 - val_loss: 0.3160 - val_accuracy: 0.9400\n",
      "Epoch 23/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.2725 - accuracy: 0.9715 - val_loss: 0.3289 - val_accuracy: 0.9400\n",
      "Epoch 24/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2622 - accuracy: 0.9719 - val_loss: 0.3004 - val_accuracy: 0.9467\n",
      "Epoch 25/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2485 - accuracy: 0.9744 - val_loss: 0.3182 - val_accuracy: 0.9400\n",
      "Epoch 26/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2436 - accuracy: 0.9752 - val_loss: 0.3204 - val_accuracy: 0.9367\n",
      "Epoch 27/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.2339 - accuracy: 0.9800 - val_loss: 0.3082 - val_accuracy: 0.9367\n",
      "Epoch 28/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2352 - accuracy: 0.9737 - val_loss: 0.3061 - val_accuracy: 0.9467\n",
      "Epoch 29/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2208 - accuracy: 0.9804 - val_loss: 0.3190 - val_accuracy: 0.9467\n",
      "Epoch 30/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2088 - accuracy: 0.9807 - val_loss: 0.2951 - val_accuracy: 0.9433\n",
      "Epoch 31/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2141 - accuracy: 0.9796 - val_loss: 0.2941 - val_accuracy: 0.9500\n",
      "Epoch 32/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2043 - accuracy: 0.9841 - val_loss: 0.3075 - val_accuracy: 0.9400\n",
      "Epoch 33/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1996 - accuracy: 0.9859 - val_loss: 0.3011 - val_accuracy: 0.9467\n",
      "Epoch 34/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1917 - accuracy: 0.9867 - val_loss: 0.2883 - val_accuracy: 0.9467\n",
      "Epoch 35/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1900 - accuracy: 0.9867 - val_loss: 0.3114 - val_accuracy: 0.9433\n",
      "Epoch 36/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2016 - accuracy: 0.9789 - val_loss: 0.2688 - val_accuracy: 0.9500\n",
      "Epoch 37/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.2117 - accuracy: 0.9785 - val_loss: 0.2962 - val_accuracy: 0.9400\n",
      "Epoch 38/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1956 - accuracy: 0.9859 - val_loss: 0.2834 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1912 - accuracy: 0.9833 - val_loss: 0.2926 - val_accuracy: 0.9433\n",
      "Epoch 40/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1823 - accuracy: 0.9870 - val_loss: 0.2905 - val_accuracy: 0.9467\n",
      "Epoch 41/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1767 - accuracy: 0.9893 - val_loss: 0.2890 - val_accuracy: 0.9400\n",
      "Epoch 42/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1839 - accuracy: 0.9837 - val_loss: 0.2880 - val_accuracy: 0.9433\n",
      "Epoch 43/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1804 - accuracy: 0.9874 - val_loss: 0.2918 - val_accuracy: 0.9367\n",
      "Epoch 44/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1737 - accuracy: 0.9907 - val_loss: 0.3235 - val_accuracy: 0.9400\n",
      "Epoch 45/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1788 - accuracy: 0.9852 - val_loss: 0.3311 - val_accuracy: 0.9367\n",
      "Epoch 46/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1787 - accuracy: 0.9885 - val_loss: 0.2939 - val_accuracy: 0.9433\n",
      "Epoch 47/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1731 - accuracy: 0.9889 - val_loss: 0.2876 - val_accuracy: 0.9533\n",
      "Epoch 48/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1768 - accuracy: 0.9867 - val_loss: 0.2900 - val_accuracy: 0.9433\n",
      "Epoch 49/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1702 - accuracy: 0.9893 - val_loss: 0.2836 - val_accuracy: 0.9533\n",
      "Epoch 50/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1787 - accuracy: 0.9833 - val_loss: 0.3058 - val_accuracy: 0.9533\n",
      "Epoch 51/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1748 - accuracy: 0.9881 - val_loss: 0.2819 - val_accuracy: 0.9467\n",
      "Epoch 52/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1627 - accuracy: 0.9915 - val_loss: 0.2907 - val_accuracy: 0.9367\n",
      "Epoch 53/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1611 - accuracy: 0.9907 - val_loss: 0.2796 - val_accuracy: 0.9500\n",
      "Epoch 54/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1679 - accuracy: 0.9874 - val_loss: 0.2759 - val_accuracy: 0.9400\n",
      "Epoch 55/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1606 - accuracy: 0.9911 - val_loss: 0.2939 - val_accuracy: 0.9400\n",
      "Epoch 56/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1580 - accuracy: 0.9907 - val_loss: 0.2850 - val_accuracy: 0.9500\n",
      "Epoch 57/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1558 - accuracy: 0.9926 - val_loss: 0.2743 - val_accuracy: 0.9500\n",
      "Epoch 58/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1579 - accuracy: 0.9896 - val_loss: 0.2907 - val_accuracy: 0.9467\n",
      "Epoch 59/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1553 - accuracy: 0.9900 - val_loss: 0.2996 - val_accuracy: 0.9467\n",
      "Epoch 60/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1663 - accuracy: 0.9870 - val_loss: 0.2862 - val_accuracy: 0.9467\n",
      "Epoch 61/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1593 - accuracy: 0.9889 - val_loss: 0.2900 - val_accuracy: 0.9400\n",
      "Epoch 62/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1534 - accuracy: 0.9937 - val_loss: 0.2778 - val_accuracy: 0.9500\n",
      "Epoch 63/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1526 - accuracy: 0.9911 - val_loss: 0.2864 - val_accuracy: 0.9433\n",
      "Epoch 64/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1534 - accuracy: 0.9896 - val_loss: 0.2667 - val_accuracy: 0.9400\n",
      "Epoch 65/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1594 - accuracy: 0.9893 - val_loss: 0.2659 - val_accuracy: 0.9500\n",
      "Epoch 66/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1578 - accuracy: 0.9859 - val_loss: 0.2514 - val_accuracy: 0.9467\n",
      "Epoch 67/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1600 - accuracy: 0.9878 - val_loss: 0.2950 - val_accuracy: 0.9467\n",
      "Epoch 68/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1542 - accuracy: 0.9915 - val_loss: 0.2734 - val_accuracy: 0.9433\n",
      "Epoch 69/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1515 - accuracy: 0.9896 - val_loss: 0.2835 - val_accuracy: 0.9433\n",
      "Epoch 70/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1498 - accuracy: 0.9937 - val_loss: 0.3135 - val_accuracy: 0.9367\n",
      "Epoch 71/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1468 - accuracy: 0.9926 - val_loss: 0.2983 - val_accuracy: 0.9500\n",
      "Epoch 72/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1502 - accuracy: 0.9904 - val_loss: 0.3087 - val_accuracy: 0.9400\n",
      "Epoch 73/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1525 - accuracy: 0.9870 - val_loss: 0.3006 - val_accuracy: 0.9400\n",
      "Epoch 74/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1631 - accuracy: 0.9844 - val_loss: 0.3012 - val_accuracy: 0.9400\n",
      "Epoch 75/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1580 - accuracy: 0.9904 - val_loss: 0.2881 - val_accuracy: 0.9333\n",
      "Epoch 76/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1551 - accuracy: 0.9904 - val_loss: 0.3175 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1510 - accuracy: 0.9900 - val_loss: 0.2808 - val_accuracy: 0.9433\n",
      "Epoch 78/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1458 - accuracy: 0.9930 - val_loss: 0.2864 - val_accuracy: 0.9433\n",
      "Epoch 79/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1433 - accuracy: 0.9941 - val_loss: 0.2841 - val_accuracy: 0.9467\n",
      "Epoch 80/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1446 - accuracy: 0.9915 - val_loss: 0.2738 - val_accuracy: 0.9467\n",
      "Epoch 81/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1426 - accuracy: 0.9915 - val_loss: 0.2659 - val_accuracy: 0.9433\n",
      "Epoch 82/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1586 - accuracy: 0.9841 - val_loss: 0.2628 - val_accuracy: 0.9400\n",
      "Epoch 83/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1538 - accuracy: 0.9911 - val_loss: 0.2458 - val_accuracy: 0.9533\n",
      "Epoch 84/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1446 - accuracy: 0.9926 - val_loss: 0.2639 - val_accuracy: 0.9400\n",
      "Epoch 85/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1401 - accuracy: 0.9937 - val_loss: 0.2681 - val_accuracy: 0.9367\n",
      "Epoch 86/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1369 - accuracy: 0.9944 - val_loss: 0.2655 - val_accuracy: 0.9433\n",
      "Epoch 87/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1445 - accuracy: 0.9907 - val_loss: 0.2498 - val_accuracy: 0.9533\n",
      "Epoch 88/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1494 - accuracy: 0.9893 - val_loss: 0.2601 - val_accuracy: 0.9500\n",
      "Epoch 89/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1474 - accuracy: 0.9907 - val_loss: 0.2708 - val_accuracy: 0.9467\n",
      "Epoch 90/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1438 - accuracy: 0.9930 - val_loss: 0.2484 - val_accuracy: 0.9467\n",
      "Epoch 91/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1399 - accuracy: 0.9907 - val_loss: 0.2836 - val_accuracy: 0.9367\n",
      "Epoch 92/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1353 - accuracy: 0.9948 - val_loss: 0.2888 - val_accuracy: 0.9300\n",
      "Epoch 93/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1364 - accuracy: 0.9944 - val_loss: 0.2837 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1389 - accuracy: 0.9919 - val_loss: 0.2616 - val_accuracy: 0.9367\n",
      "Epoch 95/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1328 - accuracy: 0.9941 - val_loss: 0.2841 - val_accuracy: 0.9400\n",
      "Epoch 96/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1325 - accuracy: 0.9941 - val_loss: 0.3236 - val_accuracy: 0.9400\n",
      "Epoch 97/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1306 - accuracy: 0.9948 - val_loss: 0.2926 - val_accuracy: 0.9433\n",
      "Epoch 98/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1359 - accuracy: 0.9911 - val_loss: 0.2801 - val_accuracy: 0.9367\n",
      "Epoch 99/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1379 - accuracy: 0.9919 - val_loss: 0.2759 - val_accuracy: 0.9433\n",
      "Epoch 100/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1371 - accuracy: 0.9900 - val_loss: 0.2860 - val_accuracy: 0.9500\n",
      "Epoch 101/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1359 - accuracy: 0.9926 - val_loss: 0.2935 - val_accuracy: 0.9400\n",
      "Epoch 102/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1388 - accuracy: 0.9911 - val_loss: 0.3210 - val_accuracy: 0.9333\n",
      "Epoch 103/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1380 - accuracy: 0.9900 - val_loss: 0.3059 - val_accuracy: 0.9433\n",
      "Epoch 104/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1704 - accuracy: 0.9778 - val_loss: 0.2860 - val_accuracy: 0.9500\n",
      "Epoch 105/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1740 - accuracy: 0.9796 - val_loss: 0.3087 - val_accuracy: 0.9333\n",
      "Epoch 106/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1658 - accuracy: 0.9856 - val_loss: 0.3261 - val_accuracy: 0.9400\n",
      "Epoch 107/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1701 - accuracy: 0.9867 - val_loss: 0.3460 - val_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1671 - accuracy: 0.9878 - val_loss: 0.3003 - val_accuracy: 0.9467\n",
      "Epoch 109/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1511 - accuracy: 0.9907 - val_loss: 0.2792 - val_accuracy: 0.9500\n",
      "Epoch 110/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1495 - accuracy: 0.9926 - val_loss: 0.3233 - val_accuracy: 0.9433\n",
      "Epoch 111/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1436 - accuracy: 0.9930 - val_loss: 0.3064 - val_accuracy: 0.9433\n",
      "Epoch 112/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1434 - accuracy: 0.9937 - val_loss: 0.3167 - val_accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "2700/2700 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.99 - 0s 19us/sample - loss: 0.1408 - accuracy: 0.9896 - val_loss: 0.2840 - val_accuracy: 0.9433\n",
      "Epoch 114/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1344 - accuracy: 0.9941 - val_loss: 0.3190 - val_accuracy: 0.9400\n",
      "Epoch 115/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1350 - accuracy: 0.9922 - val_loss: 0.3032 - val_accuracy: 0.9400\n",
      "Epoch 116/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1338 - accuracy: 0.9937 - val_loss: 0.2827 - val_accuracy: 0.9400\n",
      "Epoch 117/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1350 - accuracy: 0.9915 - val_loss: 0.2705 - val_accuracy: 0.9533\n",
      "Epoch 118/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1300 - accuracy: 0.9933 - val_loss: 0.2622 - val_accuracy: 0.9467\n",
      "Epoch 119/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1287 - accuracy: 0.9944 - val_loss: 0.2740 - val_accuracy: 0.9500\n",
      "Epoch 120/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1299 - accuracy: 0.9922 - val_loss: 0.2636 - val_accuracy: 0.9500\n",
      "Epoch 121/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1306 - accuracy: 0.9933 - val_loss: 0.2797 - val_accuracy: 0.9467\n",
      "Epoch 122/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1328 - accuracy: 0.9937 - val_loss: 0.2745 - val_accuracy: 0.9467\n",
      "Epoch 123/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1319 - accuracy: 0.9930 - val_loss: 0.2696 - val_accuracy: 0.9500\n",
      "Epoch 124/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1296 - accuracy: 0.9922 - val_loss: 0.2640 - val_accuracy: 0.9467\n",
      "Epoch 125/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1306 - accuracy: 0.9919 - val_loss: 0.2410 - val_accuracy: 0.9567\n",
      "Epoch 126/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1289 - accuracy: 0.9933 - val_loss: 0.2784 - val_accuracy: 0.9433\n",
      "Epoch 127/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1249 - accuracy: 0.9959 - val_loss: 0.2760 - val_accuracy: 0.9500\n",
      "Epoch 128/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1274 - accuracy: 0.9933 - val_loss: 0.2792 - val_accuracy: 0.9533\n",
      "Epoch 129/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1358 - accuracy: 0.9922 - val_loss: 0.2703 - val_accuracy: 0.9500\n",
      "Epoch 130/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1282 - accuracy: 0.9926 - val_loss: 0.2788 - val_accuracy: 0.9467\n",
      "Epoch 131/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1303 - accuracy: 0.9926 - val_loss: 0.2599 - val_accuracy: 0.9533\n",
      "Epoch 132/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1293 - accuracy: 0.9926 - val_loss: 0.2719 - val_accuracy: 0.9433\n",
      "Epoch 133/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1223 - accuracy: 0.9970 - val_loss: 0.2685 - val_accuracy: 0.9467\n",
      "Epoch 134/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1284 - accuracy: 0.9919 - val_loss: 0.2748 - val_accuracy: 0.9433\n",
      "Epoch 135/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1349 - accuracy: 0.9904 - val_loss: 0.2573 - val_accuracy: 0.9433\n",
      "Epoch 136/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1434 - accuracy: 0.9841 - val_loss: 0.2464 - val_accuracy: 0.9467\n",
      "Epoch 137/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1395 - accuracy: 0.9900 - val_loss: 0.2480 - val_accuracy: 0.9533\n",
      "Epoch 138/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1413 - accuracy: 0.9896 - val_loss: 0.2628 - val_accuracy: 0.9467\n",
      "Epoch 139/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1290 - accuracy: 0.9959 - val_loss: 0.2873 - val_accuracy: 0.9433\n",
      "Epoch 140/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1336 - accuracy: 0.9937 - val_loss: 0.2622 - val_accuracy: 0.9433\n",
      "Epoch 141/200\n",
      "2700/2700 [==============================] - 0s 17us/sample - loss: 0.1356 - accuracy: 0.9933 - val_loss: 0.3221 - val_accuracy: 0.9400\n",
      "Epoch 142/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1378 - accuracy: 0.9911 - val_loss: 0.3224 - val_accuracy: 0.9300\n",
      "Epoch 143/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1428 - accuracy: 0.9896 - val_loss: 0.3048 - val_accuracy: 0.9433\n",
      "Epoch 144/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1411 - accuracy: 0.9889 - val_loss: 0.3174 - val_accuracy: 0.9400\n",
      "Epoch 145/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1387 - accuracy: 0.9907 - val_loss: 0.2994 - val_accuracy: 0.9433\n",
      "Epoch 146/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1329 - accuracy: 0.9907 - val_loss: 0.2727 - val_accuracy: 0.9533\n",
      "Epoch 147/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1450 - accuracy: 0.9870 - val_loss: 0.2724 - val_accuracy: 0.9467\n",
      "Epoch 148/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1408 - accuracy: 0.9885 - val_loss: 0.2787 - val_accuracy: 0.9367\n",
      "Epoch 149/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1418 - accuracy: 0.9896 - val_loss: 0.2726 - val_accuracy: 0.9467\n",
      "Epoch 150/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1359 - accuracy: 0.9904 - val_loss: 0.2825 - val_accuracy: 0.9433\n",
      "Epoch 151/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1269 - accuracy: 0.9919 - val_loss: 0.2914 - val_accuracy: 0.9400\n",
      "Epoch 152/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1260 - accuracy: 0.9930 - val_loss: 0.2558 - val_accuracy: 0.9433\n",
      "Epoch 153/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1234 - accuracy: 0.9944 - val_loss: 0.3127 - val_accuracy: 0.9333\n",
      "Epoch 154/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1216 - accuracy: 0.9941 - val_loss: 0.2781 - val_accuracy: 0.9433\n",
      "Epoch 155/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1199 - accuracy: 0.9944 - val_loss: 0.2619 - val_accuracy: 0.9467\n",
      "Epoch 156/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1173 - accuracy: 0.9952 - val_loss: 0.2703 - val_accuracy: 0.9500\n",
      "Epoch 157/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1238 - accuracy: 0.9926 - val_loss: 0.2967 - val_accuracy: 0.9467\n",
      "Epoch 158/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1222 - accuracy: 0.9933 - val_loss: 0.2688 - val_accuracy: 0.9467\n",
      "Epoch 159/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1216 - accuracy: 0.9941 - val_loss: 0.2855 - val_accuracy: 0.9400\n",
      "Epoch 160/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1220 - accuracy: 0.9926 - val_loss: 0.2911 - val_accuracy: 0.9433\n",
      "Epoch 161/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1156 - accuracy: 0.9963 - val_loss: 0.2626 - val_accuracy: 0.9467\n",
      "Epoch 162/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1174 - accuracy: 0.9922 - val_loss: 0.2360 - val_accuracy: 0.9500\n",
      "Epoch 163/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1168 - accuracy: 0.9941 - val_loss: 0.2446 - val_accuracy: 0.9467\n",
      "Epoch 164/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1181 - accuracy: 0.9937 - val_loss: 0.2739 - val_accuracy: 0.9467\n",
      "Epoch 165/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1194 - accuracy: 0.9937 - val_loss: 0.2500 - val_accuracy: 0.9400\n",
      "Epoch 166/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1201 - accuracy: 0.9930 - val_loss: 0.2495 - val_accuracy: 0.9433\n",
      "Epoch 167/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1197 - accuracy: 0.9952 - val_loss: 0.2483 - val_accuracy: 0.9533\n",
      "Epoch 168/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1193 - accuracy: 0.9937 - val_loss: 0.2445 - val_accuracy: 0.9433\n",
      "Epoch 169/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1171 - accuracy: 0.9941 - val_loss: 0.2719 - val_accuracy: 0.9467\n",
      "Epoch 170/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1203 - accuracy: 0.9948 - val_loss: 0.2466 - val_accuracy: 0.9433\n",
      "Epoch 171/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1173 - accuracy: 0.9956 - val_loss: 0.2541 - val_accuracy: 0.9467\n",
      "Epoch 172/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1200 - accuracy: 0.9933 - val_loss: 0.2778 - val_accuracy: 0.9400\n",
      "Epoch 173/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1202 - accuracy: 0.9930 - val_loss: 0.3071 - val_accuracy: 0.9400\n",
      "Epoch 174/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1213 - accuracy: 0.9922 - val_loss: 0.2773 - val_accuracy: 0.9433\n",
      "Epoch 175/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1231 - accuracy: 0.9919 - val_loss: 0.2568 - val_accuracy: 0.9400\n",
      "Epoch 176/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1280 - accuracy: 0.9889 - val_loss: 0.2704 - val_accuracy: 0.9433\n",
      "Epoch 177/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1565 - accuracy: 0.9796 - val_loss: 0.2926 - val_accuracy: 0.9433\n",
      "Epoch 178/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1811 - accuracy: 0.9726 - val_loss: 0.3034 - val_accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1592 - accuracy: 0.9863 - val_loss: 0.2897 - val_accuracy: 0.9467\n",
      "Epoch 180/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1494 - accuracy: 0.9893 - val_loss: 0.3243 - val_accuracy: 0.9400\n",
      "Epoch 181/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1417 - accuracy: 0.9896 - val_loss: 0.3226 - val_accuracy: 0.9400\n",
      "Epoch 182/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1317 - accuracy: 0.9930 - val_loss: 0.2831 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1302 - accuracy: 0.9907 - val_loss: 0.2838 - val_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1264 - accuracy: 0.9933 - val_loss: 0.2699 - val_accuracy: 0.9467\n",
      "Epoch 185/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1222 - accuracy: 0.9952 - val_loss: 0.2983 - val_accuracy: 0.9400\n",
      "Epoch 186/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1196 - accuracy: 0.9941 - val_loss: 0.2694 - val_accuracy: 0.9400\n",
      "Epoch 187/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1187 - accuracy: 0.9937 - val_loss: 0.2887 - val_accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1137 - accuracy: 0.9956 - val_loss: 0.2982 - val_accuracy: 0.9367\n",
      "Epoch 189/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1141 - accuracy: 0.9941 - val_loss: 0.2579 - val_accuracy: 0.9400\n",
      "Epoch 190/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1129 - accuracy: 0.9948 - val_loss: 0.2464 - val_accuracy: 0.9433\n",
      "Epoch 191/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1136 - accuracy: 0.9948 - val_loss: 0.3044 - val_accuracy: 0.9333\n",
      "Epoch 192/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1128 - accuracy: 0.9952 - val_loss: 0.2883 - val_accuracy: 0.9300\n",
      "Epoch 193/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1096 - accuracy: 0.9963 - val_loss: 0.2573 - val_accuracy: 0.9433\n",
      "Epoch 194/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1111 - accuracy: 0.9948 - val_loss: 0.2708 - val_accuracy: 0.9400\n",
      "Epoch 195/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1101 - accuracy: 0.9956 - val_loss: 0.3029 - val_accuracy: 0.9333\n",
      "Epoch 196/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1197 - accuracy: 0.9919 - val_loss: 0.2665 - val_accuracy: 0.9433\n",
      "Epoch 197/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1413 - accuracy: 0.9867 - val_loss: 0.2858 - val_accuracy: 0.9400\n",
      "Epoch 198/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1449 - accuracy: 0.9856 - val_loss: 0.2778 - val_accuracy: 0.9400\n",
      "Epoch 199/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1398 - accuracy: 0.9896 - val_loss: 0.2691 - val_accuracy: 0.9400\n",
      "Epoch 200/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1349 - accuracy: 0.9896 - val_loss: 0.2881 - val_accuracy: 0.9367\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearchCV() object and fit it to the training data, also evaluate with validation data.\n",
    "grid = GridSearchCV(model_grid, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train,\n",
    "                       y_train,\n",
    "                       validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9641d",
   "metadata": {},
   "source": [
    "### Check best hyperparameters from Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24baf1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter by GridsearchCV(): {'C': 0.02, 'dropout_ratio': 0.2, 'hidden_units': 32} \n",
      "\n",
      "Best score by using this hyperparameter: 0.9570 \n",
      "\n",
      "\n",
      "For parameter {'C': 0.02, 'dropout_ratio': 0.2, 'hidden_units': 16}: Mean score 0.9478 (with std 0.0085)\n",
      "\n",
      "For parameter {'C': 0.02, 'dropout_ratio': 0.2, 'hidden_units': 32}: Mean score 0.9570 (with std 0.0066)\n",
      "\n",
      "For parameter {'C': 0.02, 'dropout_ratio': 0.5, 'hidden_units': 16}: Mean score 0.9404 (with std 0.0099)\n",
      "\n",
      "For parameter {'C': 0.02, 'dropout_ratio': 0.5, 'hidden_units': 32}: Mean score 0.9504 (with std 0.0098)\n",
      "\n",
      "For parameter {'C': 0.2, 'dropout_ratio': 0.2, 'hidden_units': 16}: Mean score 0.8504 (with std 0.0202)\n",
      "\n",
      "For parameter {'C': 0.2, 'dropout_ratio': 0.2, 'hidden_units': 32}: Mean score 0.8504 (with std 0.0202)\n",
      "\n",
      "For parameter {'C': 0.2, 'dropout_ratio': 0.5, 'hidden_units': 16}: Mean score 0.8504 (with std 0.0202)\n",
      "\n",
      "For parameter {'C': 0.2, 'dropout_ratio': 0.5, 'hidden_units': 32}: Mean score 0.8504 (with std 0.0202)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters and score of grid model\n",
    "print('Best hyperparameter by GridsearchCV():', grid_result.best_params_, '\\n')\n",
    "print('Best score by using this hyperparameter: %.4f' %(grid_result.best_score_), '\\n\\n')\n",
    "\n",
    "# Print mean, std of grid model\n",
    "means_grid = grid_result.cv_results_['mean_test_score']\n",
    "stds_grid = grid_result.cv_results_['std_test_score']\n",
    "params_grid = grid_result.cv_results_['params']\n",
    "    \n",
    "for mean, stdev, param in zip(means_grid, stds_grid, params_grid):\n",
    "    print('For parameter %r: Mean score %.4f (with std %.4f)\\n'% (param, mean, stdev))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa14ba",
   "metadata": {},
   "source": [
    "### Formulate neural network from GridsearchCV\n",
    "**According to the result of Gridsearch, we formulate a neural network with best hyperparameters from Gridsearch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "417c41ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_250 (Dense)            (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 9,666\n",
      "Trainable params: 9,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defeine new layer variable. \n",
    "hidden_units_grid = 32\n",
    "C_grid = 0.02\n",
    "dropout_ratio_grid = 0.2\n",
    "\n",
    "# Define training variable\n",
    "epochs_grid = 200\n",
    "batch_size_grid = 128\n",
    "\n",
    "# Create the new model with l2 regularization and drop out layer.\n",
    "model_grid = models.Sequential()\n",
    "model_grid.add(layers.Dense(units=hidden_units_grid, activation='relu', \n",
    "                            kernel_regularizer=regularizers.l2(C_grid), input_shape=[input_units]))\n",
    "model_grid.add(layers.Dropout(dropout_ratio_grid))\n",
    "model_grid.add(layers.Dense(units=hidden_units_grid, activation='relu', \n",
    "                            kernel_regularizer=regularizers.l2(C_grid)))\n",
    "model_grid.add(layers.Dropout(dropout_ratio_grid))\n",
    "model_grid.add(layers.Dense(units=hidden_units_grid, activation='relu', \n",
    "                            kernel_regularizer=regularizers.l2(C_grid)))\n",
    "model_grid.add(layers.Dropout(dropout_ratio_grid))\n",
    "model_grid.add(layers.Dense(units=hidden_units_grid, activation='relu', \n",
    "                            kernel_regularizer=regularizers.l2(C_grid)))\n",
    "model_grid.add(layers.Dropout(dropout_ratio_grid))\n",
    "model_grid.add(layers.Dense(units=output_units, activation='softmax'))\n",
    "\n",
    "# Configure the model with optimizer, loss function and metrics.\n",
    "model_grid.compile(optimizer=optimizers.Adam(),\n",
    "                   loss=losses.CategoricalCrossentropy(),\n",
    "                   metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "# Check result.\n",
    "print(model_grid.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3b39330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "2700/2700 [==============================] - 1s 401us/sample - loss: 3.4650 - categorical_accuracy: 0.7659 - val_loss: 3.1116 - val_categorical_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "2700/2700 [==============================] - 0s 27us/sample - loss: 2.9122 - categorical_accuracy: 0.8326 - val_loss: 2.6538 - val_categorical_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "2700/2700 [==============================] - 0s 26us/sample - loss: 2.4787 - categorical_accuracy: 0.8419 - val_loss: 2.2679 - val_categorical_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 2.1079 - categorical_accuracy: 0.8489 - val_loss: 1.9448 - val_categorical_accuracy: 0.8367\n",
      "Epoch 5/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 1.8180 - categorical_accuracy: 0.8544 - val_loss: 1.6687 - val_categorical_accuracy: 0.8367\n",
      "Epoch 6/200\n",
      "2700/2700 [==============================] - 0s 26us/sample - loss: 1.5617 - categorical_accuracy: 0.8515 - val_loss: 1.4399 - val_categorical_accuracy: 0.8367\n",
      "Epoch 7/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 1.3530 - categorical_accuracy: 0.8581 - val_loss: 1.2405 - val_categorical_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 1.1786 - categorical_accuracy: 0.8589 - val_loss: 1.0791 - val_categorical_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 1.0231 - categorical_accuracy: 0.8622 - val_loss: 0.9471 - val_categorical_accuracy: 0.8633\n",
      "Epoch 10/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.8987 - categorical_accuracy: 0.8781 - val_loss: 0.8338 - val_categorical_accuracy: 0.8833\n",
      "Epoch 11/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.7950 - categorical_accuracy: 0.8915 - val_loss: 0.7545 - val_categorical_accuracy: 0.8867\n",
      "Epoch 12/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.7069 - categorical_accuracy: 0.8948 - val_loss: 0.6754 - val_categorical_accuracy: 0.9100\n",
      "Epoch 13/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.6423 - categorical_accuracy: 0.9133 - val_loss: 0.6069 - val_categorical_accuracy: 0.9200\n",
      "Epoch 14/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.5858 - categorical_accuracy: 0.9196 - val_loss: 0.5497 - val_categorical_accuracy: 0.9200\n",
      "Epoch 15/200\n",
      "2700/2700 [==============================] - 0s 26us/sample - loss: 0.5221 - categorical_accuracy: 0.9326 - val_loss: 0.5019 - val_categorical_accuracy: 0.9267\n",
      "Epoch 16/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.4814 - categorical_accuracy: 0.9367 - val_loss: 0.4762 - val_categorical_accuracy: 0.9333\n",
      "Epoch 17/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.4358 - categorical_accuracy: 0.9481 - val_loss: 0.4507 - val_categorical_accuracy: 0.9400\n",
      "Epoch 18/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.4040 - categorical_accuracy: 0.9515 - val_loss: 0.4263 - val_categorical_accuracy: 0.9433\n",
      "Epoch 19/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.3843 - categorical_accuracy: 0.9556 - val_loss: 0.4018 - val_categorical_accuracy: 0.9400\n",
      "Epoch 20/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.3581 - categorical_accuracy: 0.9567 - val_loss: 0.3922 - val_categorical_accuracy: 0.9467\n",
      "Epoch 21/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.3484 - categorical_accuracy: 0.9600 - val_loss: 0.3893 - val_categorical_accuracy: 0.9467\n",
      "Epoch 22/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.3194 - categorical_accuracy: 0.9644 - val_loss: 0.3681 - val_categorical_accuracy: 0.9467\n",
      "Epoch 23/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.3039 - categorical_accuracy: 0.9689 - val_loss: 0.3518 - val_categorical_accuracy: 0.9500\n",
      "Epoch 24/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.2866 - categorical_accuracy: 0.9715 - val_loss: 0.3515 - val_categorical_accuracy: 0.9400\n",
      "Epoch 25/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.2757 - categorical_accuracy: 0.9759 - val_loss: 0.3622 - val_categorical_accuracy: 0.9400\n",
      "Epoch 26/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.2665 - categorical_accuracy: 0.9756 - val_loss: 0.3514 - val_categorical_accuracy: 0.9367\n",
      "Epoch 27/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.2646 - categorical_accuracy: 0.9756 - val_loss: 0.3398 - val_categorical_accuracy: 0.9400\n",
      "Epoch 28/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.2595 - categorical_accuracy: 0.9733 - val_loss: 0.3253 - val_categorical_accuracy: 0.9433\n",
      "Epoch 29/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.2462 - categorical_accuracy: 0.9793 - val_loss: 0.3362 - val_categorical_accuracy: 0.9433\n",
      "Epoch 30/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.2430 - categorical_accuracy: 0.9793 - val_loss: 0.3202 - val_categorical_accuracy: 0.9433\n",
      "Epoch 31/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.2326 - categorical_accuracy: 0.9800 - val_loss: 0.3312 - val_categorical_accuracy: 0.9333\n",
      "Epoch 32/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.2211 - categorical_accuracy: 0.9830 - val_loss: 0.3255 - val_categorical_accuracy: 0.9433\n",
      "Epoch 33/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.2161 - categorical_accuracy: 0.9800 - val_loss: 0.3331 - val_categorical_accuracy: 0.9433\n",
      "Epoch 34/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.2089 - categorical_accuracy: 0.9830 - val_loss: 0.3321 - val_categorical_accuracy: 0.9467\n",
      "Epoch 35/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.2100 - categorical_accuracy: 0.9856 - val_loss: 0.3215 - val_categorical_accuracy: 0.9400\n",
      "Epoch 36/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.2016 - categorical_accuracy: 0.9859 - val_loss: 0.3108 - val_categorical_accuracy: 0.9400\n",
      "Epoch 37/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.2002 - categorical_accuracy: 0.9848 - val_loss: 0.2966 - val_categorical_accuracy: 0.9400\n",
      "Epoch 38/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.2008 - categorical_accuracy: 0.9819 - val_loss: 0.2988 - val_categorical_accuracy: 0.9433\n",
      "Epoch 39/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1886 - categorical_accuracy: 0.9878 - val_loss: 0.3042 - val_categorical_accuracy: 0.9400\n",
      "Epoch 40/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1897 - categorical_accuracy: 0.9863 - val_loss: 0.3244 - val_categorical_accuracy: 0.9433\n",
      "Epoch 41/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1900 - categorical_accuracy: 0.9870 - val_loss: 0.3042 - val_categorical_accuracy: 0.9400\n",
      "Epoch 42/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1861 - categorical_accuracy: 0.9837 - val_loss: 0.2953 - val_categorical_accuracy: 0.9433\n",
      "Epoch 43/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1855 - categorical_accuracy: 0.9848 - val_loss: 0.2805 - val_categorical_accuracy: 0.9533\n",
      "Epoch 44/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1849 - categorical_accuracy: 0.9852 - val_loss: 0.2873 - val_categorical_accuracy: 0.9467\n",
      "Epoch 45/200\n",
      "2700/2700 [==============================] - 0s 26us/sample - loss: 0.1879 - categorical_accuracy: 0.9852 - val_loss: 0.3036 - val_categorical_accuracy: 0.9400\n",
      "Epoch 46/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.1795 - categorical_accuracy: 0.9870 - val_loss: 0.3065 - val_categorical_accuracy: 0.9367\n",
      "Epoch 47/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.1795 - categorical_accuracy: 0.9870 - val_loss: 0.3079 - val_categorical_accuracy: 0.9333\n",
      "Epoch 48/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1722 - categorical_accuracy: 0.9904 - val_loss: 0.3064 - val_categorical_accuracy: 0.9400\n",
      "Epoch 49/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1721 - categorical_accuracy: 0.9889 - val_loss: 0.3330 - val_categorical_accuracy: 0.9400\n",
      "Epoch 50/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1796 - categorical_accuracy: 0.9848 - val_loss: 0.3054 - val_categorical_accuracy: 0.9400\n",
      "Epoch 51/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1766 - categorical_accuracy: 0.9874 - val_loss: 0.2788 - val_categorical_accuracy: 0.9467\n",
      "Epoch 52/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1752 - categorical_accuracy: 0.9867 - val_loss: 0.3095 - val_categorical_accuracy: 0.9433\n",
      "Epoch 53/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1815 - categorical_accuracy: 0.9819 - val_loss: 0.2952 - val_categorical_accuracy: 0.9433\n",
      "Epoch 54/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1840 - categorical_accuracy: 0.9848 - val_loss: 0.3083 - val_categorical_accuracy: 0.9433\n",
      "Epoch 55/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1778 - categorical_accuracy: 0.9844 - val_loss: 0.2909 - val_categorical_accuracy: 0.9500\n",
      "Epoch 56/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1719 - categorical_accuracy: 0.9893 - val_loss: 0.3047 - val_categorical_accuracy: 0.9433\n",
      "Epoch 57/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1759 - categorical_accuracy: 0.9904 - val_loss: 0.2989 - val_categorical_accuracy: 0.9433\n",
      "Epoch 58/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1741 - categorical_accuracy: 0.9870 - val_loss: 0.3113 - val_categorical_accuracy: 0.9433\n",
      "Epoch 59/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1748 - categorical_accuracy: 0.9874 - val_loss: 0.3322 - val_categorical_accuracy: 0.9400\n",
      "Epoch 60/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1641 - categorical_accuracy: 0.9911 - val_loss: 0.3166 - val_categorical_accuracy: 0.9367\n",
      "Epoch 61/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1654 - categorical_accuracy: 0.9915 - val_loss: 0.3317 - val_categorical_accuracy: 0.9333\n",
      "Epoch 62/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1640 - categorical_accuracy: 0.9915 - val_loss: 0.3058 - val_categorical_accuracy: 0.9467\n",
      "Epoch 63/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.1610 - categorical_accuracy: 0.9900 - val_loss: 0.3104 - val_categorical_accuracy: 0.9367\n",
      "Epoch 64/200\n",
      "2700/2700 [==============================] - 0s 26us/sample - loss: 0.1628 - categorical_accuracy: 0.9896 - val_loss: 0.2862 - val_categorical_accuracy: 0.9333\n",
      "Epoch 65/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1607 - categorical_accuracy: 0.9900 - val_loss: 0.2883 - val_categorical_accuracy: 0.9467\n",
      "Epoch 66/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1618 - categorical_accuracy: 0.9904 - val_loss: 0.3110 - val_categorical_accuracy: 0.9367\n",
      "Epoch 67/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1593 - categorical_accuracy: 0.9896 - val_loss: 0.2889 - val_categorical_accuracy: 0.9367\n",
      "Epoch 68/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1644 - categorical_accuracy: 0.9889 - val_loss: 0.3025 - val_categorical_accuracy: 0.9400\n",
      "Epoch 69/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1698 - categorical_accuracy: 0.9874 - val_loss: 0.2780 - val_categorical_accuracy: 0.9367\n",
      "Epoch 70/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1714 - categorical_accuracy: 0.9856 - val_loss: 0.2892 - val_categorical_accuracy: 0.9400\n",
      "Epoch 71/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.1698 - categorical_accuracy: 0.9863 - val_loss: 0.2986 - val_categorical_accuracy: 0.9400\n",
      "Epoch 72/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1614 - categorical_accuracy: 0.9889 - val_loss: 0.2833 - val_categorical_accuracy: 0.9367\n",
      "Epoch 73/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1597 - categorical_accuracy: 0.9900 - val_loss: 0.2939 - val_categorical_accuracy: 0.9400\n",
      "Epoch 74/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1586 - categorical_accuracy: 0.9904 - val_loss: 0.2876 - val_categorical_accuracy: 0.9433\n",
      "Epoch 75/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1553 - categorical_accuracy: 0.9915 - val_loss: 0.2959 - val_categorical_accuracy: 0.9367\n",
      "Epoch 76/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1508 - categorical_accuracy: 0.9915 - val_loss: 0.2923 - val_categorical_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1481 - categorical_accuracy: 0.9926 - val_loss: 0.3069 - val_categorical_accuracy: 0.9400\n",
      "Epoch 78/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1564 - categorical_accuracy: 0.9893 - val_loss: 0.3088 - val_categorical_accuracy: 0.9400\n",
      "Epoch 79/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1515 - categorical_accuracy: 0.9919 - val_loss: 0.3234 - val_categorical_accuracy: 0.9367\n",
      "Epoch 80/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1529 - categorical_accuracy: 0.9919 - val_loss: 0.3315 - val_categorical_accuracy: 0.9333\n",
      "Epoch 81/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1555 - categorical_accuracy: 0.9911 - val_loss: 0.3194 - val_categorical_accuracy: 0.9400\n",
      "Epoch 82/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1556 - categorical_accuracy: 0.9896 - val_loss: 0.2949 - val_categorical_accuracy: 0.9333\n",
      "Epoch 83/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1500 - categorical_accuracy: 0.9915 - val_loss: 0.3563 - val_categorical_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1539 - categorical_accuracy: 0.9889 - val_loss: 0.2939 - val_categorical_accuracy: 0.9433\n",
      "Epoch 85/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1505 - categorical_accuracy: 0.9919 - val_loss: 0.2842 - val_categorical_accuracy: 0.9433\n",
      "Epoch 86/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1524 - categorical_accuracy: 0.9889 - val_loss: 0.2970 - val_categorical_accuracy: 0.9400\n",
      "Epoch 87/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1631 - categorical_accuracy: 0.9844 - val_loss: 0.3003 - val_categorical_accuracy: 0.9467\n",
      "Epoch 88/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1574 - categorical_accuracy: 0.9870 - val_loss: 0.3011 - val_categorical_accuracy: 0.9400\n",
      "Epoch 89/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1540 - categorical_accuracy: 0.9893 - val_loss: 0.3054 - val_categorical_accuracy: 0.9333\n",
      "Epoch 90/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1640 - categorical_accuracy: 0.9874 - val_loss: 0.3223 - val_categorical_accuracy: 0.9267\n",
      "Epoch 91/200\n",
      "2700/2700 [==============================] - 0s 19us/sample - loss: 0.1596 - categorical_accuracy: 0.9885 - val_loss: 0.2864 - val_categorical_accuracy: 0.9333\n",
      "Epoch 92/200\n",
      "2700/2700 [==============================] - 0s 25us/sample - loss: 0.1536 - categorical_accuracy: 0.9904 - val_loss: 0.2793 - val_categorical_accuracy: 0.9400\n",
      "Epoch 93/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1663 - categorical_accuracy: 0.9885 - val_loss: 0.3009 - val_categorical_accuracy: 0.9400\n",
      "Epoch 94/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1562 - categorical_accuracy: 0.9896 - val_loss: 0.3186 - val_categorical_accuracy: 0.9367\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1537 - categorical_accuracy: 0.9893 - val_loss: 0.2987 - val_categorical_accuracy: 0.9433\n",
      "Epoch 96/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1424 - categorical_accuracy: 0.9944 - val_loss: 0.3121 - val_categorical_accuracy: 0.9367\n",
      "Epoch 97/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1419 - categorical_accuracy: 0.9937 - val_loss: 0.3040 - val_categorical_accuracy: 0.9300\n",
      "Epoch 98/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1437 - categorical_accuracy: 0.9919 - val_loss: 0.2940 - val_categorical_accuracy: 0.9333\n",
      "Epoch 99/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1378 - categorical_accuracy: 0.9941 - val_loss: 0.2837 - val_categorical_accuracy: 0.9467\n",
      "Epoch 100/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1385 - categorical_accuracy: 0.9922 - val_loss: 0.3105 - val_categorical_accuracy: 0.9400\n",
      "Epoch 101/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1342 - categorical_accuracy: 0.9956 - val_loss: 0.3106 - val_categorical_accuracy: 0.9300\n",
      "Epoch 102/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1373 - categorical_accuracy: 0.9911 - val_loss: 0.3060 - val_categorical_accuracy: 0.9367\n",
      "Epoch 103/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1370 - categorical_accuracy: 0.9915 - val_loss: 0.2796 - val_categorical_accuracy: 0.9433\n",
      "Epoch 104/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1358 - categorical_accuracy: 0.9941 - val_loss: 0.3025 - val_categorical_accuracy: 0.9333\n",
      "Epoch 105/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1438 - categorical_accuracy: 0.9881 - val_loss: 0.2932 - val_categorical_accuracy: 0.9400\n",
      "Epoch 106/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1494 - categorical_accuracy: 0.9867 - val_loss: 0.3055 - val_categorical_accuracy: 0.9367\n",
      "Epoch 107/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1504 - categorical_accuracy: 0.9907 - val_loss: 0.2856 - val_categorical_accuracy: 0.9367\n",
      "Epoch 108/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1489 - categorical_accuracy: 0.9889 - val_loss: 0.2676 - val_categorical_accuracy: 0.9367\n",
      "Epoch 109/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1490 - categorical_accuracy: 0.9889 - val_loss: 0.2883 - val_categorical_accuracy: 0.9467\n",
      "Epoch 110/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1438 - categorical_accuracy: 0.9944 - val_loss: 0.2989 - val_categorical_accuracy: 0.9367\n",
      "Epoch 111/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1396 - categorical_accuracy: 0.9930 - val_loss: 0.3064 - val_categorical_accuracy: 0.9300\n",
      "Epoch 112/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1379 - categorical_accuracy: 0.9941 - val_loss: 0.3041 - val_categorical_accuracy: 0.9400\n",
      "Epoch 113/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1364 - categorical_accuracy: 0.9941 - val_loss: 0.3286 - val_categorical_accuracy: 0.9433\n",
      "Epoch 114/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1450 - categorical_accuracy: 0.9900 - val_loss: 0.3211 - val_categorical_accuracy: 0.9400\n",
      "Epoch 115/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1413 - categorical_accuracy: 0.9930 - val_loss: 0.3127 - val_categorical_accuracy: 0.9367\n",
      "Epoch 116/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1645 - categorical_accuracy: 0.9841 - val_loss: 0.3555 - val_categorical_accuracy: 0.9367\n",
      "Epoch 117/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1633 - categorical_accuracy: 0.9852 - val_loss: 0.3196 - val_categorical_accuracy: 0.9333\n",
      "Epoch 118/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1553 - categorical_accuracy: 0.9904 - val_loss: 0.3262 - val_categorical_accuracy: 0.9333\n",
      "Epoch 119/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1515 - categorical_accuracy: 0.9881 - val_loss: 0.3310 - val_categorical_accuracy: 0.9367\n",
      "Epoch 120/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1468 - categorical_accuracy: 0.9911 - val_loss: 0.3186 - val_categorical_accuracy: 0.9400\n",
      "Epoch 121/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1474 - categorical_accuracy: 0.9900 - val_loss: 0.3252 - val_categorical_accuracy: 0.9467\n",
      "Epoch 122/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1424 - categorical_accuracy: 0.9915 - val_loss: 0.3110 - val_categorical_accuracy: 0.9367\n",
      "Epoch 123/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1412 - categorical_accuracy: 0.9933 - val_loss: 0.3185 - val_categorical_accuracy: 0.9433\n",
      "Epoch 124/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1351 - categorical_accuracy: 0.9956 - val_loss: 0.3090 - val_categorical_accuracy: 0.9433\n",
      "Epoch 125/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1383 - categorical_accuracy: 0.9907 - val_loss: 0.3047 - val_categorical_accuracy: 0.9467\n",
      "Epoch 126/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1335 - categorical_accuracy: 0.9941 - val_loss: 0.3243 - val_categorical_accuracy: 0.9467\n",
      "Epoch 127/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1377 - categorical_accuracy: 0.9915 - val_loss: 0.2864 - val_categorical_accuracy: 0.9467\n",
      "Epoch 128/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1529 - categorical_accuracy: 0.9826 - val_loss: 0.3103 - val_categorical_accuracy: 0.9467\n",
      "Epoch 129/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1542 - categorical_accuracy: 0.9881 - val_loss: 0.3258 - val_categorical_accuracy: 0.9400\n",
      "Epoch 130/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1381 - categorical_accuracy: 0.9941 - val_loss: 0.3180 - val_categorical_accuracy: 0.9333\n",
      "Epoch 131/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1358 - categorical_accuracy: 0.9944 - val_loss: 0.2958 - val_categorical_accuracy: 0.9333\n",
      "Epoch 132/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1363 - categorical_accuracy: 0.9933 - val_loss: 0.3072 - val_categorical_accuracy: 0.9367\n",
      "Epoch 133/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1343 - categorical_accuracy: 0.9937 - val_loss: 0.3160 - val_categorical_accuracy: 0.9333\n",
      "Epoch 134/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1333 - categorical_accuracy: 0.9926 - val_loss: 0.2981 - val_categorical_accuracy: 0.9367\n",
      "Epoch 135/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1339 - categorical_accuracy: 0.9911 - val_loss: 0.3089 - val_categorical_accuracy: 0.9400\n",
      "Epoch 136/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1313 - categorical_accuracy: 0.9933 - val_loss: 0.2947 - val_categorical_accuracy: 0.9333\n",
      "Epoch 137/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1265 - categorical_accuracy: 0.9941 - val_loss: 0.2798 - val_categorical_accuracy: 0.9367\n",
      "Epoch 138/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1228 - categorical_accuracy: 0.9970 - val_loss: 0.3278 - val_categorical_accuracy: 0.9400\n",
      "Epoch 139/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1291 - categorical_accuracy: 0.9926 - val_loss: 0.3240 - val_categorical_accuracy: 0.9400\n",
      "Epoch 140/200\n",
      "2700/2700 [==============================] - 0s 26us/sample - loss: 0.1261 - categorical_accuracy: 0.9948 - val_loss: 0.3100 - val_categorical_accuracy: 0.9400\n",
      "Epoch 141/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1267 - categorical_accuracy: 0.9944 - val_loss: 0.2857 - val_categorical_accuracy: 0.9467\n",
      "Epoch 142/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1275 - categorical_accuracy: 0.9926 - val_loss: 0.3059 - val_categorical_accuracy: 0.9433\n",
      "Epoch 143/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1294 - categorical_accuracy: 0.9907 - val_loss: 0.2921 - val_categorical_accuracy: 0.9467\n",
      "Epoch 144/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1249 - categorical_accuracy: 0.9926 - val_loss: 0.2972 - val_categorical_accuracy: 0.9367\n",
      "Epoch 145/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1392 - categorical_accuracy: 0.9863 - val_loss: 0.3547 - val_categorical_accuracy: 0.9400\n",
      "Epoch 146/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1413 - categorical_accuracy: 0.9878 - val_loss: 0.3263 - val_categorical_accuracy: 0.9333\n",
      "Epoch 147/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1473 - categorical_accuracy: 0.9870 - val_loss: 0.2984 - val_categorical_accuracy: 0.9433\n",
      "Epoch 148/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1348 - categorical_accuracy: 0.9907 - val_loss: 0.3260 - val_categorical_accuracy: 0.9433\n",
      "Epoch 149/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1313 - categorical_accuracy: 0.9937 - val_loss: 0.3095 - val_categorical_accuracy: 0.9433\n",
      "Epoch 150/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1258 - categorical_accuracy: 0.9941 - val_loss: 0.3090 - val_categorical_accuracy: 0.9433\n",
      "Epoch 151/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1246 - categorical_accuracy: 0.9952 - val_loss: 0.2646 - val_categorical_accuracy: 0.9467\n",
      "Epoch 152/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1221 - categorical_accuracy: 0.9937 - val_loss: 0.3035 - val_categorical_accuracy: 0.9433\n",
      "Epoch 153/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1254 - categorical_accuracy: 0.9933 - val_loss: 0.3337 - val_categorical_accuracy: 0.9433\n",
      "Epoch 154/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1237 - categorical_accuracy: 0.9944 - val_loss: 0.3221 - val_categorical_accuracy: 0.9400\n",
      "Epoch 155/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1263 - categorical_accuracy: 0.9926 - val_loss: 0.2964 - val_categorical_accuracy: 0.9433\n",
      "Epoch 156/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1236 - categorical_accuracy: 0.9930 - val_loss: 0.2920 - val_categorical_accuracy: 0.9367\n",
      "Epoch 157/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1234 - categorical_accuracy: 0.9956 - val_loss: 0.2800 - val_categorical_accuracy: 0.9467\n",
      "Epoch 158/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1237 - categorical_accuracy: 0.9926 - val_loss: 0.2602 - val_categorical_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1199 - categorical_accuracy: 0.9974 - val_loss: 0.2876 - val_categorical_accuracy: 0.9433\n",
      "Epoch 160/200\n",
      "2700/2700 [==============================] - 0s 24us/sample - loss: 0.1647 - categorical_accuracy: 0.9774 - val_loss: 0.2897 - val_categorical_accuracy: 0.9433\n",
      "Epoch 161/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1680 - categorical_accuracy: 0.9822 - val_loss: 0.3504 - val_categorical_accuracy: 0.9367\n",
      "Epoch 162/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1544 - categorical_accuracy: 0.9874 - val_loss: 0.3200 - val_categorical_accuracy: 0.9433\n",
      "Epoch 163/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1463 - categorical_accuracy: 0.9893 - val_loss: 0.3403 - val_categorical_accuracy: 0.9400\n",
      "Epoch 164/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1409 - categorical_accuracy: 0.9900 - val_loss: 0.3273 - val_categorical_accuracy: 0.9433\n",
      "Epoch 165/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1395 - categorical_accuracy: 0.9904 - val_loss: 0.3324 - val_categorical_accuracy: 0.9367\n",
      "Epoch 166/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1333 - categorical_accuracy: 0.9907 - val_loss: 0.3394 - val_categorical_accuracy: 0.9400\n",
      "Epoch 167/200\n",
      "2700/2700 [==============================] - ETA: 0s - loss: 0.1408 - categorical_accuracy: 0.99 - 0s 22us/sample - loss: 0.1264 - categorical_accuracy: 0.9959 - val_loss: 0.3247 - val_categorical_accuracy: 0.9400\n",
      "Epoch 168/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1238 - categorical_accuracy: 0.9956 - val_loss: 0.3207 - val_categorical_accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1221 - categorical_accuracy: 0.9963 - val_loss: 0.3186 - val_categorical_accuracy: 0.9433\n",
      "Epoch 170/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1155 - categorical_accuracy: 0.9967 - val_loss: 0.3059 - val_categorical_accuracy: 0.9400\n",
      "Epoch 171/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1167 - categorical_accuracy: 0.9952 - val_loss: 0.3022 - val_categorical_accuracy: 0.9433\n",
      "Epoch 172/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1221 - categorical_accuracy: 0.9930 - val_loss: 0.3041 - val_categorical_accuracy: 0.9400\n",
      "Epoch 173/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1256 - categorical_accuracy: 0.9911 - val_loss: 0.3040 - val_categorical_accuracy: 0.9467\n",
      "Epoch 174/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1230 - categorical_accuracy: 0.9948 - val_loss: 0.3016 - val_categorical_accuracy: 0.9367\n",
      "Epoch 175/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1246 - categorical_accuracy: 0.9919 - val_loss: 0.2952 - val_categorical_accuracy: 0.9367\n",
      "Epoch 176/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1316 - categorical_accuracy: 0.9922 - val_loss: 0.3273 - val_categorical_accuracy: 0.9400\n",
      "Epoch 177/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1397 - categorical_accuracy: 0.9874 - val_loss: 0.3013 - val_categorical_accuracy: 0.9433\n",
      "Epoch 178/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1313 - categorical_accuracy: 0.9911 - val_loss: 0.3180 - val_categorical_accuracy: 0.9467\n",
      "Epoch 179/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1266 - categorical_accuracy: 0.9930 - val_loss: 0.3336 - val_categorical_accuracy: 0.9467\n",
      "Epoch 180/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1286 - categorical_accuracy: 0.9926 - val_loss: 0.3392 - val_categorical_accuracy: 0.9433\n",
      "Epoch 181/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1205 - categorical_accuracy: 0.9952 - val_loss: 0.3259 - val_categorical_accuracy: 0.9433\n",
      "Epoch 182/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1220 - categorical_accuracy: 0.9952 - val_loss: 0.2952 - val_categorical_accuracy: 0.9433\n",
      "Epoch 183/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1207 - categorical_accuracy: 0.9948 - val_loss: 0.3337 - val_categorical_accuracy: 0.9333\n",
      "Epoch 184/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1219 - categorical_accuracy: 0.9933 - val_loss: 0.3005 - val_categorical_accuracy: 0.9433\n",
      "Epoch 185/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1211 - categorical_accuracy: 0.9944 - val_loss: 0.3418 - val_categorical_accuracy: 0.9367\n",
      "Epoch 186/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1187 - categorical_accuracy: 0.9941 - val_loss: 0.2989 - val_categorical_accuracy: 0.9300\n",
      "Epoch 187/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1139 - categorical_accuracy: 0.9970 - val_loss: 0.2986 - val_categorical_accuracy: 0.9367\n",
      "Epoch 188/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1194 - categorical_accuracy: 0.9941 - val_loss: 0.3072 - val_categorical_accuracy: 0.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1131 - categorical_accuracy: 0.9952 - val_loss: 0.2733 - val_categorical_accuracy: 0.9433\n",
      "Epoch 190/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1666 - categorical_accuracy: 0.9748 - val_loss: 0.2818 - val_categorical_accuracy: 0.9300\n",
      "Epoch 191/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1457 - categorical_accuracy: 0.9870 - val_loss: 0.3402 - val_categorical_accuracy: 0.9367\n",
      "Epoch 192/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1370 - categorical_accuracy: 0.9889 - val_loss: 0.2993 - val_categorical_accuracy: 0.9433\n",
      "Epoch 193/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1325 - categorical_accuracy: 0.9911 - val_loss: 0.2776 - val_categorical_accuracy: 0.9467\n",
      "Epoch 194/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1287 - categorical_accuracy: 0.9933 - val_loss: 0.3228 - val_categorical_accuracy: 0.9433\n",
      "Epoch 195/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1228 - categorical_accuracy: 0.9952 - val_loss: 0.2913 - val_categorical_accuracy: 0.9467\n",
      "Epoch 196/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1228 - categorical_accuracy: 0.9941 - val_loss: 0.3225 - val_categorical_accuracy: 0.9467\n",
      "Epoch 197/200\n",
      "2700/2700 [==============================] - 0s 21us/sample - loss: 0.1233 - categorical_accuracy: 0.9926 - val_loss: 0.3106 - val_categorical_accuracy: 0.9433\n",
      "Epoch 198/200\n",
      "2700/2700 [==============================] - 0s 22us/sample - loss: 0.1234 - categorical_accuracy: 0.9948 - val_loss: 0.3260 - val_categorical_accuracy: 0.9400\n",
      "Epoch 199/200\n",
      "2700/2700 [==============================] - 0s 20us/sample - loss: 0.1305 - categorical_accuracy: 0.9885 - val_loss: 0.3311 - val_categorical_accuracy: 0.9433\n",
      "Epoch 200/200\n",
      "2700/2700 [==============================] - 0s 23us/sample - loss: 0.1207 - categorical_accuracy: 0.9937 - val_loss: 0.3102 - val_categorical_accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "#  Train the model and evaluate with the validation set in every epoch.\n",
    "history_grid = model_grid.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=epochs_grid,\n",
    "                              batch_size=batch_size_grid,\n",
    "                              validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee2746",
   "metadata": {},
   "source": [
    "### Model validation\n",
    "**Evaluate the model per validation set by checking accuracy score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ba90a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 41us/sample - loss: 0.3102 - categorical_accuracy: 0.9400\n",
      "[0.31020312835772834, 0.94]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot traing loss and validation loss\n",
    "plot_loss(history_grid)\n",
    "\n",
    "# Evaluate model by using validation set.\n",
    "print(model_grid.evaluate(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e51584",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation\n",
    "**Evaluate the chosen model with best hyperparameter per test set by checking confusion matrix, classification report, accuracy score and cohen kappa score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76c360ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cd7e1ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[ 29   8]\n",
      " [  1 162]] \n",
      "\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.87        37\n",
      "           1       0.95      0.99      0.97       163\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.96      0.89      0.92       200\n",
      "weighted avg       0.96      0.95      0.95       200\n",
      " \n",
      "\n",
      "Accuracy on test set:  0.955 \n",
      "\n",
      "cohen_kappa score： 0.8389982110912344\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the chosen model with best hyperparameter.\n",
    "pred = model_complex.predict(X_test)\n",
    "\n",
    "# Print performance of the chosen model with best hyperparameter: Confusion matrix, accuracy score and classification report.\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test.argmax(axis=1), pred.argmax(axis=1)), '\\n')\n",
    "print('Classification report: \\n', classification_report(y_test.argmax(axis=1), pred.argmax(axis=1)), '\\n') \n",
    "print('Accuracy on test set: ', accuracy_score(y_test.argmax(axis=1), pred.argmax(axis=1)), '\\n')\n",
    "print('cohen_kappa score：',cohen_kappa_score(y_test.argmax(axis=1), pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbee1f4",
   "metadata": {},
   "source": [
    "## 4. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "464def6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6c3bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the chosen model with best hyperparameter with help of pickle.\n",
    "model_complex.save('Model/NNTaskA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6b8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

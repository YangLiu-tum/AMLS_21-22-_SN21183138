{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314c9823",
   "metadata": {},
   "source": [
    "# Task B: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e71f81",
   "metadata": {},
   "source": [
    "## 1. Preprocess the label file of MRI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288613e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e4d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  3000 non-null   object\n",
      " 1   label      3000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.0+ KB\n",
      "None \n",
      "\n",
      "        file_name             label\n",
      "0  IMAGE_0000.jpg  meningioma_tumor\n",
      "1  IMAGE_0001.jpg          no_tumor\n",
      "2  IMAGE_0002.jpg  meningioma_tumor\n",
      "3  IMAGE_0003.jpg      glioma_tumor\n",
      "4  IMAGE_0004.jpg  meningioma_tumor\n"
     ]
    }
   ],
   "source": [
    "# Read label (.csv file) of dataset.\n",
    "label_csv = pd.read_csv('.\\dataset\\label.csv')\n",
    "\n",
    "# Print basic information of label, notice that it contains 4 classes based on tumor type. \n",
    "print(label_csv.info(), '\\n')\n",
    "print(label_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d77e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16967\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\16967\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\16967\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name             label  new\n",
       "0  IMAGE_0000.jpg  meningioma_tumor    2\n",
       "1  IMAGE_0001.jpg          no_tumor    0\n",
       "2  IMAGE_0002.jpg  meningioma_tumor    2\n",
       "3  IMAGE_0003.jpg      glioma_tumor    1\n",
       "4  IMAGE_0004.jpg  meningioma_tumor    2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For binary task classification, we simply use \"0\" and \"1\" to indicate and identify whether there is a tumor in the MRI images. \n",
    "label_csv['new'] = 0\n",
    "label_csv['new'][label_csv['label']=='glioma_tumor'] = 1\n",
    "label_csv['new'][label_csv['label']=='meningioma_tumor'] = 2\n",
    "label_csv['new'][label_csv['label']=='pituitary_tumor'] = 3\n",
    "\n",
    "# Check result.\n",
    "label_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b033035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000,), dtype('uint8'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer label into array dataformat.\n",
    "label_TaskB = np.array(label_csv['new']).astype('uint8')\n",
    "\n",
    "# Check result.\n",
    "label_TaskB.shape, label_TaskB.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375166f5",
   "metadata": {},
   "source": [
    "## 2. Preprocess MRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6abac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e23a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 3000 512x512 pixel gray-scale MRI images\n",
    "images = [cv2.imread(image, cv2.IMREAD_GRAYSCALE) \n",
    "          for image in glob('dataset/image/*.jpg')]\n",
    "\n",
    "# Median filter is used to remove noise from the MRI images. \n",
    "images_blur = [cv2.medianBlur(images[i], 5)\n",
    "               for i in range(0, len(images))]\n",
    "\n",
    "### Uncomment the following code to check filtered MRI image.\n",
    "# cv2.imshow('MRI Image After Median Filter Test', images_blur[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2bc3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "beta = 0 # Brightness control (0-100)\n",
    "\n",
    "images_adjusted = [cv2.convertScaleAbs(images_blur[i], alpha=alpha, beta=beta)\n",
    "                   for i in range(0, len(images))]\n",
    "                    \n",
    "\n",
    "cv2.imshow('MRI Image After Median Filter Test', images_adjusted[100])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c8ede7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_thresh = images_blur\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    x, images_thresh[i] = cv2.threshold(images_adjusted[i],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "images_normlize = [cv2.normalize(images_thresh[i], None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) \n",
    "                   for i in range(0, len(images))]\n",
    "\n",
    "### Uncomment the following code to check filtered MRI image.\n",
    "cv2.imshow('MRI Image After Median Filter Test', images_normlize[5])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10be33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 512\n",
    "\n",
    "images_resized = [cv2.resize(images_normlize[i], (resize,resize))\n",
    "                  for i in range(0, len(images))]\n",
    "\n",
    "\n",
    "# images_resized = [cv2.resize(images_normlize[i], (resize,resize))\n",
    "#                   for i in range(0, len(images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68bf52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.feature import greycomatrix, greycoprops\n",
    "# feats = np.zeros((3000,72))\n",
    "\n",
    "# for i in range(0, len(images)):\n",
    "#     distances = [1, 2, 3]\n",
    "#     angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "#     properties = ['contrast', 'energy','homogeneity','correlation','dissimilarity','ASM']\n",
    "\n",
    "#     glcm = greycomatrix(images_thresh[i], distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "#     feats[i] = np.hstack([greycoprops(glcm, prop).ravel() for prop in properties])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad43e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 images with 512x512 pixel. \n",
      "\n",
      "After vectorization\n",
      "3000 vectorized images with 262144 pixel.\n"
     ]
    }
   ],
   "source": [
    "# Transfer images into array dataformat.\n",
    "images_TaskB = np.array(images_resized)\n",
    "\n",
    "# Print image infotmation\n",
    "print('{} images with {}x{} pixel. \\n'.format(images_TaskB.shape[0], \n",
    "                                              images_TaskB.shape[1], \n",
    "                                              images_TaskB.shape[2]))\n",
    "\n",
    "# Vectorize images. \n",
    "images_TaskB = images_TaskB.reshape((3000, resize*resize))\n",
    "\n",
    "# Print vectorized image information\n",
    "print('After vectorization')\n",
    "print('{} vectorized images with {} pixel.'.format(images_TaskB.shape[0], \n",
    "                                                          images_TaskB.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364a5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sk = [cv2.imread(image) \n",
    "          for image in glob('dataset/image/*.jpg')]\n",
    "gray_sk = [cv2.cvtColor(img_sk[i],cv2.COLOR_BGR2GRAY)\n",
    "           for i in range(0, len(img_sk))]   \n",
    "\n",
    "# img_sk = [cv2.medianBlur(img_sk[i], 5)\n",
    "#           for i in range(0, len(img_sk))]\n",
    "\n",
    "# gray_sk = [cv2.medianBlur(gray_sk[i], 5)\n",
    "#            for i in range(0, len(img_sk))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "874eff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23912/1116447974.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#Get label of largest component by area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mlargest_component\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#Add 1 since we dropped zero above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#Get pixels which correspond to the brain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "img_brainout = img_sk\n",
    "for i in range(109, len(img_sk)):  \n",
    "    print(i)\n",
    "    \n",
    "    ret, thresh = cv2.threshold(gray_sk[i],0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    colormask = np.zeros(img_sk[i].shape, dtype=np.uint8)\n",
    "    colormask[thresh!=0] = np.array((0,0,255))\n",
    "    blended = cv2.addWeighted(img_sk[i],0.7,colormask,0.1,0)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(thresh)\n",
    "\n",
    "    #Get the area taken by each component. Ignore label 0 since this is the background.\n",
    "    marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0] \n",
    "    \n",
    "    #Get label of largest component by area\n",
    "    largest_component = np.argmax(marker_area)+1 #Add 1 since we dropped zero above \n",
    "    \n",
    "    #Get pixels which correspond to the brain\n",
    "    brain_mask = markers==largest_component\n",
    "\n",
    "    brain_out = img_sk[i].copy()\n",
    "    #In a copy of the original image, clear those pixels that don't correspond to the brain\n",
    "    brain_out[brain_mask==False] = (0,0,0)\n",
    "    \n",
    "    img_brainout[i] = brain_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16892/2786951967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_withoutSK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskull_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_sk_blur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray_sk_blur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# cv2.imshow('MRI Image Test', img_withoutSK[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# cv2.waitKey(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16892/1075559426.py\u001b[0m in \u001b[0;36mskull_out\u001b[1;34m(img_sk, gray_sk)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#Get label of largest component by area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mlargest_component\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#Add 1 since we dropped zero above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#Get pixels which correspond to the brain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "img_withoutSK = skull_out(img_sk_blur, gray_sk_blur)\n",
    "\n",
    "\n",
    "# cv2.imshow('MRI Image Test', img_withoutSK[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e5e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dataset/image/IMAGE_0109.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "colormask = np.zeros(img.shape, dtype=np.uint8)\n",
    "colormask[thresh!=0] = np.array((0,0,255))\n",
    "blended = cv2.addWeighted(img,0.7,colormask,0.1,0)\n",
    "\n",
    "ret, markers = cv2.connectedComponents(thresh)\n",
    "\n",
    "#Get the area taken by each component. Ignore label 0 since this is the background.\n",
    "marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0] \n",
    "#Get label of largest component by area\n",
    "largest_component = np.argmax(marker_area)+1 #Add 1 since we dropped zero above                        \n",
    "#Get pixels which correspond to the brain\n",
    "brain_mask = markers==largest_component\n",
    "\n",
    "brain_out = img.copy()\n",
    "#In a copy of the original image, clear those pixels that don't correspond to the brain\n",
    "brain_out[brain_mask==False] = (0,0,0)\n",
    "\n",
    "cv2.imshow('MRI Image Test', brain_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b858ee3",
   "metadata": {},
   "source": [
    "## 3. Data dimensionality reduction and denoising by using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e765efd",
   "metadata": {},
   "source": [
    "### A simple test by using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30a4fb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2700, 262144), (2700,), (300, 262144), (300,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into a training set and a test set (90% training and 10% testing data).\n",
    "# Notice that all random state is chosen as 0 in this assignment to ensure reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_TaskB,label_TaskB, \n",
    "                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "# Check result.\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b0114a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7566666666666667\n"
     ]
    }
   ],
   "source": [
    "# Call the SVC() model from sklearn and fit the model to the training data.\n",
    "svm_test = SVC(C=1, decision_function_shape='ovo')\n",
    "svm_test.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions from the model.\n",
    "pred_test = svm_test.predict(X_test)\n",
    "\n",
    "# Check the accuracy score.\n",
    "print('Accuracy score:', accuracy_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059450d",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5467d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Call the PCA() model from sklearn and fit the model to the training data.\n",
    "# In this example, we want to oberserve the top 500 principal components of data.\n",
    "pca_test = PCA(n_components=500)\n",
    "pca_test.fit(images_TaskB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d4c6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bb62d4c5c8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_components = 500\n",
    "\n",
    "variance_ratio = pca_test.explained_variance_ratio_\n",
    "variance_ratio_cum = variance_ratio.cumsum()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(variance_ratio_cum[:n_components], 'o-')\n",
    "plt.plot(variance_ratio[:n_components], '*-')\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(2,1 figsize = (12,3))\n",
    "\n",
    "# # default grid appearance\n",
    "# axes[0].plot(x_cum[:k], 'o-', lw=2)\n",
    "# axes[0].grid()\n",
    "\n",
    "# # custom grid appearance\n",
    "# axes[1].plot(x[:k], '*-', lw=2)\n",
    "# axes[1].grid(color='b', alpha=0.5, linestyle='dashed', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7c5cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the PCA() model from sklearn and fit the model to the training data.\n",
    "# Notice that\n",
    "pca_TaskB = PCA(n_components=200)\n",
    "images_PCA = pca_TaskB.fit_transform(images_TaskB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f98729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 200) (2700,) (300, 200) (300,)\n",
      "train set: 0.9  | test set: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Split data into a training set and a test set (90% training and 10% testing data).\n",
    "# Notice that all random state is chosen as 0 in this assignment to ensure reproducibility.\n",
    "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(images_PCA,label_TaskB, \n",
    "                                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "# Check result.\n",
    "print(X_train_PCA.shape, y_train_PCA.shape, X_test_PCA.shape, y_test_PCA.shape) \n",
    "print('train set: {}  | test set: {}'.format(round(len(y_train_PCA)/len(images_PCA),3), \n",
    "                                             round(len(y_test_PCA)/len(images_PCA),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a6a48da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "# Call the SVC() model from sklearn and fit the model to the training data.\n",
    "svm_PCA = SVC(C=65,decision_function_shape='ovo')\n",
    "svm_PCA.fit(X_train_PCA, y_train_PCA)\n",
    "\n",
    "# Get predictions from the model.\n",
    "pred_PCA = svm_PCA.predict(X_test_PCA)\n",
    "\n",
    "# Check the accuracy score.\n",
    "print('Accuracy score:', accuracy_score(y_test_PCA,pred_PCA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff5c17",
   "metadata": {},
   "source": [
    "## 4. Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b834799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4ddce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 4096), (3000,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate new data array of preprocessed data.\n",
    "# images_AfterProcess = images_PCA.copy()\n",
    "images_AfterProcess = images_TaskB.copy()\n",
    "label_AfterProcess = label_TaskB.copy()\n",
    "\n",
    "# Check preprocessed data.\n",
    "images_AfterProcess.shape, label_AfterProcess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30cbb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data with help of pickle.\n",
    "with open('DataAfterProcess/images_AfterProcess.pickle', 'wb') as handle:\n",
    "    pickle.dump(images_AfterProcess, handle)\n",
    "    \n",
    "with open('DataAfterProcess/label_AfterProcess.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_AfterProcess, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d39055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variance_ratio data generated by PCA process of images with help of pickle.\n",
    "with open('DataBackUp/variance_ratio.pickle', 'wb') as handle:\n",
    "    pickle.dump(variance_ratio, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b05cf077",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_TaskA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/3084149039.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataAfterProcess/label_AfterProcess.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_TaskA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'label_TaskA' is not defined"
     ]
    }
   ],
   "source": [
    "with open('DataAfterProcess/label_AfterProcess.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_TaskA, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368bfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

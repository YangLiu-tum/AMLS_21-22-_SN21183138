{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cf9748",
   "metadata": {},
   "source": [
    "# Task B: Data Preprocessing of Transfer Learning with VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3dca4e",
   "metadata": {},
   "source": [
    "## 1. Implement one-hot encoding to label file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4dffb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0732cc3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,) (200,)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed label of image data with help of pickle.\n",
    "with open('DataAfterProcess/label_AfterProcess.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)\n",
    "\n",
    "# Load preprocessed label of test dataset with help of pickle.\n",
    "with open('DataAfterProcess/test_label_AfterProcess.pickle', 'rb') as handle:\n",
    "    y_test = pickle.load(handle)\n",
    "\n",
    "# Check result.\n",
    "print(y.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f99a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 4) (200, 4)\n"
     ]
    }
   ],
   "source": [
    "# Implement one-hot encoding to labels.\n",
    "y = to_categorical(y)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Check result.\n",
    "print(y.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61acaaae",
   "metadata": {},
   "source": [
    "## 2. Preprocess MRI images for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadcd182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f99912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256, 256, 3) (200, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read 3000 512x512 pixel gray-scale MRI images\n",
    "images_train = [cv2.imread(image) \n",
    "                for image in glob('dataset/image/*.jpg')]\n",
    "\n",
    "# Read 200 512x512 pixel gray-scale MRI images\n",
    "images_test = [cv2.imread(image) \n",
    "               for image in glob('test/image/*.jpg')]\n",
    "\n",
    "# Resize images into 256*256 pixel\n",
    "resize = 256\n",
    "images_train_resized = [cv2.resize(images_train[i], (resize,resize))\n",
    "                        for i in range(0, len(images_train))]\n",
    "images_test_resized = [cv2.resize(images_test[i], (resize,resize))\n",
    "                        for i in range(0, len(images_test))]\n",
    "\n",
    "# Normalize images.\n",
    "X = np.array(images_train_resized)/255\n",
    "X_test = np.array(images_test_resized)/255\n",
    "\n",
    "# Check result.\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df346d7",
   "metadata": {},
   "source": [
    "## 1. Formulate base model of transfer learning: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad85e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "# Define input of the VGG16, since they are fixed!\n",
    "height, width, channel = X.shape[1], X.shape[2], X.shape[-1]\n",
    "\n",
    "# Create and configure the VGG16 model.\n",
    "path_VGG16_weights='Model/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model = vgg16.VGG16(weights = path_VGG16_weights,\n",
    "                         include_top = False, \n",
    "                         input_shape = (height, width, channel))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be9681",
   "metadata": {},
   "source": [
    "## 2. Compute output of convolutional layer in VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef09cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 8, 8, 512)\n",
      "(200, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "# Compute output of the convolutional layer in VGG16 as new dataset and test set used for transfer learning.\n",
    "X_VGG =  base_model.predict(X)\n",
    "X_test_VGG =  base_model.predict(X_test)\n",
    "\n",
    "# Check result.\n",
    "print(X_VGG.shape)\n",
    "print(X_test_VGG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a24e1",
   "metadata": {},
   "source": [
    "## 2. Save new dataset and test set used for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609b682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data array to store new dataset and test set.\n",
    "X_VGG_256 = X_VGG.reshape(3000, \n",
    "                          X_VGG.shape[1]*X_VGG.shape[1]*X_VGG.shape[3])\n",
    "X_test_VGG_256 = X_test_VGG.reshape(200, \n",
    "                                    X_test_VGG.shape[1]*X_test_VGG.shape[1]*X_test_VGG.shape[3])\n",
    "\n",
    "\n",
    "# Save new dataset and test set with help of pickle.\n",
    "with open('DataAfterProcess/X_VGG_256.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_VGG_256, handle)  \n",
    "    \n",
    "with open('DataAfterProcess/X_test_VGG_256.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_test_VGG_256, handle)\n",
    "    \n",
    "# Save label file after one-hot encoding with help of pickle.\n",
    "with open('DataAfterProcess/y.pickle', 'wb') as handle:\n",
    "    pickle.dump(y, handle)  \n",
    "    \n",
    "with open('DataAfterProcess/y_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6b8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

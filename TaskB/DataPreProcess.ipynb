{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314c9823",
   "metadata": {},
   "source": [
    "# Task B: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e71f81",
   "metadata": {},
   "source": [
    "## 1. Preprocess the label file of MRI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288613e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e4d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  3000 non-null   object\n",
      " 1   label      3000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.0+ KB\n",
      "None \n",
      "\n",
      "        file_name             label\n",
      "0  IMAGE_0000.jpg  meningioma_tumor\n",
      "1  IMAGE_0001.jpg          no_tumor\n",
      "2  IMAGE_0002.jpg  meningioma_tumor\n",
      "3  IMAGE_0003.jpg      glioma_tumor\n",
      "4  IMAGE_0004.jpg  meningioma_tumor\n"
     ]
    }
   ],
   "source": [
    "# Read label (.csv file) of dataset.\n",
    "label_csv = pd.read_csv('.\\dataset\\label.csv')\n",
    "\n",
    "# Print basic information of label, notice that it contains 4 classes based on tumor type. \n",
    "print(label_csv.info(), '\\n')\n",
    "print(label_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d77e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16967\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\16967\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\16967\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name             label  new\n",
       "0  IMAGE_0000.jpg  meningioma_tumor    2\n",
       "1  IMAGE_0001.jpg          no_tumor    0\n",
       "2  IMAGE_0002.jpg  meningioma_tumor    2\n",
       "3  IMAGE_0003.jpg      glioma_tumor    1\n",
       "4  IMAGE_0004.jpg  meningioma_tumor    2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For binary task classification, we simply use \"0\" and \"1\" to indicate and identify whether there is a tumor in the MRI images. \n",
    "label_csv['new'] = 0\n",
    "label_csv['new'][label_csv['label']=='glioma_tumor'] = 1\n",
    "label_csv['new'][label_csv['label']=='meningioma_tumor'] = 2\n",
    "label_csv['new'][label_csv['label']=='pituitary_tumor'] = 3\n",
    "\n",
    "# Check result.\n",
    "label_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b033035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000,), dtype('uint8'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer label into array dataformat.\n",
    "label_TaskB = np.array(label_csv['new']).astype('uint8')\n",
    "\n",
    "# Check result.\n",
    "label_TaskB.shape, label_TaskB.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375166f5",
   "metadata": {},
   "source": [
    "## 2. Preprocess MRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6abac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e23a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 3000 512x512 pixel gray-scale MRI images\n",
    "images = [cv2.imread(image, cv2.IMREAD_GRAYSCALE) \n",
    "          for image in glob('dataset/image/*.jpg')]\n",
    "\n",
    "# Median filter is used to remove noise from the MRI images. \n",
    "images_blur = [cv2.medianBlur(images[i], 5)\n",
    "               for i in range(0, len(images))]\n",
    "\n",
    "### Uncomment the following code to check filtered MRI image.\n",
    "# cv2.imshow('MRI Image After Median Filter Test', images_blur[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2bc3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "beta = 0 # Brightness control (0-100)\n",
    "\n",
    "images_adjusted = [cv2.convertScaleAbs(images_blur[i], alpha=alpha, beta=beta)\n",
    "                   for i in range(0, len(images))]\n",
    "                    \n",
    "# cv2.imshow('MRI Image After Median Filter Test', images_adjusted[100])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8ede7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_thresh = images_blur\n",
    "\n",
    "# for i in range(0, len(images)):\n",
    "#     x, images_thresh[i] = cv2.threshold(images_adjusted[i],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# images_normlize = [cv2.normalize(images_thresh[i], None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) \n",
    "#                    for i in range(0, len(images))]\n",
    "    \n",
    "images_normlize = [cv2.normalize(images_adjusted[i], None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) \n",
    "                   for i in range(0, len(images))]\n",
    "\n",
    "### Uncomment the following code to check filtered MRI image.\n",
    "cv2.imshow('MRI Image After Median Filter Test', images_normlize[5])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10be33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 128\n",
    "\n",
    "images_resized = [cv2.resize(images_normlize[i], (resize,resize))\n",
    "                  for i in range(0, len(images))]\n",
    "\n",
    "\n",
    "# images_resized = [cv2.resize(images_normlize[i], (resize,resize))\n",
    "#                   for i in range(0, len(images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68bf52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.feature import greycomatrix, greycoprops\n",
    "# feats = np.zeros((3000,72))\n",
    "\n",
    "# for i in range(0, len(images)):\n",
    "#     distances = [1, 2, 3]\n",
    "#     angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "#     properties = ['contrast', 'energy','homogeneity','correlation','dissimilarity','ASM']\n",
    "\n",
    "#     glcm = greycomatrix(images_thresh[i], distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "#     feats[i] = np.hstack([greycoprops(glcm, prop).ravel() for prop in properties])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad43e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 images with 128x128 pixel. \n",
      "\n",
      "After vectorization\n",
      "3000 vectorized images with 16384 pixel.\n"
     ]
    }
   ],
   "source": [
    "# Transfer images into array dataformat.\n",
    "images_TaskB = np.array(images_resized)\n",
    "\n",
    "# Print image infotmation\n",
    "print('{} images with {}x{} pixel. \\n'.format(images_TaskB.shape[0], \n",
    "                                              images_TaskB.shape[1], \n",
    "                                              images_TaskB.shape[2]))\n",
    "\n",
    "# Vectorize images. \n",
    "images_TaskB = images_TaskB.reshape((3000, resize*resize))\n",
    "\n",
    "# Print vectorized image information\n",
    "print('After vectorization')\n",
    "print('{} vectorized images with {} pixel.'.format(images_TaskB.shape[0], \n",
    "                                                          images_TaskB.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364a5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sk = [cv2.imread(image) \n",
    "          for image in glob('dataset/image/*.jpg')]\n",
    "gray_sk = [cv2.cvtColor(img_sk[i],cv2.COLOR_BGR2GRAY)\n",
    "           for i in range(0, len(img_sk))]   \n",
    "\n",
    "# img_sk = [cv2.medianBlur(img_sk[i], 5)\n",
    "#           for i in range(0, len(img_sk))]\n",
    "\n",
    "# gray_sk = [cv2.medianBlur(gray_sk[i], 5)\n",
    "#            for i in range(0, len(img_sk))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "874eff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23912/1116447974.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#Get label of largest component by area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mlargest_component\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#Add 1 since we dropped zero above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#Get pixels which correspond to the brain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "img_brainout = img_sk\n",
    "for i in range(109, len(img_sk)):  \n",
    "    print(i)\n",
    "    \n",
    "    ret, thresh = cv2.threshold(gray_sk[i],0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    colormask = np.zeros(img_sk[i].shape, dtype=np.uint8)\n",
    "    colormask[thresh!=0] = np.array((0,0,255))\n",
    "    blended = cv2.addWeighted(img_sk[i],0.7,colormask,0.1,0)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(thresh)\n",
    "\n",
    "    #Get the area taken by each component. Ignore label 0 since this is the background.\n",
    "    marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0] \n",
    "    \n",
    "    #Get label of largest component by area\n",
    "    largest_component = np.argmax(marker_area)+1 #Add 1 since we dropped zero above \n",
    "    \n",
    "    #Get pixels which correspond to the brain\n",
    "    brain_mask = markers==largest_component\n",
    "\n",
    "    brain_out = img_sk[i].copy()\n",
    "    #In a copy of the original image, clear those pixels that don't correspond to the brain\n",
    "    brain_out[brain_mask==False] = (0,0,0)\n",
    "    \n",
    "    img_brainout[i] = brain_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16892/2786951967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_withoutSK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskull_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_sk_blur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray_sk_blur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# cv2.imshow('MRI Image Test', img_withoutSK[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# cv2.waitKey(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16892/1075559426.py\u001b[0m in \u001b[0;36mskull_out\u001b[1;34m(img_sk, gray_sk)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#Get label of largest component by area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mlargest_component\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#Add 1 since we dropped zero above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#Get pixels which correspond to the brain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AMLS_Lab\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "img_withoutSK = skull_out(img_sk_blur, gray_sk_blur)\n",
    "\n",
    "\n",
    "# cv2.imshow('MRI Image Test', img_withoutSK[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e5e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dataset/image/IMAGE_0109.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "colormask = np.zeros(img.shape, dtype=np.uint8)\n",
    "colormask[thresh!=0] = np.array((0,0,255))\n",
    "blended = cv2.addWeighted(img,0.7,colormask,0.1,0)\n",
    "\n",
    "ret, markers = cv2.connectedComponents(thresh)\n",
    "\n",
    "#Get the area taken by each component. Ignore label 0 since this is the background.\n",
    "marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0] \n",
    "#Get label of largest component by area\n",
    "largest_component = np.argmax(marker_area)+1 #Add 1 since we dropped zero above                        \n",
    "#Get pixels which correspond to the brain\n",
    "brain_mask = markers==largest_component\n",
    "\n",
    "brain_out = img.copy()\n",
    "#In a copy of the original image, clear those pixels that don't correspond to the brain\n",
    "brain_out[brain_mask==False] = (0,0,0)\n",
    "\n",
    "cv2.imshow('MRI Image Test', brain_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b858ee3",
   "metadata": {},
   "source": [
    "## 3. Data dimensionality reduction and denoising by using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e765efd",
   "metadata": {},
   "source": [
    "### A simple test by using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30a4fb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2700, 16384), (2700,), (300, 16384), (300,))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into a training set and a test set (90% training and 10% testing data).\n",
    "# Notice that all random state is chosen as 0 in this assignment to ensure reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_TaskB,label_TaskB, \n",
    "                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "# Check result.\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b0114a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "# Call the SVC() model from sklearn and fit the model to the training data.\n",
    "svm_test = SVC(C=1, decision_function_shape='ovo')\n",
    "svm_test.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions from the model.\n",
    "pred_test = svm_test.predict(X_test)\n",
    "\n",
    "# Check the accuracy score.\n",
    "print('Accuracy score:', accuracy_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059450d",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5467d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=300)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Call the PCA() model from sklearn and fit the model to the training data.\n",
    "# In this example, we want to oberserve the top 500 principal components of data.\n",
    "pca_test = PCA(n_components=300)\n",
    "pca_test.fit(images_TaskB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45d4c6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1996d5595c8>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_components = 300\n",
    "\n",
    "variance_ratio = pca_test.explained_variance_ratio_\n",
    "variance_ratio_cum = variance_ratio.cumsum()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(variance_ratio_cum[:n_components], 'o-')\n",
    "plt.plot(variance_ratio[:n_components], '*-')\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(2,1 figsize = (12,3))\n",
    "\n",
    "# # default grid appearance\n",
    "# axes[0].plot(x_cum[:k], 'o-', lw=2)\n",
    "# axes[0].grid()\n",
    "\n",
    "# # custom grid appearance\n",
    "# axes[1].plot(x[:k], '*-', lw=2)\n",
    "# axes[1].grid(color='b', alpha=0.5, linestyle='dashed', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a7c5cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Call the PCA() model from sklearn and fit the model to the training data.\n",
    "# Notice that\n",
    "pca_TaskB = PCA(n_components=100)\n",
    "images_PCA = pca_TaskB.fit_transform(images_TaskB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f98729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 100) (2700,) (300, 100) (300,)\n",
      "train set: 0.9  | test set: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Split data into a training set and a test set (90% training and 10% testing data).\n",
    "# Notice that all random state is chosen as 0 in this assignment to ensure reproducibility.\n",
    "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(images_PCA,label_TaskB, \n",
    "                                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "# Check result.\n",
    "print(X_train_PCA.shape, y_train_PCA.shape, X_test_PCA.shape, y_test_PCA.shape) \n",
    "print('train set: {}  | test set: {}'.format(round(len(y_train_PCA)/len(images_PCA),3), \n",
    "                                             round(len(y_test_PCA)/len(images_PCA),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a6a48da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Call the SVC() model from sklearn and fit the model to the training data.\n",
    "svm_PCA = SVC(C=10)\n",
    "svm_PCA.fit(X_train_PCA, y_train_PCA)\n",
    "\n",
    "# Get predictions from the model.\n",
    "pred_PCA = svm_PCA.predict(X_test_PCA)\n",
    "\n",
    "# Check the accuracy score.\n",
    "print('Accuracy score:', accuracy_score(y_test_PCA,pred_PCA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff5c17",
   "metadata": {},
   "source": [
    "## 4. Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b834799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4ddce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 4096), (3000,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate new data array of preprocessed data.\n",
    "# images_AfterProcess = images_PCA.copy()\n",
    "images_AfterProcess = images_TaskB.copy()\n",
    "label_AfterProcess = label_TaskB.copy()\n",
    "\n",
    "# Check preprocessed data.\n",
    "images_AfterProcess.shape, label_AfterProcess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30cbb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data with help of pickle.\n",
    "with open('DataAfterProcess/images_AfterProcess.pickle', 'wb') as handle:\n",
    "    pickle.dump(images_AfterProcess, handle)\n",
    "    \n",
    "with open('DataAfterProcess/label_AfterProcess.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_AfterProcess, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d39055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variance_ratio data generated by PCA process of images with help of pickle.\n",
    "with open('DataBackUp/variance_ratio.pickle', 'wb') as handle:\n",
    "    pickle.dump(variance_ratio, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b05cf077",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_TaskA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/3084149039.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataAfterProcess/label_AfterProcess.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_TaskA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'label_TaskA' is not defined"
     ]
    }
   ],
   "source": [
    "with open('DataAfterProcess/label_AfterProcess.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_TaskA, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368bfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
